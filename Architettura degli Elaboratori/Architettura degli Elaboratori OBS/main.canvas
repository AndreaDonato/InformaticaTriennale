{
	"nodes":[
		{"id":"e723e0fbc1846d02","type":"text","text":"# Tipi di architetture\n\nPersonal computers (PCs) good performance to single users at low cost and usually\nexecute third-party software. 35 years old!\n\n\nServers usually accessed only via a network. oriented to carrying sizable\nworkloads, or handling many small jobs, e usually based on\nsoftware from another source (such as a database or simulation system), emphasis\non dependability, since a crash is usually  costly\n\nsupercomputers (configured as servers) which at the present consist of tens of thousands of processors and many terabytes of memory, weather forecasting, oil exploration, protein structure determination, and other large-scale problems\n\n\nEmbedded computers microprocessors networks of processors designed to run one application or one set of related applications that are normally integrated with the hardware and delivered as a single system; minimum performance with stringent limitations on cost or power lower tolerance for failure consumer-oriented embedded applications emphasis is on doing one function as perfectly as possible large embedded\nsystems redundancy often employed most concepts apply directly, or with slight modifications, to embedded computers.\n\npersonal mobile device (PMD) smart phone or a tablet tomorrow it may include  electronic glasses are small wireless devices to connect to the Internet\n\n\nCloud Computing large collections of servers that provide services over the Internet\n\n\nSoftware as a Service (SaaS) delivers software and data as a service over the Internet\nvia browser instead of binary code that must be installed runs wholly on that device e.g. web search social networking\n\n\n","x":1791,"y":115,"width":720,"height":777,"color":"2"},
		{"id":"2452606adbf4ae6d","type":"file","file":"Capitolo 1/conversions.png","x":1520,"y":-280,"width":991,"height":340},
		{"id":"70f63fa924d39f03","type":"text","text":"# Come influenza le performance?\n\n- Algorithm: number of source-level statements number of I/O operations executed\n- Programming language compiler, and architecture: number of computer instructions for each source-level statement\n- Processor and memory: how fast instructions can be executed\n- I/O system (hardware and OS): how fast I/O operations may be executed","x":2071,"y":1612,"width":500,"height":377},
		{"id":"3c12a472e21d0b51","type":"text","text":"# Domande a cui rispondere\n\nHow are programs written in a high-level language translated into the language of the hardware, and how does the hardware\nexecute the resulting program?\n\nWhat is the interface between the software and the hardware, and how does software instruct the hardware to perform needed functions?\n\nhow can designers improve energy, efficiency, performance\n\nhow can programmer improve the performance\n \nswitch from sequential processing to parallel processing\n\nunderstanding these questions makes improving the performances a scientific procedure\n","x":800,"y":1091,"width":991,"height":398},
		{"id":"7c44d0b7fa4661bf","type":"text","text":"# Cuscinetti tra user e HW\n\nsystems software is the name of stuff sitting between the hardware and the application software. two types are central to every computer:\n- operating system: Supervising program that manages the resources of a computer for the benefit of the programs that run on that computer\n- compiler: translates high-level language statements into assembly language statements\n\nbut also\n\n-  loaders: loads programs in main memory\n- assemblers: translates a symbolic version of instructions into the binary version (assembly language A symbolic representation of machine instructions Assembly language requires the programmer to write one line for every instruction that the computer will follow, forcing the programmer to think like the computer)\n- ...\n\nthey provide\n- basic input and output\n- Allocating\n- sharing of the computer among multiple applications\n\n","x":3211,"y":460,"width":991,"height":760},
		{"id":"3f606618d45d0104","type":"text","text":"# Tecniche di design\n\n- abstractions\n- make common case fast will tend to enhance performance better than optimizing the rare case\n- parallel performance\n- pipelining particular pattern of parallelism. runs programs faster by overlapping the execution of instructions industry has bet its future that programmers will switch to explicitly parallel programming.\n- prediction: it can be faster on average to guess and start working rather than wait until you know for sure\n- hierarchy of memories: memory speed often shapes performance, capacity limits the size of problems. cost of memory is majority of computer cost. hierarchy of memories: fastest, smallest, and the most expensive memory per bit at the top slowest, largest, and cheapest per bit at the bottom\n- Dependability via Redundancy: redundant components that can take over when a failure occurs and to help detect failures","x":2321,"y":960,"width":720,"height":550},
		{"id":"f3d63dbf481dd171","type":"file","file":"Capitolo 1/ComputerScheme.png","x":4531,"y":-356,"width":400,"height":333},
		{"id":"500dd90d04313081","type":"text","text":"# Commenti a caso che non so dove mettere (da qualche parte qui vicino)\n\nMoore’s Law integrated circuit resources double every 18–24 months computer designs can take years resources can easily double between the start and finish computer architects must anticipate where the technology will be when the design finishes  \n\n\n\nfive classic components of a computer are input, output, memory,\ndatapath, and control, with the last two sometimes combined and called\nthe processor\n\n\nExecution time is the only valid and unimpeachable measure of\nperformance. Many other metrics have been proposed and found wanting.\nSometimes these metrics are flawed from the start by not reflecting\nexecution time; other times a metric that is sound in a limited context\nis extended and used beyond that context or without the additional\nclarification needed to make it valid.\n\n\nmillion instructions per second (MIPS) A measurement of program execution speed based on the number of millions of instructions. \n$$\nMIPS = \\frac{I}{T_{cpu}*10^6} = \\frac{r_C}{CPI\\cdot 10^6}\n$$\n","x":3731,"y":-440,"width":720,"height":700},
		{"id":"94ebb589ac92b6e9","type":"text","text":"# Nomenclatura interna\n\n- integrated circuit (chip) dozens to millions of transistors.\n\n- CPU contains the datapath and control adds numbers, tests numbers, signals I/O devices to activate, and so on\n\t- Inside the processor is another type of memory, cache memory. small, fast memory that acts as a buffer for a slower, larger memory. SRAM (cache) faster and less dense than DRAM (RAM). cache is a safe place for hiding things (????)\n- datapath performs arithmetic operations\n- control: commands the datapath, memory, and I/O devices according to the instructions of the program.\n- DRAM: Memory built as an integrated circuit Access times are 50 nanoseconds In contrast to sequential access memories, such as magnetic tapes, the RAM portion of the term DRAM means that memory accesses take basically the same amount of time no matter what portion of the memory is read.\n- transistor: on/off switch controlled by an electric signal.\n- VLSI: device containing millions of transistors","x":4431,"y":460,"width":460,"height":700},
		{"id":"46ee857cb70eed15","type":"text","text":"# Nomenclatura (concettuale) interna\n\ninterface between the hardware and the lowest-level software (**architecture** or ISA), includes anything programmers need to know to make a binary machine language program work correctly.\nallows computer designers to talk about functions\nindependently from the hardware\n\ncombination of the basic instruction set and the operating system interface provided for application programmers is called the application binary interface (ABI)\n\nimplementation of an architecture is hardware that obeys the architecture abstraction\n","x":4931,"y":460,"width":440,"height":700},
		{"id":"969e5ce3a6049ee4","type":"text","text":"# Reti (cenni)\n\ncomputers on the network can share I/O devices ($\\Rightarrow$ Nonlocal access). Ethernet: up to a kilometer long and transfer at up to 40 gigabits per second.\n\nLAN network within a geographically\nconfined area, typically within a single building. capacity of from 1 to 40 gigabits per second\n\nWAN network that can span a continent\n\nOptical communications allowed growth in the capacity of wide area networks to gigabits and  to a worldwide network\n\nWireless technology enabled the post-PC era. ability to radiosignal with low-cost semiconductor technology (CMOS) used for memory and microprocessors enabled improvement in price","x":5431,"y":460,"width":420,"height":700},
		{"id":"6264c0d982a44972","type":"text","text":"## Giorgio vuole fare un breve trattato sull'Universo","x":5454,"y":120,"width":280,"height":140,"color":"1"},
		{"id":"0b6d09ee9d694b1f","type":"text","text":"# (Riassunto) 1 - Introduzione\n\nAl momento le frecce indicano l'ordine degli argomenti nel capitolo, non sono assolutamente utili in senso concettuale","x":1751,"y":-550,"width":480,"height":220,"color":"6"},
		{"id":"e4506d54dcf914ea","type":"text","text":"# Performance\n\nwe can define computer performance in several distinct ways\n- **response time (execution time)**: As an individual computer user, the time between the start and completion of a task\n- Datacenters manage throughput or bandwidth (total amount of work done in a given time)\n\n##### Example: How to increase throughtput?\nmay be via (look for others...)\n- Replacing the processor in a computer with a faster version\n- also Adding additional processors to a system that uses multiple processors for separate tasks—for example, searching the web. If demand for processing in this second case is as large as the throughput, system might force requests to queue up increasing the throughput could also improve response time.\n\nwe could define\n$$\nperformance = \\frac{1}{execution\\,\\,time}\n$$\n\n###### Measuring performance\n\n- wall clock time, response time, or elapsed time: total time to complete a task.\n- processor may work on several programs simultaneously system may try to optimize throughput rather than elapsed time. **CPU execution time** is the time the CPU spends computing for this task and does not include time spent waiting for I/O or running other programs. further divided into\n\t- CPU time spent in the program (user CPU time)\n\t- CPU time spent in the operating system performing tasks on behalf of the program (system CPU time)\n\nDifferentiating between system and user is difficult.\n\nWe use \"system performance\" for elapsed time on an unloaded system and \"CPU performance\" for user CPU time. discussions of how to summarize performance can be applied to either elapsed time or CPU time measurements.\n\nMany applications depend as much on I/O performance, which relies on both hardware and software.\n\nTo improve the performance clear definition of what performance matters and find bottlenecks","x":5511,"y":1320,"width":817,"height":1080},
		{"id":"dfd2890763a0d962","type":"text","text":"# CPU\n\nclock determines when events take place in the hardware (so how fast the hardware can perform basic functions).\nDesigners refer to clock period both for complete clock cycle (picoseconds) and for the clock rate (GHz). Che cani.\n$$\nT_{cpu}(P) = N_{c}(P) \\cdot T_C = \\frac{N_{c}(P)}{r_c}\n$$\ndove $T_{CPU}(P)$ è CPU execution time for a Program P, $N_{c}(P)$ è CPU clock cycles for a given P, $T_c$ è Clock cycle time e $r_c$ è il suo inverso (clock rate). Quante ovvietà.\n\nImprove performance by reducing clock cycles required or the length of the clock cycle. Often trade-off: Many techniques that decrease the number of clock cycles may also increase the clock cycle time\n\nexecution time must depend on the number $I(P)$ of instructions executed in a program (instruction count ovvero $T_{CPU}$ è una $T_{CPU}(I(P))$), possiamo vedere questa dipendenza come\n$$\nN_{C}(P) = I(P) \\cdot CPI(P)\n$$\n\naverage clock cycles per instruction CPI (è una media di cicli per istruzione del programma P che esegue I(P) istruzioni) provides one way of comparing two different implementations of the identical instruction set architecture.\n$$\nT_{CPU}(P) = \\frac{I(P) \\cdot CPI(P)}{r_c}\n$$\n\nWe can measure the CPU execution time by running the program.\nclock cycle time is usually published instruction count and CPI can be more difficult to obtain instruction count by using software tools\nor by using a simulator of the architecture. Alternatively, hardware counters included in most processors, to record a variety of measurements. instruction count depends on the architecture, but not on the exact implementation\n\nCosa influenza $I$ e $CPI$?\n- if the **algorithm** uses more divides, it will tend to have a higher CPI;\n- statements in the **programming language** translated to processor instructions determine instruction count.\n- compiler\n- ISA (anche clock rate (?))\n\n\n##### Altro\nInvert CPI to talk about IPC instructions per clock cycle\n\ntoday’s processors can vary their clock rates Intel Core i7 will temporarily increase clock rate by about 10% until the chip gets too warm. Intel calls this Turbo mode.","x":6531,"y":1260,"width":660,"height":1200,"color":"2"},
		{"id":"e1323ed7fa9295aa","type":"text","text":"# Instruction Set Architecture (ISA)\n\nL'ISA può essere visto come un vocabolario delle operazioni eseguibili dall'HW.\n*Tendenzialmente*, a diversi HW corrispondono diversi ISA, ma è possibile\n- costruire ISA diversi sullo stesso HW;\n- costruire un ISA compatibile con diversi HW.\n\nE' probabile trovare ISA molto simili tra loro, perché tutti i computer\n- sono costruiti a partire principi di funzionamento simili (e.g. ci sono sempre dei registri, della memoria in cui tenere i dati che non entrano nei registri, ...);\n- necessitano almeno di un insieme standard di operazioni di base (e.g. addizione, lettura da memoria, ...).\n\nA livello pratico, l'ISA definisce alcuni algoritmi in linguaggio macchina che hanno come risultati operazioni più complesse come\n- operazioni aritmetico-logiche (e.g. sommare due numeri);\n- spostamento di dati tra registri, o tra registri e memoria;\n- istruzioni di salto (e.g. alterazione del _flusso normale_);\n- ...\n\nPotremmo chiamare uno di questi algoritmi *somma*, o *moltiplicazione*, e ignorare completamente i dettagli implementativi. L'ISA mi garantisce che se all'algoritmo *somma* do' in pasto due numeri, il risultato sarà la loro somma.\n\nPer questo motivo l'ISA si può considerare il _primo livello di **astrazione**_ dell'informatica.\n\nMeglio ancora, c'è qualcuno che automatizza questo processo di astrazione.\n\nIl compito dell'**assembler** è quello di tradurre gli algoritmi definiti dall'ISA in nomi standard e compatti, che insieme formano il _linguaggio **Assembly**_.","x":-1900,"y":3420,"width":720,"height":800,"color":"4"},
		{"id":"7724895a9f26e30f","type":"text","text":"# Fabbricare un Chip\n\nmanufacture of a chip begins with silicon semiconductor. add materials to silicon that allow tiny areas to transform into\n\n- Excellent conductors (copper, aluminum)\n- Excellent insulators (plastic, glass)\n- conduct or insulate under specific conditions (transistor)\n\nTransistors fall into the last category process starts with silicon crystal ingot finely sliced into wafers then patterns of chemicals are placed on each wafer, creating the transistors, conductors, and insulators\n\nToday’s integrated circuits contain only one layer of transistors but may have from two to eight levels of metal conductor, separated by layers of insulators\n\nmicroscopic flaw in the wafer can result in failing. simplest way to cope with imperfection is to place many independent components on a single wafer\n\npatterned wafer is *diced*, Dicing enables you to discard only dies that contain the flaws ((**yield**: percentage of good dies))\n\nThe cost of an integrated circuit rises quickly as the die size increases\n$$\nCost\\,per\\,die = \\frac{Cost\\,per\\,wafer}{Dies\\,per\\,wafer\\times yield}\n$$\n$$\nDies\\,per\\,wafer) \\simeq \\frac{Wafer\\,area}{Die\\,area}\n$$\n\n$$\nyield = \\frac{1}{(1 + (Defects\\,per\\,area \\times Die\\,area/2))^2}\n$$\n\nThe final equation is based on empirical observations","x":4451,"y":1320,"width":920,"height":1080},
		{"id":"a46ca09fa4d7ec52","type":"text","text":"## Parallelism\n\nthe programmer must divide an application so that each processor has roughly the same amount to do at the same time, and that the overhead of scheduling and coordination doesn’t fritter away the potential performance benefits of parallelism  schedule the sub-tasks balance the load.\n\nfalls short if conclusion (of operation) , couldn’t be written until all the other parts were completed. care must be taken to reduce communication and synchronization overhead.","x":5571,"y":2885,"width":817,"height":240},
		{"id":"35873d0873f6009a","type":"text","text":"il libro di tutto questo cita solo Amdahl ma fa sempre bene rileggere","x":5106,"y":3005,"width":250,"height":120},
		{"id":"5ee91b04fb136a01","type":"text","text":"# Benchmark\n\nda capire se è una conseguenza del parallelismo (cioè se in uniprogramming sai predire le performance in modo preciso e qui no).\n\nto evaluate a new computer, set of benchmarks (programs specifically chosen to measure performance form a workload (A set of programs run on a computer) that the user hopes will predict the performance of the actual workload.\n\nSPEC (System Performance Evaluation Cooperative) creates standard sets of benchmarks for modern computer systems\n\nDividing the execution time of a reference processor by the execution time of the evaluated computer normalizes the execution time measurements. bigger numeric results indicate faster performance. SPECratio is inverse of execution time. A summary is obtained by taking the geometric mean of the SPECratios (why????) apply the geometric mean so that it gives the same relative answer no matter what computer is used to normalize the results (why???).\n\nQua lui fa la media geometrica di \"*execution time ratio$_i$*\". non sono sicuro di capire cosa significa...\n\nle pagine successive le definisco \"oscure\" (pag 48 del pdf)","x":5571,"y":3175,"width":817,"height":510},
		{"id":"f9becf64c2d6e92f","type":"file","file":"Demetrescu/Ottimizzazione.txt","x":5031,"y":3230,"width":400,"height":400},
		{"id":"e4cd21ce4fcc8e29","type":"text","text":"# Power Efficiency\n\nclock rate and power are correlated. power provides a limit to what we can cool. energy metric joules is a better measure than a power rate like watts. integrated circuits CMOS (complementary metal oxide semiconductor energy consumption (is so-called dynamic energy) is consumed when transistors switch states from 0 to 1 and vice versa. dall'equazione dell'energia immagazzinata in u condensatore ricavo che power required per transistor\n$$\nP \\propto \\frac{1}{2} CV^2\\cdot f\n$$\n\ndove $f$ è la Frequency, function of the clock rate. C is function of number of transistors connected to an output (fanout (?????????)) and *technology* qualsiasi cosa voglia dire...\n\nEnergy and thus power can be reduced by lowering the voltage. In 20 years, voltages have gone from 5 V to 1 V. modern problem is that further lowering of the voltage appears to make the\ntransistors too leaky 40% of the power consumption in server chips is due to leakage.\nto address the power problem turn off parts of the chip that are not used in a given clock cycle.\nthere are many more expensive ways to cool chips, but generally too costly.\n\nleakage current flows even when a transistor is off 40% of the energy consumption increasing the number of transistors increases power dissipation hard to lower voltage further\n\nSunto: \n- power must be brought in and distributed around the chip\n - power is dissipated as heat and must be removed","x":6491,"y":2885,"width":817,"height":920},
		{"id":"78b3395d6c378f86","type":"file","file":"Capitolo 1/PowerAndClockRate.png","x":7531,"y":3405,"width":806,"height":340},
		{"id":"e71d455138a8e246","type":"text","text":"# Storia\n##### Incompleta, se proprio vuoi perdere tempo pagina 54 del pdf\n\nworld’s first\ncomputer.\nENIAC\nElectronic\nNumerical Integrator and Calculator\n\n1900 additions\nper second.\nprovided conditional jumps and was programmable\nmanually by\nplugging cables and setting switches\nvon Neumann helped crystallize the ideas and wrote a\nmemo\nbasis for the\nterm von Neumann compute\nEDSAC (Electronic Delay Storage Automatic\nCalculator)\n1949","x":7551,"y":2245,"width":441,"height":792},
		{"id":"100ff872e0aa5955","type":"text","text":"execution time is the product of the three factors in this table: instruction count in billions, clocks per instruction (CPI), and clock cycle time in\nnanoseconds. SPECratio is simply the reference time, which is supplied by SPEC (di un processore di riferimento che non so quale sia, probabilente è vecchio), divided by the measured execution time. The single number\nquoted as SPECINTC2006 is the geometric mean of the SPECratios.","x":6344,"y":4307,"width":706,"height":193},
		{"id":"a397c5d67ebfce21","type":"file","file":"Capitolo 1/BenchmarksSPEC.png","x":5641,"y":4127,"width":623,"height":300},
		{"id":"efecee1b85d4d14d","type":"text","text":"# Architettura","x":-1662,"y":3020,"width":244,"height":65,"color":"6"},
		{"id":"20a4b8a4ba668db7","type":"text","text":"# Linguaggio dell'Hardware","x":-1750,"y":3240,"width":420,"height":50,"color":"6"},
		{"id":"16abd413d233f637","type":"text","text":"# Hardware","x":-1642,"y":2780,"width":205,"height":50,"color":"6"},
		{"id":"3cfb69272e86d401","type":"text","text":"# CPU","x":-2340,"y":3240,"width":125,"height":50,"color":"6"},
		{"id":"afb57d55a3a9456a","type":"text","text":"# Registri\n\nGli operandi devono provenire da un numero limitato di posizioni speciali costruite direttamente nell'hardware chiamate registri. La dimensione di un registro in RISC-V è di 64 bit (doubleword, 32 bit chiamati word), con un numero limitato di registri, tipicamente 32. Il dettato è: più piccolo è più veloce.\n\nUn grande numero di registri potrebbe aumentare il tempo del ciclo di clock: i segnali elettronici devono viaggiare più lontano. Ma 31 registri potrebbero non essere più veloci di 32. Bisogna bilanciare il desiderio dei programmi di avere più registri con il desiderio del progettista di mantenere veloce il ciclo di clock.\n\nLa convenzione RISC-V è _x_ seguito dal numero del registro, ad eccezione di alcuni nomi di registro.\n\nIl processore può mantenere solo una piccola quantità di dati nei registri. Array e strutture vengono mantenuti in memoria e RISC-V deve includere istruzioni che trasferiscono dati tra memoria e registri (istruzioni di trasferimento dati). Deve fornire l'indirizzo di memoria. La memoria è solo un grande array unidimensionale, con l'indirizzo che agisce come indice di quell'array, a partire da 0.","x":-3260,"y":2830,"width":580,"height":680},
		{"id":"181cc23557388283","type":"text","text":"## Filosofia di scrittura per ISA\n\nSi può implementare un ISA focalizzando l'attenzione sulle prestazioni o sul programmatore, a cui fanno seguito due \"correnti di pensiero\".\n\n- **RISC** (Reduced Instruction Set Computing): fornisce un ISA minimale formato da operazioni semplici e veloci. L'obiettivo è un controllo fine sulle prestazioni;\n- **CISC** (Complex Instruction Set Computing): fornisce un ISA più ricco formato da operazioni più lente e complesse. L'obiettivo è scrivere meno codice possibile;","x":-840,"y":2940,"width":480,"height":400,"color":"4"},
		{"id":"f00b04df665e4e06","type":"text","text":"## Nota sul termine\nPer *Architettura* si intende in gergo sia la struttura fisica dell'HW (e.g. dimensione del bus, numero di registri, ...) sia l'ISA ad esso associato.","x":-1330,"y":2978,"width":440,"height":150,"color":"4"},
		{"id":"8c3e31c10fa045d8","type":"text","text":"###### Istruzione di salto: ISA (IA-32)\n\nAltera il _flusso normale_ (e.g. dopo l'istruzione $n$ viene quella $n+1$) scrivendo nel *Program Counter* un _indirizzo_ (o un'_etichetta_) definito dal programmatore contenente la nuova prossima istruzione da eseguire.\n\nA livello HW devono avvenire diversi step.\n- Prendo l'istruzione dalla memoria e la decodifico;\n- La CPU calcola l'indirizzo e lo mette nel PC;\n- Recupero l'istruzione al nuovo indirizzo;\n- Eseguo e riparte il flusso normale.\n\nQuesto algoritmo, ovviamente, deve essere espresso in linguaggio macchina.","x":-1099,"y":3800,"width":480,"height":420,"color":"4"},
		{"id":"1c60be0dd5ff281e","type":"text","text":"##### Istruzione di salto: Assembly (IA-32) \n\n\tJMP <indirizzo>\n\tJMP <etichetta>\n\n$\\Rightarrow$ Un'istruzione Assembly corrisponde a una sequenza di operazioni (definite dall'ISA sottostante) che il processore deve eseguire.","x":-600,"y":3800,"width":240,"height":420,"color":"4"},
		{"id":"2fc7aea1295a65e4","type":"text","text":"# Tipi di ISA...","x":-981,"y":3570,"width":245,"height":60,"color":"6"},
		{"id":"ef76980f9cea6e22","type":"text","text":"## RISC vs MIPS","x":278,"y":4480,"width":250,"height":60},
		{"id":"89901351b69f4ba9","type":"text","text":"# Commenti a caso che non so dove mettere, edizione capitolo 2\n\nDesign Principle 1: Simplicity favors regularity.\n\n\nPer quanto oggi possa sembrare ovvio, il funzionamento dei computer si basa sul cosiddetto *Stored-Program Concept*, ovvero sull'idea che istruzioni e dati possono essere conservati in memoria sotto forma di numeri.","x":1120,"y":1751,"width":720,"height":700},
		{"id":"94b4618bbb47c1fa","type":"file","file":"Demetrescu/IA-32.txt","x":-840,"y":2580,"width":480,"height":320,"color":"4"},
		{"id":"48b5a89e36d2e078","type":"text","text":"questa roba è utilissima (ovviamente), sta un po' a cavallo tra i due capitoli","x":760,"y":1751,"width":250,"height":140},
		{"id":"c5d920fa7babd150","type":"file","file":"Demetrescu/pipelining.txt","x":700,"y":1901,"width":400,"height":400},
		{"id":"41f1b1a58ee74373","type":"text","text":"# Operandi dell'architettura: i registri\n\noperands must be from a limited number of special locations built directly in hardware called registers. size of a register in RISC-V is 64 bits (doubleword, 32 bits called a word)  limited number of registers, typically 32.\nDiktat: Smaller is faster\nlarge number of registers may increase the clock cycle time: electronic signals must travel farther. but 31 registers may not be\nfaster than 32. must balance the craving of programs for more registers with the designer’s desire to keep the clock cycle fast. \n\nRISC-V convention is *x* followed by the number of the register, except for a few register names.\n\nprocessor can keep only a small amount of data in registers. Arrays and structures are kept in memory RISC-V must include instructions that transfer data between memory and registers (**data transfer instruction**). must supply the memory address.\nMemory is just a large, single-dimensional array, with the address acting as the index to that array, starting at 0","x":-3920,"y":2830,"width":580,"height":710},
		{"id":"6a1f44f4ce649afe","type":"text","text":"## ... e prima dei linguaggi HDL??\n\nPrima si faceva tutto a mano.\n\nPur essendo nati sul finire degli anni '60, non erano né efficienti né popolari. Solo con Verilog e VHDL, verso metà degli anni '80, la tecnica ha iniziato a diffondersi.\n\nVa sottolineato che anche oggi la progettazione può ancora richiedere del lavoro non automatizzato.","x":-840,"y":2260,"width":480,"height":280,"color":"4"},
		{"id":"0707ec4b5b023109","type":"text","text":"# ... ovvero tipi di Assembly\n\nDiverse implementazioni del vocabolario HW (ISA) definiscono diversi linguaggi, che prendono tutti il nome di ***Assembly***.\n\nIn pratica, se l'HW \"vive\" nel dominio della fisica e l'ISA è una descrizione logico-matematica delle operazioni supportate dall'HW, con l'Assembly si entra per la prima volta nell'implementazione informatica.\n\nLa corrispondenza però non è biunivoca.\n\nA una stessa ISA possono corrispondere più sintassi Assembly, vedi ad esempio\n- x86\n\t- Sintassi Intel\n\t- Sintassi AT&T\n- ARM\n\t- Sintassi ARM (Developer)\n\t- Sintassi GAS (GNU Assembler)\n- MIPS\n\t- MIPS32 Assembly\n\t- SPIM\n\nSeguono esempi di ISA/Assembly (perché in pratica poi la gente usa questi due termini in modo intercambiabile).","x":-260,"y":3420,"width":420,"height":800,"color":"4"},
		{"id":"b7bcea7f39de9f04","type":"text","text":"# x86\n\nArchitettura **CISC** introdotta nel 1978 da **Intel** con il processore **8086** a 16 bit, poi estesa a 32 bit nel 1985 con l'80386 che ha introdotto lo storico ISA **IA-32**.\n\nI processori x86 sono utilizzati nei computer desktop (personal computer), nei server e nelle workstation.\n\nIn un mercato rimasto per decenni sotto la totale egemonia di Intel, nel 1991 **AMD** (precedentemente produttore subordinato a Intel stessa) lancia il proprio **Am386** basato su x86, diventando sostanzialmente primo e unico competitor di Intel fino ad oggi.\n\nEd è AMD a portare avanti lo sviluppo di x86, introducendone nel 2003 l'estensione a 64 bit **AMD64** (detta anche **x64** o **x86-64**) con il processore **Opteron**, che presenta una modalità di retrocompatibilità con le istruzioni a 16 e 32 bit.\n\nIntel e HP avevano già provato a creare una propria estensione, IA-64, ma questa non era retrocompatibile, motivo per cui si sono accodati ad AMD64.\n\nMicrosoft è cliente affezionato di x86.","x":-260,"y":2580,"width":420,"height":760,"color":"4"},
		{"id":"82f17ecc160e067b","type":"text","text":"# Apple Silicon\n\nMenzione di merito per gli hipster dell'informatica. Nel corso della sua storia, Apple le ha provate un po' tutte.\n\nAll'inizio usava **Motorola 68k**, un'architettura CISC, poi è passata a una RISC chiamata **PowerPC** e nel 2006 ha optato per x86. Ha iniziato a usare i processori ARM nel 2007 con il primo iPhone, e deve essergli piaciuto, perché da là in poi hanno creato la loro sezione ricerca e sviluppo che ha prodotto l'architettura *ARM-based* **Silicon**, che a partire dal 2020 è tornata ad alimentare anche i dispositivi fissi e laptop.","x":-260,"y":2260,"width":923,"height":249,"color":"4"},
		{"id":"c4bef55d226d9f2d","type":"text","text":"# ARM\n\nArchitettura **RISC** nata nel 1985 come _Acorn RISC Machine_ dalla *Acorn Computers*, che nel 1990 forma una *joint venture* insieme a _VLSI Technology_ e **Apple** con lo scopo di perfezionarla (Apple mantiene l'acronimo ARM ma lo modifica in **Advanced RISC Machines** perché non gli andava molto a genio il nome della concorrenza in un progetto che finanziava). Diventa infine una società a sé stante, nota semplicemente come **ARM**.\n\nSi tratta di un'architettura poco energivora, e quindi particolarmente adatta a smartphone e tablet (è infatti utilizzata da praticamente tutti i produttori, da Apple a **Samsung** e **Huawei**), come pure a smartwatch, dispositivi *embedded* e di tipo *Internet of Things* (come *Raspberry Pi*).\n\nARM ha sviluppato nel tempo diverse ISA, volte principalmente a migliorare l'efficienza del codice e il consumo di memoria, ma soprattutto nel 2011 ha rilasciato la propria estensione a 64 bit, **ARMv8**, dando un forte impulso all'industria dei dispositivi portatili.\n\nAd oggi ARM non produce i propri processori, ma vende le licenze a terzi (Nvidia, Qualcomm, ...).","x":243,"y":2580,"width":420,"height":760,"color":"4"},
		{"id":"6f8dca31ed1e0112","type":"text","text":"# SPARC\n\nArchitettura RISC sviluppata da *Sun Microsystems*, oggi assorbita da **Oracle**, per server UNIX.\n\nMolto popolare fino agli anni 2000, ad oggi il suo uso è in calo a favore delle architetture x86 e ARM.","x":243,"y":3420,"width":420,"height":380,"color":"4"},
		{"id":"78004fb19f7d1705","type":"text","text":"# RISC-V\n\nRISC-V assembly add a, b, c add the two variables b and c and to put their sum in a. each RISC-V arithmetic instruction performs only one operation and must always have exactly three variables each line of this language can contain at most one instruction. comments always terminate at the end of a line. every instruction to have exactly three operands philosophy of keeping the hardware simple.\n32 registri, memory word Accessed only by data transfer instructions, RISC-V uses byte addresses, so sequential doubleword *\\[Tipicamente per word si intendono 32 bit e doubleword 64, e questo è un commento che fa dopo e che mi sembra incoerente con questa frase\\]* accesses differ by 8\n###### ChatGPT:\nRISC-V non è limitato esclusivamente a 64-bit. L'architettura RISC-V è stata progettata per essere modulare e flessibile, il che significa che può supportare sia sistemi a 32-bit che a 64-bit, così come altre possibili larghezze di bus o parole.\n\nLa specifica base di RISC-V definisce istruzioni per un'architettura a 32-bit, mentre le estensioni possono essere utilizzate per supportare larghezze di bus e parole diverse, inclusi 64-bit. Questa flessibilità è una delle ragioni per cui RISC-V è popolare in una vasta gamma di applicazioni, dalle microcontroller embedded ai server ad alte prestazioni.","x":-260,"y":4286,"width":420,"height":980},
		{"id":"5d905f6c8910912d","type":"text","text":"# Progettare l'Hardware\n\nCome costruisco in modo ottimale i circuiti all'interno delle varie componenti HW?\n\nCi sono dei linguaggi di progettazione come *Verilog* o *VHDL* (detti **HDL**, *Hardware Description Language*), che permettono di scrivere un codice descrittivo delle operazioni che dovrà eseguire la macchina, come ad esempio un'addizione con segno.\n\nAttraverso un software, detto di *sintesi*, viene prodotta a partire dal codice una mappa logica equivalente al codice, detta *netlist*, che presenta elementi come porte logiche, flip-flop e multiplexer.\n\nSeguono diversi step di ottimizzazione volti a ridurre la superficie occupata e massimizzare le prestazioni.\n\nInfine avviene il *mapping*, ovvero lo schema logico viene implementato tramite una data tecnologia (celle logiche per un *FPGA*, transistor per un *ASIC*).","x":-1330,"y":2260,"width":440,"height":640,"color":"4"},
		{"id":"f55cf6b29f22c43d","type":"text","text":"# MIPS\n\nStorica architettura RISC sviluppata da *MIPS Technologies* (ora parte di *Wave Computing*).\n\nUtilizzata per dispositivi *embedded* come router, ma anche per console di gioco (e.g. PlayStation2).\n\nLa sua popolarità è in calo, gli si preferiscono Assembly più moderni come RISC-V.","x":243,"y":3840,"width":420,"height":380,"color":"4"},
		{"id":"5b46158c20ea1d79","type":"file","file":"Capitolo 2/RISCvsMIPS.png","x":600,"y":4320,"width":307,"height":531},
		{"id":"c84a18acd87bdb46","type":"file","file":"Capitolo 2/x86vsRISCvsMIPS.png","x":960,"y":4346,"width":418,"height":480}
	],
	"edges":[
		{"id":"352324112e64b113","fromNode":"3c12a472e21d0b51","fromSide":"right","toNode":"70f63fa924d39f03","toSide":"left"},
		{"id":"b9f09ab23c605f65","fromNode":"e723e0fbc1846d02","fromSide":"left","toNode":"3c12a472e21d0b51","toSide":"top"},
		{"id":"02479a35015b5cf2","fromNode":"70f63fa924d39f03","fromSide":"right","toNode":"3f606618d45d0104","toSide":"bottom"},
		{"id":"7698822a27692414","fromNode":"3f606618d45d0104","fromSide":"top","toNode":"7c44d0b7fa4661bf","toSide":"left"},
		{"id":"d750fa4a8a142824","fromNode":"969e5ce3a6049ee4","fromSide":"top","toNode":"6264c0d982a44972","toSide":"bottom"},
		{"id":"fc5ded6ec491d93d","fromNode":"7c44d0b7fa4661bf","fromSide":"right","toNode":"94ebb589ac92b6e9","toSide":"left"},
		{"id":"51251623d685e714","fromNode":"94ebb589ac92b6e9","fromSide":"right","toNode":"46ee857cb70eed15","toSide":"left"},
		{"id":"a7eafeb6c8c346f7","fromNode":"46ee857cb70eed15","fromSide":"right","toNode":"969e5ce3a6049ee4","toSide":"left"},
		{"id":"2812fd451c957750","fromNode":"94ebb589ac92b6e9","fromSide":"bottom","toNode":"7724895a9f26e30f","toSide":"top"},
		{"id":"f496ae47111d27c9","fromNode":"7724895a9f26e30f","fromSide":"right","toNode":"e4506d54dcf914ea","toSide":"left"},
		{"id":"99d0c42d87f2952f","fromNode":"e4506d54dcf914ea","fromSide":"right","toNode":"dfd2890763a0d962","toSide":"left"},
		{"id":"66d451b3dd1158ac","fromNode":"dfd2890763a0d962","fromSide":"bottom","toNode":"e4cd21ce4fcc8e29","toSide":"top"},
		{"id":"a195332ee9782da8","fromNode":"e4cd21ce4fcc8e29","fromSide":"right","toNode":"78b3395d6c378f86","toSide":"left"},
		{"id":"58858eb02c3845e0","fromNode":"a397c5d67ebfce21","fromSide":"right","toNode":"100ff872e0aa5955","toSide":"left"},
		{"id":"5c08edf34c14e11e","fromNode":"5ee91b04fb136a01","fromSide":"bottom","toNode":"a397c5d67ebfce21","toSide":"top"},
		{"id":"cb68dd135ac37fa6","fromNode":"e4cd21ce4fcc8e29","fromSide":"left","toNode":"a46ca09fa4d7ec52","toSide":"right"},
		{"id":"5a8f2417660fbab0","fromNode":"a46ca09fa4d7ec52","fromSide":"bottom","toNode":"5ee91b04fb136a01","toSide":"top"},
		{"id":"6977e7d4fb7b4066","fromNode":"5ee91b04fb136a01","fromSide":"left","toNode":"f9becf64c2d6e92f","toSide":"right"},
		{"id":"d5006d3c292b2549","fromNode":"f9becf64c2d6e92f","fromSide":"top","toNode":"35873d0873f6009a","toSide":"bottom"},
		{"id":"9b0641f0e1a9b609","fromNode":"20a4b8a4ba668db7","fromSide":"bottom","toNode":"e1323ed7fa9295aa","toSide":"top"},
		{"id":"d508e5541dc47a7d","fromNode":"16abd413d233f637","fromSide":"left","toNode":"3cfb69272e86d401","toSide":"right"},
		{"id":"f1fb8ac7b3414ea9","fromNode":"efecee1b85d4d14d","fromSide":"top","toNode":"16abd413d233f637","toSide":"bottom"},
		{"id":"46efe16780ffdfc7","fromNode":"efecee1b85d4d14d","fromSide":"bottom","toNode":"20a4b8a4ba668db7","toSide":"top"},
		{"id":"f858eed49274173b","fromNode":"16abd413d233f637","fromSide":"bottom","toNode":"efecee1b85d4d14d","toSide":"top"},
		{"id":"d684531186819afb","fromNode":"20a4b8a4ba668db7","fromSide":"top","toNode":"efecee1b85d4d14d","toSide":"bottom"},
		{"id":"95f160da0ff4c8a4","fromNode":"e1323ed7fa9295aa","fromSide":"right","toNode":"2fc7aea1295a65e4","toSide":"left"},
		{"id":"34aa5ae3bd520c15","fromNode":"2fc7aea1295a65e4","fromSide":"right","toNode":"0707ec4b5b023109","toSide":"left"},
		{"id":"457d735ff4c79713","fromNode":"8c3e31c10fa045d8","fromSide":"right","toNode":"1c60be0dd5ff281e","toSide":"left"},
		{"id":"0285343dfd80b766","fromNode":"0707ec4b5b023109","fromSide":"bottom","toNode":"78004fb19f7d1705","toSide":"top"},
		{"id":"ca12efab1db9458e","fromNode":"e1323ed7fa9295aa","fromSide":"left","toNode":"3cfb69272e86d401","toSide":"bottom"},
		{"id":"285b5aabbfe7cf08","fromNode":"3cfb69272e86d401","fromSide":"left","toNode":"afb57d55a3a9456a","toSide":"right"},
		{"id":"e5a344f0f86469d2","fromNode":"2fc7aea1295a65e4","fromSide":"top","toNode":"181cc23557388283","toSide":"bottom"},
		{"id":"342f8296ad8dcd8c","fromNode":"efecee1b85d4d14d","fromSide":"right","toNode":"f00b04df665e4e06","toSide":"left"},
		{"id":"712c4a87e670c777","fromNode":"e1323ed7fa9295aa","fromSide":"right","toNode":"8c3e31c10fa045d8","toSide":"left"},
		{"id":"e5d44beb7317a2f0","fromNode":"1c60be0dd5ff281e","fromSide":"right","toNode":"0707ec4b5b023109","toSide":"left"},
		{"id":"3f2b159ecf7882f5","fromNode":"0707ec4b5b023109","fromSide":"top","toNode":"b7bcea7f39de9f04","toSide":"bottom"},
		{"id":"9b850d7643080984","fromNode":"b7bcea7f39de9f04","fromSide":"left","toNode":"94b4618bbb47c1fa","toSide":"right"},
		{"id":"f6febe9b41eb394f","fromNode":"0707ec4b5b023109","fromSide":"top","toNode":"c4bef55d226d9f2d","toSide":"bottom"},
		{"id":"579229ba29426824","fromNode":"c4bef55d226d9f2d","fromSide":"top","toNode":"82f17ecc160e067b","toSide":"bottom"},
		{"id":"57f4f21a68f74a12","fromNode":"16abd413d233f637","fromSide":"right","toNode":"5d905f6c8910912d","toSide":"left"},
		{"id":"112f13888106b5bf","fromNode":"5d905f6c8910912d","fromSide":"right","toNode":"6a1f44f4ce649afe","toSide":"left"},
		{"id":"1f7bd9286ec299ba","fromNode":"0707ec4b5b023109","fromSide":"right","toNode":"6f8dca31ed1e0112","toSide":"left"},
		{"id":"a99a4013df708a3a","fromNode":"0707ec4b5b023109","fromSide":"right","toNode":"f55cf6b29f22c43d","toSide":"left"}
	]
}
{
	"nodes":[
		{"id":"e1323ed7fa9295aa","type":"text","text":"# Instruction Set Architecture (ISA)\n\nL'ISA può essere visto come un vocabolario delle operazioni eseguibili dall'HW.\n*Tendenzialmente*, a diversi HW corrispondono diversi ISA, ma è possibile\n- costruire ISA diversi sullo stesso HW;\n- costruire un ISA compatibile con diversi HW.\n\nE' probabile trovare ISA molto simili tra loro, perché tutti i computer\n- sono costruiti a partire principi di funzionamento simili (e.g. ci sono sempre dei registri, della memoria in cui tenere i dati che non entrano nei registri, ...);\n- necessitano almeno di un insieme standard di operazioni di base (e.g. addizione, lettura da memoria, ...).\n\nA livello pratico, l'ISA definisce alcuni algoritmi in linguaggio macchina che hanno come risultati operazioni più complesse come\n- operazioni aritmetico-logiche (e.g. sommare due numeri);\n- spostamento di dati tra registri, o tra registri e memoria;\n- istruzioni di salto (e.g. alterazione del _flusso normale_);\n- ...\n\nPotremmo chiamare uno di questi algoritmi *somma*, o *moltiplicazione*, e ignorare completamente i dettagli implementativi. L'ISA mi garantisce che se all'algoritmo *somma* do' in pasto due numeri, il risultato sarà la loro somma.\n\nPer questo motivo l'ISA si può considerare il _primo livello di **astrazione**_ dell'informatica.\n\nMeglio ancora, c'è qualcuno che automatizza questo processo di astrazione.\n\nIl compito dell'**assembler** è quello di tradurre gli algoritmi definiti dall'ISA in nomi standard e compatti, che insieme formano il _linguaggio **Assembly**_.","x":-1900,"y":3420,"width":720,"height":800,"color":"4"},
		{"id":"181cc23557388283","type":"text","text":"# Filosofia di scrittura per ISA\n\nSi può implementare un ISA focalizzando l'attenzione sulle prestazioni o sul programmatore, a cui fanno seguito due \"correnti di pensiero\".\n\n- ***RISC*** (**Reduced Instruction Set Computing**): fornisce un ISA minimale formato da operazioni semplici e veloci. L'obiettivo è un controllo fine sulle prestazioni.\n\t- Le **istruzioni** sono di **dimensione (lunghezza) fissa**. AGGIUNGI COMMENTO FETCH\n\t- Se voglio recuperare un valore dalla memoria per metterlo in un registro, esistono delle operazioni *ad-hoc*. Se invece voglio eseguire un'operazione che coinvolge la ALU (e.g. somma, moltiplicazione, ...), gli operandi devono essere già nei registri. **_Non_** posso usare A come operando per la ALU se A è in memoria al momento dell'esecuzione dell'istruzione ($\\Rightarrow$ **non sono ammessi operandi a memoria**);\n\t- Conseguentemente la CPU è dotata di **molti registri interni**;\n\t- Modi di indirizzamento semplici ?????????????\n- ***CISC*** (**Complex Instruction Set Computing**): fornisce un ISA più ricco formato da operazioni più lente e complesse. L'obiettivo è scrivere meno codice possibile.\n\t- **Istruzioni** di **dimensione variabile** (NO PARALLELISMO IN FASE FETCH);\n\t- **Sono ammessi operandi a memoria** (e quindi gli accessi sono più frequenti);\n\t- Conseguentemente vi sono **pochi registri interni**;\n\t- Modi di indirizzamento più complessi???????????????","x":-1099,"y":2700,"width":739,"height":640,"color":"3"},
		{"id":"0707ec4b5b023109","type":"text","text":"# ... ovvero tipi di Assembly\n\nSegue che diverse implementazioni del vocabolario HW (ISA) definiscono diversi linguaggi, che prendono tutti il nome di ***Assembly***.\n\nIn pratica, se l'HW \"vive\" nel dominio della fisica e l'ISA è una descrizione logico-matematica delle operazioni supportate dall'HW, con l'Assembly ($\\Rightarrow$ con il linguaggio macchina) si entra nell'implementazione informatica.\n\nAd una stessa ISA possono corrispondere più **_sintassi_** Assembly, vedi ad esempio\n- x86\n\t- Sintassi Intel\n\t- Sintassi AT&T\n- ARM\n\t- Sintassi ARM (Developer)\n\t- Sintassi GAS (GNU Assembler)\n- MIPS\n\t- MIPS32 Assembly\n\t- SPIM\n\nSeguono esempi di ISA/Assembly (perché in pratica poi la gente usa questi due termini in modo intercambiabile).","x":-260,"y":3420,"width":420,"height":800,"color":"4"},
		{"id":"17667cee3c12cf49","type":"text","text":"# Parlare con l'Hardware - Storia dell'Assembly\n\nIl modo più semplice per comunicare con un sistema elettronico è la far passare (*on*) o meno (*off*) corrente attraverso un componente, traducibile a livello logico con il sistema binario (le cui cifre sono dette **_bit_**) e con l'algebra booleana.\n\nA seconda di come vengono progettate, le componenti di un calcolatore si differenziano per le reazioni alle sequenze di 0 ed 1 che gli vengono impartite ($\\Rightarrow$ sono funzioni). Tali sequenze vengono dette **_istruzioni_** ($\\Rightarrow$ sono gli input di tali funzioni).\n\nI primi programmatori scrivevano direttamente le sequenze corrispondenti alle istruzioni in binario (e.g. `1000110010100000` è un'istruzione di somma).\n\nEssendo un processo estremamente complesso, laborioso e soggetto a errori, a qualcuno venne l'idea di **utilizzare i calcolatori stessi per programmare altri calcolatori**, ovvero di automatizzare la traduzione delle operazioni concettuali, scritte in **notazione simbolica**, in vere e proprie istruzioni.\n\nTali programmi vengono detti **_assemblatori_** (e.g. alla notazione simbolica `add` l'assemblatore associa l'istruzione macchina `1000110010100000`).\n\nIl linguaggio simbolico derivante viene detto **_Linguaggio Assembler_** (o **_Assembly_**).","x":-1900,"y":2700,"width":720,"height":640,"color":"4"},
		{"id":"20a4b8a4ba668db7","type":"text","text":"# Linguaggio dell'Hardware","x":-1750,"y":2588,"width":420,"height":50,"color":"6"},
		{"id":"1c60be0dd5ff281e","type":"text","text":"##### Istruzione di salto: Assembly (IA-32) \n\n\tJMP <indirizzo>\n\tJMP <etichetta>\n\n$\\Rightarrow$ Un'istruzione Assembly corrisponde a una sequenza di operazioni (definite dall'ISA sottostante) che il processore deve eseguire.","x":-600,"y":3800,"width":240,"height":420,"color":"4"},
		{"id":"8c3e31c10fa045d8","type":"text","text":"###### Istruzione di salto: ISA (IA-32)\n\nAltera il _flusso normale_ (e.g. dopo l'istruzione $n$ viene quella $n+1$) scrivendo nel *Program Counter* un _indirizzo_ (o un'_etichetta_) definito dal programmatore contenente la nuova prossima istruzione da eseguire.\n\nA livello HW devono avvenire diversi step.\n- Prendo l'istruzione dalla memoria e la decodifico;\n- La CPU calcola l'indirizzo e lo mette nel PC;\n- Recupero l'istruzione al nuovo indirizzo;\n- Eseguo e riparte il flusso normale.\n\nQuesto algoritmo, ovviamente, deve essere espresso in linguaggio macchina.","x":-1099,"y":3800,"width":480,"height":420,"color":"4"},
		{"id":"2fc7aea1295a65e4","type":"text","text":"# Tipi di ISA...","x":-852,"y":3520,"width":245,"height":60,"color":"6"},
		{"id":"f55cf6b29f22c43d","type":"text","text":"# MIPS\n\nAcronimo di **_Microprocessor without Interlocked Pipelined Stages_**.\nStorica architettura RISC sviluppata da *MIPS Technologies* (ora parte di *Wave Computing*).\n\nUtilizzata per dispositivi *embedded* come router, ma anche per console di gioco (e.g. PlayStation2).\n\nLa sua popolarità è in calo, gli si preferiscono Assembly più moderni come RISC-V.","x":243,"y":3420,"width":420,"height":380,"color":"4"},
		{"id":"6f8dca31ed1e0112","type":"text","text":"# SPARC\n\nArchitettura RISC sviluppata da *Sun Microsystems*, oggi assorbita da **Oracle**, per server UNIX.\n\nMolto popolare fino agli anni 2000, ad oggi il suo uso è in calo a favore delle architetture x86 e ARM.","x":243,"y":3840,"width":420,"height":380,"color":"4"},
		{"id":"b7bcea7f39de9f04","type":"text","text":"# x86\n\nArchitettura **CISC** introdotta nel 1978 da **Intel** con il processore **8086** a 16 bit, poi estesa a 32 bit nel 1985 con l'80386 che ha introdotto lo storico ISA **IA-32**.\n\nI processori x86 sono utilizzati nei computer desktop (personal computer), nei server e nelle workstation.\n\nIn un mercato rimasto per decenni sotto la totale egemonia di Intel, nel 1991 **AMD** (precedentemente produttore subordinato a Intel stessa) lancia il proprio **Am386** basato su x86, diventando sostanzialmente primo e unico competitor di Intel fino ad oggi.\n\nEd è AMD a portare avanti lo sviluppo di x86, introducendone nel 2003 l'estensione a 64 bit **AMD64** (detta anche **x64** o **x86-64**) con il processore **Opteron**, che presenta una modalità di retrocompatibilità con le istruzioni a 16 e 32 bit.\n\nIntel e HP avevano già provato a creare una propria estensione, IA-64, ma questa non era retrocompatibile, motivo per cui si sono accodati ad AMD64.\n\nMicrosoft è cliente affezionato di x86.","x":-260,"y":4340,"width":420,"height":760,"color":"4"},
		{"id":"c4bef55d226d9f2d","type":"text","text":"# ARM\n\nArchitettura **RISC** nata nel 1985 come _Acorn RISC Machine_ dalla *Acorn Computers*, che nel 1990 forma una *joint venture* insieme a _VLSI Technology_ e **Apple** con lo scopo di perfezionarla (Apple mantiene l'acronimo ARM ma lo modifica in **Advanced RISC Machines** perché non gli andava molto a genio il nome della concorrenza in un progetto che finanziava). Diventa infine una società a sé stante, nota semplicemente come **ARM**.\n\nSi tratta di un'architettura poco energivora, e quindi particolarmente adatta a smartphone e tablet (è infatti utilizzata da praticamente tutti i produttori, da Apple a **Samsung** e **Huawei**), come pure a smartwatch, dispositivi *embedded* e di tipo *Internet of Things* (come *Raspberry Pi*).\n\nARM ha sviluppato nel tempo diverse ISA, volte principalmente a migliorare l'efficienza del codice e il consumo di memoria, ma soprattutto nel 2011 ha rilasciato la propria estensione a 64 bit, **ARMv8**, dando un forte impulso all'industria dei dispositivi portatili.\n\nAd oggi ARM non produce i propri processori, ma vende le licenze a terzi (Nvidia, Qualcomm, ...).","x":243,"y":4340,"width":420,"height":760,"color":"4"},
		{"id":"82f17ecc160e067b","type":"text","text":"# Apple Silicon\n\nMenzione di merito per gli hipster dell'informatica. Nel corso della sua storia, Apple le ha provate un po' tutte.\n\nAll'inizio usava **Motorola 68k**, un'architettura CISC, poi è passata a una RISC chiamata **PowerPC** e nel 2006 ha optato per x86. Ha iniziato a usare i processori ARM nel 2007 con il primo iPhone, e deve essergli piaciuto, perché da là in poi hanno creato la loro sezione ricerca e sviluppo che ha prodotto l'architettura *ARM-based* **Silicon**, che a partire dal 2020 è tornata ad alimentare anche i dispositivi fissi e laptop.","x":-260,"y":5180,"width":923,"height":249,"color":"4"},
		{"id":"94b4618bbb47c1fa","type":"file","file":"Demetrescu/IA-32.txt","x":-1099,"y":4340,"width":739,"height":50,"color":"4"},
		{"id":"efecee1b85d4d14d","type":"text","text":"# Architettura\n\nPer *Architettura* si intende in gergo sia la struttura fisica dell'HW (e.g. dimensione del bus, numero di registri, ...) sia l'ISA (*vocabolario*) ad esso associato.","x":-1750,"y":2285,"width":420,"height":180,"color":"6"},
		{"id":"a83c4681e122399d","type":"text","text":"# Architettura MIPS","x":-899,"y":2350,"width":340,"height":50,"color":"6"},
		{"id":"d6a444107be393e2","type":"text","text":"# MIPS Assembly","x":-196,"y":2995,"width":293,"height":50,"color":"6"},
		{"id":"6df8e8451dd5d9b7","type":"text","text":"# slides 2 cpu MIPS\n\nclock = onde quadre (circa), quando mando tensione alta i circuiti lo sentono e cambiano stato, al contrario nulla. Do impulso di tensione e il circuito reagisce e si assesta (riempie i condensatori, ...). Se troppo veloce non ho tempo di assestarmi (e il risultato è imprevedibile)! Output della logica combinatoria (istruzioni) è un cambio di stato, che viene messo in pratica al successivo impulso di tensione. Diversi circuiti hanno diversi tempi di assestamento.\n\nCPU usa complemento a 2 perché ottimizzato per le somme (e sottrazioni) con segno. Come la posizionale classica ma il bit più significativo è pesato con $-2^{32}$. In pratica è un bit del segno. Piccolo problema: se uso 16 bit? Devo estendere ll bit del segno (bit più significativo dei 16, vedi movs e movz! per questo con gli unsigned basta mettere tutti zeri).\n\nper passare da x a -x flippo tutti i bit e aggiungo 1 (perché in complemento a 2 x + $x_{invertito}$ = -1). Segue che le sottrazioni sono x -> -x e poi somme.\n\nIEEE754 standard notazione scientifica per i float (8 bit exp, 1 bit segno, 23 bit mantissa)\n\n","x":2941,"y":5167,"width":740,"height":560},
		{"id":"fee11152a0da7dfa","type":"text","text":"# slides 1\n\nx0 registro di soli zeri (velocizza, tipo per copia e inclolla)\n\nin ias c'erano 40 bit e istruzioni sinistra e destra (opcode+address 2 volte). Opcode Opcode identifica operazione (è un dato? indirizo?)\n\nspesso succede di avere più indirizzi di quelli che poi si addressano (permette sviluppi futuri). con gli ip non ci hanno pensato ed è finita male quando ne sono seviti altri\n\nguarda slides per l'architettura IAS\n\nMBD carico roba dalla memoria per poi mandarla in cpu\n\nMAR salva indirizzo RAM per qualsiasi istruzione (+PC indirizzo del programma+ IR)\nSe eseguo operazione di lettura alla riga 0 il PC resta 0 e l'indirizzo RAM va in MAR.\nIR è il pezzo di istruzione circa l'istruzione da eseguire, dal MAR\nAC si chiama così perché è operazione comune somma ricorrente\nMQ stesso con moltiplicazione\n\nPoi passa tutto al controllo che parla con ALU & co\n\nSeguono istruzioni trasferimento (registri-memoria). A ogni istruzione corrisponde una circuiteria ad hoc. Aggiungere istruzioni corrisponde ad aggiungere HW. Se faccio risc mi voglio ricondurre a operazioni sempllci\n\nFetching: il PC dice al MAR oh vai a prendere la mia istruzione, quello lo prende e lo splitta in IR e IBR. Opcode= devi caricare 101 e metterlo in AC; address: 101. L'opcode finisce in IR, che lo dice alla CU, la quale lo dice alla ALU che esegue.\n\n\n\n","x":2941,"y":4347,"width":740,"height":700},
		{"id":"500dd90d04313081","type":"text","text":"# Commenti a caso che non so dove mettere (da qualche parte qui vicino)\n\nMoore’s Law integrated circuit resources double every 18–24 months computer designs can take years resources can easily double between the start and finish computer architects must anticipate where the technology will be when the design finishes  \n\n\n\nfive classic components of a computer are input, output, memory,\ndatapath, and control, with the last two sometimes combined and called\nthe processor\n\n\nExecution time is the only valid and unimpeachable measure of\nperformance. Many other metrics have been proposed and found wanting.\nSometimes these metrics are flawed from the start by not reflecting\nexecution time; other times a metric that is sound in a limited context\nis extended and used beyond that context or without the additional\nclarification needed to make it valid.\n\n\nmillion instructions per second (MIPS) A measurement of program execution speed based on the number of millions of instructions. \n$$\nMIPS = \\frac{I}{T_{cpu}*10^6} = \\frac{r_C}{CPI\\cdot 10^6}\n$$\n","x":4531,"y":-869,"width":720,"height":700},
		{"id":"6264c0d982a44972","type":"text","text":"## Giorgio vuole fare un breve trattato sull'Universo","x":6254,"y":-309,"width":280,"height":140,"color":"1"},
		{"id":"7c44d0b7fa4661bf","type":"text","text":"# Cuscinetti tra user e HW\n\nsystems software is the name of stuff sitting between the hardware and the application software. two types are central to every computer:\n- operating system: Supervising program that manages the resources of a computer for the benefit of the programs that run on that computer\n- compiler: translates high-level language statements into assembly language statements\n\nbut also\n\n-  loaders: loads programs in main memory\n- assemblers: translates a symbolic version of instructions into the binary version (assembly language A symbolic representation of machine instructions Assembly language requires the programmer to write one line for every instruction that the computer will follow, forcing the programmer to think like the computer)\n- ...\n\nthey provide\n- basic input and output\n- Allocating\n- sharing of the computer among multiple applications\n\n","x":4011,"y":31,"width":991,"height":760},
		{"id":"94ebb589ac92b6e9","type":"text","text":"# Nomenclatura interna\n\n- integrated circuit (chip) dozens to millions of transistors.\n\n- CPU contains the datapath and control adds numbers, tests numbers, signals I/O devices to activate, and so on\n\t- Inside the processor is another type of memory, cache memory. small, fast memory that acts as a buffer for a slower, larger memory. SRAM (cache) faster and less dense than DRAM (RAM). cache is a safe place for hiding things (????)\n- datapath performs arithmetic operations\n- control: commands the datapath, memory, and I/O devices according to the instructions of the program.\n- DRAM: Memory built as an integrated circuit Access times are 50 nanoseconds In contrast to sequential access memories, such as magnetic tapes, the RAM portion of the term DRAM means that memory accesses take basically the same amount of time no matter what portion of the memory is read.\n- transistor: on/off switch controlled by an electric signal.\n- VLSI: device containing millions of transistors","x":5231,"y":31,"width":460,"height":700},
		{"id":"f3d63dbf481dd171","type":"file","file":"Capitolo 1/ComputerScheme.png","x":5331,"y":-785,"width":400,"height":333},
		{"id":"46ee857cb70eed15","type":"text","text":"# Nomenclatura (concettuale) interna\n\ninterface between the hardware and the lowest-level software (**architecture** or ISA), includes anything programmers need to know to make a binary machine language program work correctly.\nallows computer designers to talk about functions\nindependently from the hardware\n\ncombination of the basic instruction set and the operating system interface provided for application programmers is called the application binary interface (ABI)\n\nimplementation of an architecture is hardware that obeys the architecture abstraction\n","x":5731,"y":31,"width":440,"height":700},
		{"id":"969e5ce3a6049ee4","type":"text","text":"# Reti (cenni)\n\ncomputers on the network can share I/O devices ($\\Rightarrow$ Nonlocal access). Ethernet: up to a kilometer long and transfer at up to 40 gigabits per second.\n\nLAN network within a geographically\nconfined area, typically within a single building. capacity of from 1 to 40 gigabits per second\n\nWAN network that can span a continent\n\nOptical communications allowed growth in the capacity of wide area networks to gigabits and  to a worldwide network\n\nWireless technology enabled the post-PC era. ability to radiosignal with low-cost semiconductor technology (CMOS) used for memory and microprocessors enabled improvement in price","x":6231,"y":31,"width":420,"height":700},
		{"id":"dfd2890763a0d962","type":"text","text":"# CPU\n\nclock determines when events take place in the hardware (so how fast the hardware can perform basic functions).\nDesigners refer to clock period both for complete clock cycle (picoseconds) and for the clock rate (GHz). Che cani.\n$$\nT_{cpu}(P) = N_{c}(P) \\cdot T_C = \\frac{N_{c}(P)}{r_c}\n$$\ndove $T_{CPU}(P)$ è CPU execution time for a Program P, $N_{c}(P)$ è CPU clock cycles for a given P, $T_c$ è Clock cycle time e $r_c$ è il suo inverso (clock rate). Quante ovvietà.\n\nImprove performance by reducing clock cycles required or the length of the clock cycle. Often trade-off: Many techniques that decrease the number of clock cycles may also increase the clock cycle time\n\nexecution time must depend on the number $I(P)$ of instructions executed in a program (instruction count ovvero $T_{CPU}$ è una $T_{CPU}(I(P))$), possiamo vedere questa dipendenza come\n$$\nN_{C}(P) = I(P) \\cdot CPI(P)\n$$\n\naverage clock cycles per instruction CPI (è una media di cicli per istruzione del programma P che esegue I(P) istruzioni) provides one way of comparing two different implementations of the identical instruction set architecture.\n$$\nT_{CPU}(P) = \\frac{I(P) \\cdot CPI(P)}{r_c}\n$$\n\nWe can measure the CPU execution time by running the program.\nclock cycle time is usually published instruction count and CPI can be more difficult to obtain instruction count by using software tools\nor by using a simulator of the architecture. Alternatively, hardware counters included in most processors, to record a variety of measurements. instruction count depends on the architecture, but not on the exact implementation\n\nCosa influenza $I$ e $CPI$?\n- if the **algorithm** uses more divides, it will tend to have a higher CPI;\n- statements in the **programming language** translated to processor instructions determine instruction count.\n- compiler\n- ISA (anche clock rate (?))\n\n\n##### Altro\nInvert CPI to talk about IPC instructions per clock cycle\n\ntoday’s processors can vary their clock rates Intel Core i7 will temporarily increase clock rate by about 10% until the chip gets too warm. Intel calls this Turbo mode.","x":7331,"y":831,"width":660,"height":1200,"color":"2"},
		{"id":"7724895a9f26e30f","type":"text","text":"# Fabbricare un Chip\n\nmanufacture of a chip begins with silicon semiconductor. add materials to silicon that allow tiny areas to transform into\n\n- Excellent conductors (copper, aluminum)\n- Excellent insulators (plastic, glass)\n- conduct or insulate under specific conditions (transistor)\n\nTransistors fall into the last category process starts with silicon crystal ingot finely sliced into wafers then patterns of chemicals are placed on each wafer, creating the transistors, conductors, and insulators\n\nToday’s integrated circuits contain only one layer of transistors but may have from two to eight levels of metal conductor, separated by layers of insulators\n\nmicroscopic flaw in the wafer can result in failing. simplest way to cope with imperfection is to place many independent components on a single wafer\n\npatterned wafer is *diced*, Dicing enables you to discard only dies that contain the flaws ((**yield**: percentage of good dies))\n\nThe cost of an integrated circuit rises quickly as the die size increases\n$$\nCost\\,per\\,die = \\frac{Cost\\,per\\,wafer}{Dies\\,per\\,wafer\\times yield}\n$$\n$$\nDies\\,per\\,wafer) \\simeq \\frac{Wafer\\,area}{Die\\,area}\n$$\n\n$$\nyield = \\frac{1}{(1 + (Defects\\,per\\,area \\times Die\\,area/2))^2}\n$$\n\nThe final equation is based on empirical observations","x":5251,"y":891,"width":920,"height":1080},
		{"id":"e4506d54dcf914ea","type":"text","text":"# Performance\n\nwe can define computer performance in several distinct ways\n- **response time (execution time)**: As an individual computer user, the time between the start and completion of a task\n- Datacenters manage throughput or bandwidth (total amount of work done in a given time)\n\n##### Example: How to increase throughtput?\nmay be via (look for others...)\n- Replacing the processor in a computer with a faster version\n- also Adding additional processors to a system that uses multiple processors for separate tasks—for example, searching the web. If demand for processing in this second case is as large as the throughput, system might force requests to queue up increasing the throughput could also improve response time.\n\nwe could define\n$$\nperformance = \\frac{1}{execution\\,\\,time}\n$$\n\n###### Measuring performance\n\n- wall clock time, response time, or elapsed time: total time to complete a task.\n- processor may work on several programs simultaneously system may try to optimize throughput rather than elapsed time. **CPU execution time** is the time the CPU spends computing for this task and does not include time spent waiting for I/O or running other programs. further divided into\n\t- CPU time spent in the program (user CPU time)\n\t- CPU time spent in the operating system performing tasks on behalf of the program (system CPU time)\n\nDifferentiating between system and user is difficult.\n\nWe use \"system performance\" for elapsed time on an unloaded system and \"CPU performance\" for user CPU time. discussions of how to summarize performance can be applied to either elapsed time or CPU time measurements.\n\nMany applications depend as much on I/O performance, which relies on both hardware and software.\n\nTo improve the performance clear definition of what performance matters and find bottlenecks","x":6311,"y":891,"width":817,"height":1080},
		{"id":"a46ca09fa4d7ec52","type":"text","text":"## Parallelism\n\nthe programmer must divide an application so that each processor has roughly the same amount to do at the same time, and that the overhead of scheduling and coordination doesn’t fritter away the potential performance benefits of parallelism  schedule the sub-tasks balance the load.\n\nfalls short if conclusion (of operation) , couldn’t be written until all the other parts were completed. care must be taken to reduce communication and synchronization overhead.","x":6371,"y":2456,"width":817,"height":240},
		{"id":"e4cd21ce4fcc8e29","type":"text","text":"# Power Efficiency\n\nclock rate and power are correlated. power provides a limit to what we can cool. energy metric joules is a better measure than a power rate like watts. integrated circuits CMOS (complementary metal oxide semiconductor energy consumption (is so-called dynamic energy) is consumed when transistors switch states from 0 to 1 and vice versa. dall'equazione dell'energia immagazzinata in u condensatore ricavo che power required per transistor\n$$\nP \\propto \\frac{1}{2} CV^2\\cdot f\n$$\n\ndove $f$ è la Frequency, function of the clock rate. C is function of number of transistors connected to an output (fanout (?????????)) and *technology* qualsiasi cosa voglia dire...\n\nEnergy and thus power can be reduced by lowering the voltage. In 20 years, voltages have gone from 5 V to 1 V. modern problem is that further lowering of the voltage appears to make the\ntransistors too leaky 40% of the power consumption in server chips is due to leakage.\nto address the power problem turn off parts of the chip that are not used in a given clock cycle.\nthere are many more expensive ways to cool chips, but generally too costly.\n\nleakage current flows even when a transistor is off 40% of the energy consumption increasing the number of transistors increases power dissipation hard to lower voltage further\n\nSunto: \n- power must be brought in and distributed around the chip\n - power is dissipated as heat and must be removed","x":7291,"y":2456,"width":817,"height":920},
		{"id":"35873d0873f6009a","type":"text","text":"il libro di tutto questo cita solo Amdahl ma fa sempre bene rileggere","x":5906,"y":2576,"width":250,"height":120},
		{"id":"5ee91b04fb136a01","type":"text","text":"# Benchmark\n\nda capire se è una conseguenza del parallelismo (cioè se in uniprogramming sai predire le performance in modo preciso e qui no).\n\nto evaluate a new computer, set of benchmarks (programs specifically chosen to measure performance form a workload (A set of programs run on a computer) that the user hopes will predict the performance of the actual workload.\n\nSPEC (System Performance Evaluation Cooperative) creates standard sets of benchmarks for modern computer systems\n\nDividing the execution time of a reference processor by the execution time of the evaluated computer normalizes the execution time measurements. bigger numeric results indicate faster performance. SPECratio is inverse of execution time. A summary is obtained by taking the geometric mean of the SPECratios (why????) apply the geometric mean so that it gives the same relative answer no matter what computer is used to normalize the results (why???).\n\nQua lui fa la media geometrica di \"*execution time ratio$_i$*\". non sono sicuro di capire cosa significa...\n\nle pagine successive le definisco \"oscure\" (pag 48 del pdf)","x":6371,"y":2746,"width":817,"height":510},
		{"id":"f9becf64c2d6e92f","type":"file","file":"Demetrescu/Ottimizzazione.txt","x":5831,"y":2801,"width":400,"height":400},
		{"id":"e71d455138a8e246","type":"text","text":"# Storia\n##### Incompleta, se proprio vuoi perdere tempo pagina 54 del pdf\n\nworld’s first\ncomputer.\nENIAC\nElectronic\nNumerical Integrator and Calculator\n\n1900 additions\nper second.\nprovided conditional jumps and was programmable\nmanually by\nplugging cables and setting switches\nvon Neumann helped crystallize the ideas and wrote a\nmemo\nbasis for the\nterm von Neumann compute\nEDSAC (Electronic Delay Storage Automatic\nCalculator)\n1949","x":8351,"y":1816,"width":441,"height":792},
		{"id":"100ff872e0aa5955","type":"text","text":"execution time is the product of the three factors in this table: instruction count in billions, clocks per instruction (CPI), and clock cycle time in\nnanoseconds. SPECratio is simply the reference time, which is supplied by SPEC (di un processore di riferimento che non so quale sia, probabilente è vecchio), divided by the measured execution time. The single number\nquoted as SPECINTC2006 is the geometric mean of the SPECratios.","x":7144,"y":3878,"width":706,"height":193},
		{"id":"a397c5d67ebfce21","type":"file","file":"Capitolo 1/BenchmarksSPEC.png","x":6441,"y":3698,"width":623,"height":300},
		{"id":"78b3395d6c378f86","type":"file","file":"Capitolo 1/PowerAndClockRate.png","x":8331,"y":2976,"width":806,"height":340},
		{"id":"0b6d09ee9d694b1f","type":"text","text":"# (Riassunto) 1 - Introduzione\n\nAl momento le frecce indicano l'ordine degli argomenti nel capitolo, non sono assolutamente utili in senso concettuale","x":2551,"y":-979,"width":480,"height":220,"color":"6"},
		{"id":"2452606adbf4ae6d","type":"file","file":"Capitolo 1/conversions.png","x":2320,"y":-709,"width":991,"height":340},
		{"id":"e723e0fbc1846d02","type":"text","text":"# Tipi di architetture\n\nPersonal computers (PCs) good performance to single users at low cost and usually\nexecute third-party software. 35 years old!\n\n\nServers usually accessed only via a network. oriented to carrying sizable\nworkloads, or handling many small jobs, e usually based on\nsoftware from another source (such as a database or simulation system), emphasis\non dependability, since a crash is usually  costly\n\nsupercomputers (configured as servers) which at the present consist of tens of thousands of processors and many terabytes of memory, weather forecasting, oil exploration, protein structure determination, and other large-scale problems\n\n\nEmbedded computers microprocessors networks of processors designed to run one application or one set of related applications that are normally integrated with the hardware and delivered as a single system; minimum performance with stringent limitations on cost or power lower tolerance for failure consumer-oriented embedded applications emphasis is on doing one function as perfectly as possible large embedded\nsystems redundancy often employed most concepts apply directly, or with slight modifications, to embedded computers.\n\npersonal mobile device (PMD) smart phone or a tablet tomorrow it may include  electronic glasses are small wireless devices to connect to the Internet\n\n\nCloud Computing large collections of servers that provide services over the Internet\n\n\nSoftware as a Service (SaaS) delivers software and data as a service over the Internet\nvia browser instead of binary code that must be installed runs wholly on that device e.g. web search social networking\n\n\n","x":2591,"y":-314,"width":720,"height":777,"color":"2"},
		{"id":"3f606618d45d0104","type":"text","text":"# Tecniche di design\n\n- abstractions\n- make common case fast will tend to enhance performance better than optimizing the rare case\n- parallel performance\n- pipelining particular pattern of parallelism. runs programs faster by overlapping the execution of instructions industry has bet its future that programmers will switch to explicitly parallel programming.\n- prediction: it can be faster on average to guess and start working rather than wait until you know for sure\n- hierarchy of memories: memory speed often shapes performance, capacity limits the size of problems. cost of memory is majority of computer cost. hierarchy of memories: fastest, smallest, and the most expensive memory per bit at the top slowest, largest, and cheapest per bit at the bottom\n- Dependability via Redundancy: redundant components that can take over when a failure occurs and to help detect failures","x":3121,"y":531,"width":720,"height":550},
		{"id":"3c12a472e21d0b51","type":"text","text":"# Domande a cui rispondere\n\nHow are programs written in a high-level language translated into the language of the hardware, and how does the hardware execute the resulting program?\n\nWhat is the interface between the software and the hardware, and how does software instruct the hardware to perform needed functions?\n\nhow can designers improve energy, efficiency, performance\n\nhow can programmer improve the performance\n \nswitch from sequential processing to parallel processing\n\nunderstanding these questions makes improving the performances a scientific procedure\n","x":1600,"y":662,"width":991,"height":398},
		{"id":"70f63fa924d39f03","type":"text","text":"# Come influenza le performance?\n\n- Algorithm: number of source-level statements number of I/O operations executed\n- Programming language compiler, and architecture: number of computer instructions for each source-level statement\n- Processor and memory: how fast instructions can be executed\n- I/O system (hardware and OS): how fast I/O operations may be executed","x":2871,"y":1183,"width":500,"height":377},
		{"id":"c84a18acd87bdb46","type":"file","file":"Capitolo 2/x86vsRISCvsMIPS.png","x":2120,"y":2557,"width":418,"height":480},
		{"id":"5b46158c20ea1d79","type":"file","file":"Capitolo 2/RISCvsMIPS.png","x":1760,"y":2531,"width":307,"height":531},
		{"id":"78004fb19f7d1705","type":"text","text":"# RISC-V\n\nRISC-V assembly add a, b, c add the two variables b and c and to put their sum in a. each RISC-V arithmetic instruction performs only one operation and must always have exactly three variables each line of this language can contain at most one instruction. comments always terminate at the end of a line. every instruction to have exactly three operands philosophy of keeping the hardware simple.\n32 registri, memory word Accessed only by data transfer instructions, RISC-V uses byte addresses, so sequential doubleword *\\[Tipicamente per word si intendono 32 bit e doubleword 64, e questo è un commento che fa dopo e che mi sembra incoerente con questa frase\\]* accesses differ by 8\n###### ChatGPT:\nRISC-V non è limitato esclusivamente a 64-bit. L'architettura RISC-V è stata progettata per essere modulare e flessibile, il che significa che può supportare sia sistemi a 32-bit che a 64-bit, così come altre possibili larghezze di bus o parole.\n\nLa specifica base di RISC-V definisce istruzioni per un'architettura a 32-bit, mentre le estensioni possono essere utilizzate per supportare larghezze di bus e parole diverse, inclusi 64-bit. Questa flessibilità è una delle ragioni per cui RISC-V è popolare in una vasta gamma di applicazioni, dalle microcontroller embedded ai server ad alte prestazioni.","x":2120,"y":3062,"width":420,"height":980},
		{"id":"89901351b69f4ba9","type":"text","text":"# Commenti a caso che non so dove mettere, edizione capitolo 2\n\nDesign Principle 1: Simplicity favors regularity.\n\n\nPer quanto oggi possa sembrare ovvio, il funzionamento dei computer si basa sul cosiddetto *Stored-Program Concept*, ovvero sull'idea che istruzioni e dati possono essere conservati in memoria sotto forma di numeri.","x":1970,"y":1343,"width":720,"height":700},
		{"id":"16abd413d233f637","type":"text","text":"# Hardware","x":-1955,"y":1689,"width":205,"height":50,"color":"6"},
		{"id":"5d905f6c8910912d","type":"text","text":"# Progettare l'Hardware\n\nCome costruisco in modo ottimale i circuiti all'interno delle varie componenti HW?\n\nCi sono dei linguaggi di progettazione come *Verilog* o *VHDL* (detti **HDL**, *Hardware Description Language*), che permettono di scrivere un codice descrittivo delle operazioni che dovrà eseguire la macchina, come ad esempio un'addizione con segno.\n\nAttraverso un software, detto di *sintesi*, viene prodotta a partire dal codice una mappa logica equivalente al codice, detta *netlist*, che presenta elementi come porte logiche, flip-flop e multiplexer.\n\nSeguono diversi step di ottimizzazione volti a ridurre la superficie occupata e massimizzare le prestazioni.\n\nInfine avviene il *mapping*, ovvero lo schema logico viene implementato tramite una data tecnologia (celle logiche per un *FPGA*, transistor per un *ASIC*).","x":-2337,"y":1039,"width":970,"height":398,"color":"3"},
		{"id":"6a1f44f4ce649afe","type":"text","text":"## ... e prima dei linguaggi HDL??\n\nPrima si faceva tutto a mano.\n\nPur essendo nati sul finire degli anni '60, non erano né efficienti né popolari. Solo con Verilog e VHDL, verso metà degli anni '80, la tecnica ha iniziato a diffondersi.\n\nVa sottolineato che anche oggi la progettazione può ancora richiedere del lavoro non automatizzato.","x":-2092,"y":519,"width":480,"height":280,"color":"3"},
		{"id":"a98cbc58d3a170b7","type":"text","text":"# Gestione Architettura","x":-2920,"y":2350,"width":400,"height":50,"color":"6"},
		{"id":"f64f10efeafc58a7","type":"text","text":"# Caratteristiche generali (MIPS 2000)\n\nMIPS 2000 è un'architettura **_RISC_** a **_32 bit_**. Questo significa che tutte le **word** hanno dimensione fissa, il che permette diverse ottimizzazioni a livello di circuito.\n\nHo uno spazio di indirizzamento di $2^{30}$ indirizzi, ognuno contenente una word da 32 bit. Sono però interessato a leggere il singolo byte, motivo per cui per muovermi dalla word al'indirizzo t alla successiva devo fare t+4.\n\nGli interi vengono salvati in complemento a 2, e in formato little endian.\n\nPrevede 3 microprocessori:\n- La CPU principale, contenente l'ALU con 32 registri interi e accesso RAM\n- Coprocessore 0, senza registri o accesso RAM, serve per gestione eccezioni\n- Coprocessore 1 per calcolo in virgola mobile con 32 registri float utilizzabili come 64 registri a 16bit.\n\nAlcuni dei 32 registri sono riservati all'assemblatore, ad esempio\n\n32 registri da 32bit (da s0 a s7, da t0 a t9, ecc). Ognuno ha particolarità, alcuni sono riservati al processore.\n\n\nci sono molti opcode liberi, utilizzabili per definire nuove istruzioni (ma immagino mi serva il supporto HW)\n\nvedi slides per istruzioni coprocessore (just to know)\n\nslt, slti spesso parte del vero codice sotto le pseudoistruzioni\n\n`or %s4, %zero, %s0` copia il contenuto di s0 in s4\n\nspesso in assembly salto se la condizione _non_ è soddisfatta (per entrare nell'\"if\" devo non-saltare)\nTutte le istruzioni di controllo vanno implementate con i salti (ma posso sempre farmi una funzione for...)\n\n.word devo saltare di 4 per spostarmi di elemento.\n\nmips è pensato per avere funzioni da massimo 4 argomenti e 2 output, ma posso sempre mettere altra roba in ram (con gli indirizzi).\n\nLe calling conventions (caller/callee save) non vengono molto rispettate, ma sarebbe meglio farlo per la compatibilità\n\n`lw $s0, vector` è identico a `la $t0, vector` + `lw $s1, 4($t0)` (load word vs load address)\n\n`jr $t1` salta all'indirizzo di memoria contenuto nel registro t1 (se ci ho messo roba non multipla di 4 mi dà errore a runtime)\n\nposso fare operazioni con immediati e registri, immediati ed etichette ed etichette e registri (credo)","x":-1099,"y":1400,"width":739,"height":740},
		{"id":"acee9d59937134d5","type":"text","text":"# Registri MIPS\n\n- registro @ per pseudoistruzioni, se lo uso non da errore ma mi sovrappongo all'assemblatore\n- ra tiene traccia del program counter (indirizzo di ritorno per dopo funzione)\n- stack frame `$fp` che credo sia il primo elemento della stack\n- stack pointer `$sp` (che differenza c'è ??) credo sia l'ultimo elemento della stack\n- Registri temporanei (`$t0, ... $t9)`) - sono caller-save, ovvero possono cambiare tra una chiamata di funzione e l'altra, utilizzati nelle funzioni. se il chiamante li sta usando, sta a lui salvarli in stack per riprenderli in seguito;\n- Registro salvati (`$s1, ... $s7`) - sono callee-save, non cambiano tra una chiamata di funzione e l'altra, Se una funzione vuole usarli, deve prima salvarne il contenuto in stack e ripristinarli prima di uscire;\n- Registri di input (`$a0, ... $a3`) - usati come argomenti da passare a funzione;\n- Registri di output (`$vo, $v1`) - usati per i risultati della funzione;\n","x":-120,"y":1400,"width":531,"height":740},
		{"id":"a4cfc60010d051fa","type":"text","text":"tutte le istruzioni sono a 32bit. Questo permette di implementare un parallelismo a livello di circuito: dopo aver letto l'istruzione posso fare altro (Mentre ALU fa somme la CU può recuperare istruzione successiva. In CISC devo controllare quanto è lunga l'istruzione, capire cosa farci, ... più difficile da ottimizzare). In RISC è più facile decodificare l'istruzione.\n\nGli operandi devono stare solo nei registri (niente operandi a memoria) e infatti ne ha molti per evitare gli accessi a memoria. . CiSC sta rubando molto da RISC lately. \n\n","x":-340,"y":1040,"width":551,"height":342},
		{"id":"3310c53b683f43f3","type":"text","text":"# Syscall\n\nin passato bisognava scrivere una funzione ad-hoc per ogni HW, poi si è passati alla memoria virtuale e poi ci pensa il SO.\n\nChiamiamo il SO per cambiare lo stato dell'HW.\nCome si usano?\n- `$v0` quale syscall voglio chiamare\n- `$a0, $a1, $a2, $f0` parametri (argomenti)\n- `$v0, $f0` output\n\nho solo 4 input, come faccio a scrivere 100 caratteri? uso la memoria (buffer). \n\nper copiare valore di registro in un altro c'è la `move`, ma è più veloce con gli operatori logici?\n\nsyscall importanti 1, 4, 5, 8, 10, 11 (utile a stampare un a capo), 17 (molto usato nei SO, termina e restituisce l'exit code) ","x":-580,"y":-480,"width":617,"height":520},
		{"id":"01582bc3f803f4ce","type":"text","text":"# Memory & co\n\nla roba nella ram può essere interpretata come ASCII.\nl'assemblatore separa lo spazio del programma (.text, direttive dell'assemblatore) e dei dati statici (.data, dimensione fissata). poi heap-spazio_libero-stack. GP è il pointer dell'heap. GP+4 alloca spazio per una word in heap. GP ed SP dovrebbero stare nel loro spazio, ma dipende da come il processore gestisce i controlli e le eccezioni. MIPS permette di disattivare i controlli. il programma finisce quando il PC raggiunge la fine dello spazio dedicatogli (in automatico?.\n\nimplicito -> non è scritto nell'istruzione l'address (e.g. leggi il PC);\nRegistro indiretto: nell'opcode ti dico che devi interpretare il valore del registro che segue come indirizzo di memoria e lo vai a prendere.;\n\nmi sa che se scrivo  tipo `add *roba*, -4` quel -4 è automaticamente trattato a 16bit e poi esteso in modo opportuno dalla add.\n\nle etichette dell'assembly sono tradotte in indirizzi di memoria","x":200,"y":80,"width":600,"height":520},
		{"id":"cd5d7cb1c640e6d1","type":"text","text":"# Istruzioni MIPS\n\nLe istruzioni della CPU dell’architettura MIPS, seguono (per lo più) una struttura molto\nsemplice, ossia `<operazione> <destinazione>, <sorgenti>, <argomenti>`.","x":243,"y":2700,"width":420,"height":640},
		{"id":"8f128dc2275f072f","type":"text","text":"# Istruzioni MIPS\n\n\n\nGli immediati sono inglobati dentro l'istruzione stessa!\n\nIl jump incondizionato può saltare a posizioni di memoria più grandi rispetto al condizionato (che nei 32bit deve contenere ANCHE la condizione).\n\n##### R-type\nSono le istruzioni che coinvolgono i registri. Se ne ho 32 li indicizzo con 5bit. Se mi servono 3 operandi (addendo, addendo, risultato, nel codice sono in questo ordine e in assembly al contrario!!) ho già sprecato 15bit. Altri 5 li riservo per lo shift logico (shamt, se devo fare prodotti o divisioni per potenze di due). I primi 6 sono opcode (che tipo di istruzione è e.g. aritmetica) e gli ultimi 6 specificano che tipo è (somma, mul, ...). Questa implementazione \"scissa\" discende dalla legge di Amhdal (?).\nNon entra la RAM obv. \\$t0 = 8 -> nono registro\n##### I-Type\nSe ci bastano solo due registri avanzano 16bit, che posso usare come numero o indirizzo di memoria (... comunque in 16bit).\n- Se devo sommare 1 non è efficiente usare un intero registro. \"add immediato\" `addi $t2, $s2, 1`. NB: il target register si sposta all'interno dell'istruzione! In particolare prima era un operando (vedi slides) \\[source, target, destination\\] e crea casino a livello di circuito logico. Notare che non ho spazio dedicato per shift logico.\n- roba come load word (`lw`) supporta roba come `100($s2)` che va all'indirizzo `$s2+100`. Chiaramente sono limitato nel massimo indirizzo addressable (... sicuro? fai i conti. sicuro a 64bit sì ma sticazzi)\n- Posso usare le i-type per fare salto condizionato. se di default aggiorno PC -> PC+4, posso aggiungere un offset come immediato nei 16bit.\n\n##### j-Type\nTipo \"salto incondizionato\", 6bit di opcode e 26 di address. Gli ultimi 2 devono essere 0 (perché il PC salta solo a multipli di 4), quindi posso usare quei due bit per aggiungere info -> 28bit. Ma  non sono 32 -> se serve saltare di oltre 2^32bit sto scrivendo un codice terribile","x":760,"y":1640,"width":800,"height":1260},
		{"id":"122d37da0139aaba","type":"text","text":"# ASCII ed endianess\n\nsono byte, passo da uno all'altro incrementando di 1.\n\nse ho stringa ascii tolgo 48 e diventa un intero (?)\n\ncr vai a capo, lf torna indietro (o contrario)\n\n\"little endian \"potrebbe essere molto utile\", invertito a gruppi di 8 ma leggo i byte al contrario. quasi tutte le CPU, compresa MARS, usano little endian.\n\nperché?\n- posso leggere il numero a diverse precisioni direttamente (e.g. se mi serve un byte con little endian faccio subilto, con lo stesso indirizzo di memoria). quando leggo la memoria prendo subito a sinistra, \n- altri vantaggi nelle somme e sottrazioni, è più veloce leggerli e iniziare a fare i conti che leggere tutto e poi iniziare a fare il conto.\n\nin pratica non succede quasi mai, è una roba storica","x":-394,"y":180,"width":540,"height":800},
		{"id":"66099e113f954c7e","type":"text","text":"# memory pointers\n\nstack pointer sp scende, heap pointer hp sale\nstack frame (o frame pointer) è l'inizio della stack (mentre lo stack pointer è la fine). in realtà è ridondante (... ai fini della programmazione basic, se faccio roba dinamica chiaramente mi serve)","x":816,"y":3183,"width":524,"height":257},
		{"id":"fe03d6cf0d123954","type":"text","text":"# Cache","x":-2720,"y":1864,"width":250,"height":60,"color":"6"},
		{"id":"0098615274085117","type":"text","text":"# Progettare un'architettura MIPS\n\nsingolo colpo di clock -> in un solo colpo viene eseguita l'istruzione.\nogni circuito esegue una certa istruzione, e ognuno può avere tempi di assestamento diversi. Quello che stiamo per vedere è una semplificazione della CPU. per ora.\n\ncontrollo legge l'input e comanda il resto dicendo cosa farci. \nvalore hard-coded??\ncircuito combinatorio interagisce con lo stato e lo cambia. in genere 1 è segnale alto, solo in un caso lo è 0\n\nSe devo fare AND in cascata, invece di mettere tanti circuiti uguali (porte logiche in questo caso) posso reindirizzare l'output verso l'input. Ma l'AND ci mette un tot per dare l'output (assestamento). la logica combinatoria si attiva SOLO quando il segnale di clock sale. per assestarsi ci mette un tot. quanto? per ora boh, sicuramente il prossimo gradino devo programmarlo dopo che si assesta. (elementi di stato sensibili al fronte di salita). il tempo di esecuzione dell'istruzione è il tempo che ci mette la logica a stabilizzarsi. un AND ci mette un tot. N AND ci mettono N\\*tot.. Finché non mi assesto l'output è indefinito. quando faccio overclock provo a ridurre l'intervallo tra le salite, sperando di prendere la roba giusta (che i circuiti siano già assestati). in questo modo posso fare cicli sui circuiti. ergo: singolo ciclo di clock = in un solo intervallo devo eseguire tutta l'istruzione. Quindi devo progettare il periodo di clock per farci entrare l'istruzione più lenta (CPU è vincolata dall'istruzione più lenta che può eseguire, in genere quelle a memoria), altrimenti quando la eseguo rompo tutto.\n\n","x":-3637,"y":713,"width":1117,"height":525},
		{"id":"78d0c8dfe0453bfa","type":"text","text":"# CPU a singolo ciclo di clock (senza pipeline)\n\nla CU sa quali parti del circuito attivare. non posso mandare l'istruzione direttamente all'ADDER .\nquando mando l'impulso di clock si attivano TUTTI i circuiti della CPU. la tensione va comunque anche nelle parti che non ci servono, che ignoriamo. quindi importante sapere a cosa sono interessato (CU)\nse metto operazioni in cascata l'assestamento è in cascata. il secondo AND inizia a stabilizzarsi solo quando il primo AND si è stabilizzato.\n\nil segnale si propaga ovunque, sta ai mux bloccarlo dove non deve passare.\nmemread e memwrite controllano che il risultato della alu venga o non venga usato per accedere a memoria","x":-3637,"y":1300,"width":1117,"height":440},
		{"id":"e42b6ea00a3a478f","type":"text","text":"# fasi\n- fetch\n- decode\n- ..\n- aggiornamento PC - si può fare in parallelo alle altre operazioni sul singolo ciclo di clock (parallelismo interno, non di istruzioni, che invece si ha con la pipeline)","x":-4180,"y":1300,"width":374,"height":440},
		{"id":"3a482ea687c941c1","type":"text","text":"# unità funzionali\n","x":-4180,"y":1800,"width":374,"height":380},
		{"id":"f7074efa4ab3d2bb","type":"text","text":"# varie\n\nbello che la CPU ha sia dati che istruzioni, ma a livello di architettura separo banco dati e banco istruzioni. potrebbero pure stare su ram diverse, per quanto ne sa l'architettura\n\ncambiando solo il controllo passo da una lw ad una addi.\n\nx nella tabella verità sta per \"i dont care\"\n\nil salto è rappresentato rispetto a PC+4 (non rispetto a PC), perché tanto il +4 lo faccio comunque a monte","x":-4800,"y":1360,"width":385,"height":540},
		{"id":"f6ae47c315f3d2fb","type":"text","text":"# CU\n\nè una tabella di verità che associa a ogni opcode un set di segnali. partono tutti, il mux sceglie chi uccidere","x":-5260,"y":1500,"width":416,"height":185},
		{"id":"e7e23c3722a618ab","type":"text","text":"eclipse ide","x":-4034,"y":988,"width":250,"height":60},
		{"id":"9c3972537895859b","type":"text","text":"# Riassunto \nin pratica si riduce tutto a:\n\nogni componente è una funzione che fa cose\n\nquello che faccio io è settare l'unitaà di controllo e i mux per decidere cosa dare in pasto a chi e quali segnali considerare e quali ignorare o bloccare\n\ntutto questo stando attento al fatto che l'impulso elettrico si propaga ovunque io non lo blocchi esplicitamente con un mux o con un segnale di controllo\n\ndopodiché, una volta note le operazioni di base, sono solo esercizi","x":-3631,"y":2155,"width":553,"height":445},
		{"id":"41f1b1a58ee74373","type":"text","text":"# Operandi dell'architettura: i registri\n\noperands must be from a limited number of special locations built directly in hardware called registers. size of a register in RISC-V is 64 bits (doubleword, 32 bits called a word)  limited number of registers, typically 32.\nDiktat: Smaller is faster\nlarge number of registers may increase the clock cycle time: electronic signals must travel farther. but 31 registers may not be\nfaster than 32. must balance the craving of programs for more registers with the designer’s desire to keep the clock cycle fast. \n\nRISC-V convention is *x* followed by the number of the register, except for a few register names.\n\nprocessor can keep only a small amount of data in registers. Arrays and structures are kept in memory RISC-V must include instructions that transfer data between memory and registers (**data transfer instruction**). must supply the memory address.\nMemory is just a large, single-dimensional array, with the address acting as the index to that array, starting at 0","x":-3480,"y":3460,"width":580,"height":680},
		{"id":"afb57d55a3a9456a","type":"text","text":"# Registri\n\nGli operandi devono provenire da un numero limitato di posizioni speciali costruite direttamente nell'hardware chiamate registri. La dimensione di un registro in RISC-V è di 64 bit (doubleword, 32 bit chiamati word), con un numero limitato di registri, tipicamente 32. Il dettato è: più piccolo è più veloce.\n\nUn grande numero di registri potrebbe aumentare il tempo del ciclo di clock: i segnali elettronici devono viaggiare più lontano. Ma 31 registri potrebbero non essere più veloci di 32. Bisogna bilanciare il desiderio dei programmi di avere più registri con il desiderio del progettista di mantenere veloce il ciclo di clock.\n\nLa convenzione RISC-V è _x_ seguito dal numero del registro, ad eccezione di alcuni nomi di registro.\n\nIl processore può mantenere solo una piccola quantità di dati nei registri. Array e strutture vengono mantenuti in memoria e RISC-V deve includere istruzioni che trasferiscono dati tra memoria e registri (istruzioni di trasferimento dati). Deve fornire l'indirizzo di memoria. La memoria è solo un grande array unidimensionale, con l'indirizzo che agisce come indice di quell'array, a partire da 0.","x":-2840,"y":3460,"width":580,"height":680},
		{"id":"18bb82c16136bede","type":"file","file":"pipelining.txt","x":-3981,"y":3415,"width":400,"height":400},
		{"id":"165f0ab7d8b79def","type":"text","text":"# Hazard\n\n","x":-5120,"y":5020,"width":628,"height":200},
		{"id":"434ce1c924360a5a","type":"text","text":"al colpo di clock si attivano i latch (mi sa vedi progettazione sistemi digitali) forse è per questo che la circuiteria è sensibile ai gradini dell'onda quadra!!!","x":-5480,"y":3220,"width":375,"height":138},
		{"id":"d73fa2053944763c","type":"file","file":"Ottimizzazione.txt","x":-3981,"y":2980,"width":400,"height":400},
		{"id":"2e9af087f944ad95","type":"text","text":"# Pipelining\n\nNella schematizzazione a singolo colpo di clock, devo aspettare l'esecuzione e l'assestamento dell'intero circuito. Ma posso usare il colpo di clock per eseguire solo un pezzetto del circuito? \n\nOgni istruzione può essere divisa a livello di circuito in 5 fasi indipendenti:\n\n- Fetch (IF) - 200ps - non serve controllo\n- Decode (ID) - 100ps (discesa) - non serve controllo\n- Execute, che si compone in\n\t- Esecuzione ALU (EXE) - 200ps\n\t- Accesso a Memoria (MEM) - 200ps\n\t- Eventuale scrittura nei registri (Write Back, WB) - 100ps (salita)\n\nSe eseguo un'istruzione alla volta, ogni ciclo di clock esegue utilmente solo una di queste fasi, lasciando le restanti 4 parti di circuito \"inutilizzate\". L'idea è che quando eseguo $ID_1$ posso già iniziare a fare $IF_2$ e via dicendo, in modo che dalla quinta istruzione in poi venga utilizzato tutto il circuito.\n\nTroppo facile. Ci sono diversi problemi se provo a fare questa cosa:\n\n- ***Ciclo di Clock*** - Istruzioni diverse hanno tempi di esecuzione diversi. Devo adeguare il periodo di Clock all'istruzione più lenta, di fatto lasciando tempi morti nelle zone circuitali più veloci. In generale, si cerca di progettare CPU in modo da avere fasi con tempi simili per massimizzare l'ottimizzazione;\n\t- In generale, la velocità di clock non di per sé è inutile se non so \"quanto\" esegue per ogni ciclo di clock. ??? -> grandezza utile sono i flops???\n- ***Registri intermedi*** - Per poter eseguire ogni pezzo di circuito in modo indipendente, devo mettere in mezzo dell'HW che \"blocca\" la propagazione del segnale al resto del circuito e salva i risultati temporanei per il prossimo ciclo di clock;\n- ***Hazard*** - Non sempre le azioni parallele sono indipendenti. Ad esempio, se l'istruzione 2 ha bisogno come dato di input l'output dell'istruzione 1, questa non avrà ancora finito l'esecuzione. In generale, quando ho un'informazione che deve essere propagata tra le fasi posso incontrare gli hazard;\n\t- ***Conflitti*** - In un elaboratore reale, IF e MEM usano la stessa RAM. Considerarle separate sarà una semplificazione fatta per semplicità di trattazione;\n\n\n\n\n\n","x":-5324,"y":3580,"width":1059,"height":820,"color":"3"},
		{"id":"1e44f734e3ca2eae","type":"text","text":"# Pipeline","x":-4919,"y":3358,"width":250,"height":60,"color":"6"},
		{"id":"514b4547d1f96fcc","type":"text","text":"# Ottimizzazione WB/ID\n\nLe operazioni di WB e ID hanno diverse cose in comune.\n\n- Durano molto meno rispetto a tutte le altre fasi, diciamo meno della metà;\n- Lavorano con i registri, in particolare WB scrive e ID legge.\n\nSe $ID_2$ deve aspettare $WB_1$ a rigore dovrei inserire 3 stalli.\n\nSiccome siamo furbi, ci ricordiamo di star lavorando assumendo che tutte le fasi del circuito siano sensibili al fronte di salita dell'onda quadra di clock. Ma visto che i circuiti di WB e ID ci mettono così poco a stabilizzarsi, ***posso eseguirle entrambe in fila in un singolo ciclo di clock***. Basta rendere ***ID sensibile al fronte di discesa***, lasciando ***WB al fronte di salita***.\n\nQuesto mi permette di eseguirle in parallelo (dal POV del ciclo di clock complessivo) e ID vedrà nei registri il risultato di WB, risparmiando uno stallo.","x":-7000,"y":3300,"width":660,"height":460,"color":"4"},
		{"id":"29d0f3c34ea3f35f","type":"text","text":"# Malfunzionamenti (CU)\n\nspesso i chip si rompono in fase di produzione. se ne fanno tanti, si scartano quelli malfunzionanti. ci sono delle istruzioni che tipicamente vanno in corto (e.g. quelli della CU). Possiamo scrivere pezzi di codice ad hoc per testare gli errori frequenti se li conosco.\n\na volte, visto che sono cavi molto vicini, flippa accidentalmente il bit.\n\nsuccede spesso che regwrite viene determinato da branch. bisogna trovare le CPU difettose tramite codice che testa le istruzioni affected, in modo da poterle scartare\n\nmi serve una tabella che descrive le istruzioni","x":-5720,"y":2500,"width":557,"height":510},
		{"id":"14e2e9fcc14975b1","x":-6900,"y":3849,"width":388,"height":282,"color":"4","type":"text","text":"# Structural Hazard\n\nIl fatto che ID e MEM non facciano riferimento a memorie separate aggiunge delle complicazioni.\n\nDa risolvere in fase di progettazione, quindi procederò ad ignorarle."},
		{"id":"838f77bb16984999","type":"text","text":"# Control Hazard (Salti)\n\nDi norma eseguo le istruzioni in fila, leggendo la successiva all'indirizzo `PC+4`. Se però eseguo un salto (alterazione del flusso normale) il prossimo indirizzo di fetch lo scopro solo dopo la fase EXE. Ci sono due casi:\n- EXE mi dice che non devo saltare - non faccio niente;\n- EXE mi dice che devo saltare - mi tocca modificare la pipeline, che intanto era andata in automatico a `PC+4`). ","x":-6220,"y":4120,"width":720,"height":466},
		{"id":"dd817c0531806cd2","type":"text","text":"# Hazard\n\n","x":-5942,"y":3960,"width":164,"height":60,"color":"6"},
		{"id":"88f1a92a07e5b12b","type":"text","text":"# Data Hazard\n\nL'esempio più evidente è quello in cui la fase EXE dell'istruzione 2 richiede un dato che l'istruzione 1 non ha ancora calcolato. Come risolvo?\n\n- ***Stalli*** - Ritardo l'esecuzione dell'operazione 2 aggiungendo delle fasi di stallo;\n\t- Arrivo a sovrapporre $WB_1$ e $IF_2$ (***tre stalli***);\n\t- Questo necessita di un segnale di controllo per dire alla ALU di mandare un singolo colpo a vuoto. L'istruzione per fare ciò si chiama ***No-Operation*** (***NOP***), ed è una cosa del tipo `opcode=000000` che esegue `add $0 $0 $0`;\n\t- ***Ottimizzazione WB/ID*** - Arrivo a sovrapporre $WB_1$ e $ID_2$ (***due stalli***);\n- ***Forwarding (bypassing)*** - In realtà per avere il dato basta aspettare EXE. Posso collegare direttamente output e input della ALU, con opportuno controllo.\n\t- Quindi arrivo a sovrapporre $EXE_1$ e $ID_2$, come se non ci fosse l'hazard? No, perché EXE si prende un intero ciclo di clock per produrre l'output (non esiste un'ottimizzazione EXE/ID), quindi ***devo mettere almeno uno stallo***;\n\t- Questo richiede un'***Unità di Propagazione***, ovvero un mux a tre casi:\n\t\t- `NoForwarding` - La ALU prende il valore dal banco `ID/EXE`;\n\t\t- `Forwarding_1` - Faccio forwarding dall'istruzione precedente, quindi prendo il valore dal banco `EXE/MEM` (**uno stallo**);\n\t\t- `Forwarding_2` - Faccio forwarding da due istruzioni fa, quindi prendo il valore dal banco `MEM/WB`(se l'istruzione intermedia ha già fatto uno stallo non devo aggiungerne altri, altrimenti metto uno stallo. Ma forse in questo caso posso usare `Forwarding_1`...?);\n- ***Ottimizzazione del Codice*** - Se sono un programmatore furbo o se uso un compilatore furbo posso provare a riordinare le istruzioni Assembly in modo che l'istruzione $n+1$ non richieda l'output dell'istruzione $n$ o $n-1$.\n\nUn'altra situazione tipica in cui si verifica Data Hazard è quando eseguo una `sw` e una `lw` consecutivamente sullo stesso indirizzo di memoria. In questo caso, non è la fase EXE ad avere problemi, ma l'accesso a memoria. ????? SIAMO SICURI????","x":-6220,"y":3040,"width":720,"height":810,"color":"3"}
	],
	"edges":[
		{"id":"352324112e64b113","fromNode":"3c12a472e21d0b51","fromSide":"right","toNode":"70f63fa924d39f03","toSide":"left"},
		{"id":"b9f09ab23c605f65","fromNode":"e723e0fbc1846d02","fromSide":"left","toNode":"3c12a472e21d0b51","toSide":"top"},
		{"id":"02479a35015b5cf2","fromNode":"70f63fa924d39f03","fromSide":"right","toNode":"3f606618d45d0104","toSide":"bottom"},
		{"id":"7698822a27692414","fromNode":"3f606618d45d0104","fromSide":"top","toNode":"7c44d0b7fa4661bf","toSide":"left"},
		{"id":"d750fa4a8a142824","fromNode":"969e5ce3a6049ee4","fromSide":"top","toNode":"6264c0d982a44972","toSide":"bottom"},
		{"id":"fc5ded6ec491d93d","fromNode":"7c44d0b7fa4661bf","fromSide":"right","toNode":"94ebb589ac92b6e9","toSide":"left"},
		{"id":"51251623d685e714","fromNode":"94ebb589ac92b6e9","fromSide":"right","toNode":"46ee857cb70eed15","toSide":"left"},
		{"id":"a7eafeb6c8c346f7","fromNode":"46ee857cb70eed15","fromSide":"right","toNode":"969e5ce3a6049ee4","toSide":"left"},
		{"id":"2812fd451c957750","fromNode":"94ebb589ac92b6e9","fromSide":"bottom","toNode":"7724895a9f26e30f","toSide":"top"},
		{"id":"f496ae47111d27c9","fromNode":"7724895a9f26e30f","fromSide":"right","toNode":"e4506d54dcf914ea","toSide":"left"},
		{"id":"99d0c42d87f2952f","fromNode":"e4506d54dcf914ea","fromSide":"right","toNode":"dfd2890763a0d962","toSide":"left"},
		{"id":"66d451b3dd1158ac","fromNode":"dfd2890763a0d962","fromSide":"bottom","toNode":"e4cd21ce4fcc8e29","toSide":"top"},
		{"id":"a195332ee9782da8","fromNode":"e4cd21ce4fcc8e29","fromSide":"right","toNode":"78b3395d6c378f86","toSide":"left"},
		{"id":"58858eb02c3845e0","fromNode":"a397c5d67ebfce21","fromSide":"right","toNode":"100ff872e0aa5955","toSide":"left"},
		{"id":"5c08edf34c14e11e","fromNode":"5ee91b04fb136a01","fromSide":"bottom","toNode":"a397c5d67ebfce21","toSide":"top"},
		{"id":"cb68dd135ac37fa6","fromNode":"e4cd21ce4fcc8e29","fromSide":"left","toNode":"a46ca09fa4d7ec52","toSide":"right"},
		{"id":"5a8f2417660fbab0","fromNode":"a46ca09fa4d7ec52","fromSide":"bottom","toNode":"5ee91b04fb136a01","toSide":"top"},
		{"id":"6977e7d4fb7b4066","fromNode":"5ee91b04fb136a01","fromSide":"left","toNode":"f9becf64c2d6e92f","toSide":"right"},
		{"id":"d5006d3c292b2549","fromNode":"f9becf64c2d6e92f","fromSide":"top","toNode":"35873d0873f6009a","toSide":"bottom"},
		{"id":"46efe16780ffdfc7","fromNode":"efecee1b85d4d14d","fromSide":"bottom","toNode":"20a4b8a4ba668db7","toSide":"top"},
		{"id":"d684531186819afb","fromNode":"20a4b8a4ba668db7","fromSide":"top","toNode":"efecee1b85d4d14d","toSide":"bottom"},
		{"id":"95f160da0ff4c8a4","fromNode":"e1323ed7fa9295aa","fromSide":"right","toNode":"2fc7aea1295a65e4","toSide":"left"},
		{"id":"34aa5ae3bd520c15","fromNode":"2fc7aea1295a65e4","fromSide":"right","toNode":"0707ec4b5b023109","toSide":"left"},
		{"id":"457d735ff4c79713","fromNode":"8c3e31c10fa045d8","fromSide":"right","toNode":"1c60be0dd5ff281e","toSide":"left"},
		{"id":"e5a344f0f86469d2","fromNode":"2fc7aea1295a65e4","fromSide":"top","toNode":"181cc23557388283","toSide":"bottom"},
		{"id":"712c4a87e670c777","fromNode":"e1323ed7fa9295aa","fromSide":"right","toNode":"8c3e31c10fa045d8","toSide":"left"},
		{"id":"e5d44beb7317a2f0","fromNode":"1c60be0dd5ff281e","fromSide":"right","toNode":"0707ec4b5b023109","toSide":"left"},
		{"id":"9b850d7643080984","fromNode":"b7bcea7f39de9f04","fromSide":"left","toNode":"94b4618bbb47c1fa","toSide":"right"},
		{"id":"1f7bd9286ec299ba","fromNode":"0707ec4b5b023109","fromSide":"right","toNode":"6f8dca31ed1e0112","toSide":"left"},
		{"id":"a99a4013df708a3a","fromNode":"0707ec4b5b023109","fromSide":"right","toNode":"f55cf6b29f22c43d","toSide":"left"},
		{"id":"aaecf4954a61bddc","fromNode":"20a4b8a4ba668db7","fromSide":"bottom","toNode":"17667cee3c12cf49","toSide":"top"},
		{"id":"35d80a6cb2e6256a","fromNode":"17667cee3c12cf49","fromSide":"bottom","toNode":"e1323ed7fa9295aa","toSide":"top"},
		{"id":"19a2e0432952ced0","fromNode":"16abd413d233f637","fromSide":"top","toNode":"5d905f6c8910912d","toSide":"bottom"},
		{"id":"ebc443c2597f79bd","fromNode":"5d905f6c8910912d","fromSide":"top","toNode":"6a1f44f4ce649afe","toSide":"bottom"},
		{"id":"e1d24bcc06328477","fromNode":"0707ec4b5b023109","fromSide":"bottom","toNode":"b7bcea7f39de9f04","toSide":"top"},
		{"id":"dc7d36bec23e12ed","fromNode":"0707ec4b5b023109","fromSide":"bottom","toNode":"c4bef55d226d9f2d","toSide":"top"},
		{"id":"c164acdfc26fbfca","fromNode":"c4bef55d226d9f2d","fromSide":"bottom","toNode":"82f17ecc160e067b","toSide":"top"},
		{"id":"576fc7d3629dc82b","fromNode":"0707ec4b5b023109","fromSide":"top","toNode":"d6a444107be393e2","toSide":"bottom"},
		{"id":"a70f7f8ea5373fc9","fromNode":"efecee1b85d4d14d","fromSide":"right","toNode":"a83c4681e122399d","toSide":"left"},
		{"id":"db7b3613f95e9948","fromNode":"d6a444107be393e2","fromSide":"top","toNode":"a83c4681e122399d","toSide":"right"},
		{"id":"6a3aecd1f15c000e","fromNode":"a83c4681e122399d","fromSide":"right","toNode":"d6a444107be393e2","toSide":"top"},
		{"id":"0f09e0d823be2db3","fromNode":"efecee1b85d4d14d","fromSide":"left","toNode":"a98cbc58d3a170b7","toSide":"right"},
		{"id":"84b6514039db7f03","fromNode":"a98cbc58d3a170b7","fromSide":"top","toNode":"1e44f734e3ca2eae","toSide":"top"},
		{"id":"2f59c77f8056676d","fromNode":"a98cbc58d3a170b7","fromSide":"top","toNode":"fe03d6cf0d123954","toSide":"bottom"},
		{"id":"975e5355f4ef5dbb","fromNode":"a83c4681e122399d","fromSide":"top","toNode":"f64f10efeafc58a7","toSide":"bottom"},
		{"id":"f83a09ef341b547d","fromNode":"0098615274085117","fromSide":"bottom","toNode":"78d0c8dfe0453bfa","toSide":"top"},
		{"id":"b3d409c1f6343b51","fromNode":"78d0c8dfe0453bfa","fromSide":"left","toNode":"e42b6ea00a3a478f","toSide":"right"},
		{"id":"794858b59fe8eab2","fromNode":"78d0c8dfe0453bfa","fromSide":"bottom","toNode":"3a482ea687c941c1","toSide":"right"},
		{"id":"366389577662d15e","fromNode":"1e44f734e3ca2eae","fromSide":"bottom","toNode":"2e9af087f944ad95","toSide":"top"},
		{"id":"851bfd9733a82ef7","fromNode":"2e9af087f944ad95","fromSide":"bottom","toNode":"165f0ab7d8b79def","toSide":"top"},
		{"id":"7b85b3704c99596d","fromNode":"2e9af087f944ad95","fromSide":"left","toNode":"dd817c0531806cd2","toSide":"right"},
		{"id":"c16c734f4e300464","fromNode":"dd817c0531806cd2","fromSide":"top","toNode":"88f1a92a07e5b12b","toSide":"bottom"},
		{"id":"0db8df5c89538295","fromNode":"88f1a92a07e5b12b","fromSide":"left","toNode":"514b4547d1f96fcc","toSide":"right"},
		{"id":"a640103652f44305","fromNode":"dd817c0531806cd2","fromSide":"left","toNode":"14e2e9fcc14975b1","toSide":"right"},
		{"id":"2efd5d43a301cb46","fromNode":"dd817c0531806cd2","fromSide":"bottom","toNode":"838f77bb16984999","toSide":"top"}
	]
}
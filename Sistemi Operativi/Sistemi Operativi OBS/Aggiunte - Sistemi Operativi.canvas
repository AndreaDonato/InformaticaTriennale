{
	"nodes":[
		{"id":"005e7e1e1c753ec3","type":"text","text":"# Multi-Level Queue (MLQ)\n\nCrea una _ready queue_ che contiene solo i processi del SO, assegnale priorità massima e un algoritmo _preemptive_ come _SRTF_.\n\nCrea una _ready queue_ per i processi da eseguire in _background_, come i download, assegnale priorità media e un algoritmo *SJF*.\n\nInfine, crea una _ready queue_ per i processi utente, assegnale priorità bassa e un algoritmo _non-preemptive_ come _FCFS_.\n\nInfine, crea un algoritmo che sceglie da quale _ready queue_ scegliere i prossimo processo, in un range che varia tra\n\n- **_Strict Priority_** - I processi nella _ready queue_ a priorità $n$ vengono eseguiti solo se tutte le _queue_ con priorità fino a $n-1$ sono libere;\n- **_Round-Robin_** - L'apice della democrazia: a tutte le *queue* viene data la possibilità di _runnare_ i rispettivi processi.\n\nComplimenti, hai implementato un algoritmo **_multi-level queue_**!\n\n","x":-7254,"y":2375,"width":614,"height":500,"color":"4"},
		{"id":"2a9d90b8cc31da54","type":"text","text":"# Priority Scheduling\n\nUna generalizzazione di SJF che assegna la CPU al processo con _priorità_ maggiore (generalmente $0$ rappresenta la priorità massima).\n\nI criteri di scelta per il valore di _priorità_ possono essere definiti\n\n- dal SO (**Internal Priority**);\n- dall'utente (**External Priority**).\n\nLa sua variante _preemptive_ si attiva, come con _SRTF_, quando un nuovo processo entra nella _ready queue_.\n\nLa _starvation_ dei processi a bassa _priorità_ può essere contrastata aumentando quest'ultima proporzionalmente al loro tempo di attesa (**_Aging_**), ma in condizioni di _overload_ del sistema può portare ad un \"appiattimento\" dell'algoritmo (tutti i processi finiscono per avere la stessa priorità).","x":-8740,"y":2375,"width":590,"height":500,"color":"4"},
		{"id":"e286057ad92c4f0c","type":"text","text":"# Round Robin (RR)\n\nIl più semplice algoritmo _preemptive_, _Round Robin_ è un _FCFS_ con il **_timer_**.\n\nQuando la CPU viene assegnata a un processo, parte il _time slice_. Se il processo termina (o si interrompe volontariamente) prima del _timer_ si ricade in _FCFS_ (chiaro che se metto un _time slice_ enorme tendo a ricadere in _FCFS_). Altrimenti, il processo viene interrotto dallo _Scheduler_ e messo in fondo alla _ready queue_.\n\nIn pratica cerca di evitare il _Convoy Effect_ dando un tempo limite ad ogni _CPU Burst_. Tuttavia, l'_average waiting time_ può ancora essere lungo (i processi brevi non hanno alcuna priorità perché nessun processo ha priorità).\n\nIl _trade-off_ empirico tra il ricadere in _FCFS_ (e quindi _Convoy Effect_) e i troppi _Context Switch_ (e quindi tempo CPU sprecato) è **orientativamente** un *time slice* circa $3$ ordini di grandezza più grande rispetto al tempo caratteristico di quest'ultimo (i.e. se il _context switch_ dura $0.1\\,ms$, scelgo un _time slice_ di $100\\,ms$).\n\nLe effettive differenze prestazionali rispetto a _FCFS_ possono variare a seconda di fattori come numero di processi, durata media, ordine di arrivo nella _ready queue_, ...","x":-8049,"y":1684,"width":698,"height":516,"color":"4"},
		{"id":"346edb2cd343ae50","type":"text","text":"# Rappresentazione virtuale della Memoria fisica\n\nQui tende ad esserci molta confusione. Provo a fare ordine. Ragioniamo a 32-bit e 4Kb di pagina.\n\nLa memoria fisica ha una capacità limite di $2^{32}$ byte $= 4$ Gigabyte, banalmente perché non posso referenziare più di quello con un indirizzo fisico a $32$ bit.\n\nAnche la memoria virtuale, con la sua Page Table (**PT**), può referenziare al più $4$ Gigabyte, perché anche gli indirizzi virtuali possono essere al massimo di $32$ bit.\n\nA questo punto però mi ricordo che esiste la paginazione. Questo è quello che succede (credo):\n\n1. Ho un indirizzo virtuale, uso i primi $20$ bit per scorrere la PT del processo per trovare il frame a cui è associata;\n\n2. Tale frame è indicizzato da un numero a $32$ bit, e può trovarsi sia in memoria fisica che in Swap. Questa informazione è contenuta in una tabella di corrispondenza del SO (e suppongo della MMU) che associa $2^{32}$ frame a tre tipi di dato:\n\n\t- Uno dei possibili $2^{20}$ indirizzi per i frame disponibili in memoria fisica, se è allocato attualmente in RAM;\n\t- L'indirizzo nello spazio di swap su disco, se non è allocato in RAM ma lo è su disco;\n\t- Un qualche tipo di NULL se non è allocato.\n\n\n3. Se il frame è in memoria fisica tutto bene, uso gli ultimi $12$ bit dell'indirizzo virtuale per trovare l'offset leggere il dato;\n\n4. Se è in swap, sostituisco quel frame con uno in RAM, poi procedo col punto 3;\n\n5. Se non è allocato SIGSEGV.\n\nA questo punto è chiaro che il *limite teorico della memoria virtuale*, ovvero la quantità di memoria virtuale complessiva gestita dal SO tra RAM e disco, è $2^{32}\\cdot sizeof(page)$ byte, ovvero $2^{44}$ byte $= 16$ Terabyte.","x":-259,"y":-2739,"width":860,"height":700,"color":"4"},
		{"id":"7d169a16a8cca630","type":"file","file":"Memoria/Compaction/FullCompaction.png","x":-259,"y":-3699,"width":860,"height":402},
		{"id":"58f52445ff3fb61e","type":"file","file":"Memoria/Compaction/PartialCompaction.png","x":-259,"y":-3263,"width":860,"height":404},
		{"id":"69f3dd73ee95ff32","type":"text","text":"# (1) Alcune aggiunte a questo sacro .txt\n\n#### MMU\n\nSi trova nel processore. Usa due registri, che forniscono gli indirizzi limite per il processo in analisi. Si chiamano *base* e *limit*. Ogni volta che si genera un indirizzo di memoria in User Mode, la CPU deve controllare che questo sia nel range $[base, base+limit]$ per quel dato programma\n\nLo scorrimento della memoria per mappare i buchi tra i processi è $O(N)$ con $N$ numero di buchi. Può diventare $O(log N)$ se uso un Binary Search Tree (BST) tenendo traccia dei buchi (e quindi non doverli cercare ogni volta).\n\nLe simulazioni dicono che *first fit* e *best fit* sono gli algoritmi più efficienti, il primo è naturalmente più veloce.\nSimulations show that for every 2N allocated blocks, N are lost due to external fragmentation. 1/3 of memory space is wasted on average.\nCi sta una pratica chiamata *Compaction* che appunto compatta i processi per ridurre la frammentazione esterna.\n\n#### Swapping\n\nI processi devono stare in RAM solo quando vengono eseguiti, altrimenti posso fiondarli in SSD e riprenderli quando necessario (swapping).\n- Se l'Address Binding è dinamico posso rilocare come voglio. Prima dello swapping faccio Compaction e ottimizzo la frammentazione esterna\n- Se è Static o Absolute devo ricaricare (o ricompilare) il processo nella stessa identica porzione di memoria. Questo significa in pratica che lo swaping è utile solo se c'è un altro processo che può runnare nelle stesse locazioni, e sfruttare quindi gli interrupt dell'altro. In realtà usare lo swapping in questi casi **NON HA ALCUN SENSO**, perché così sovrascrivo continuamente i dati dei processi swappati. (ma infatti perché non lo dici nelle slides??).\n\n### Paging\n\nIn realtà oggi non si usa lo swapping, ma il paging.\n\n\tProcesses spend 90% of their time accessing only 10% of their allocated memory space.\n\nSe la memoria virtuale è indicizzata da $m$ bit (indirizzi virtuali che variano in range $[0, 2^{m-1}]$) e la dimensione della pagina è $2^n$ (ovvero l'offset interno è indicizzato da $n$ bit) il numero di pagine nella memoria virtuale è $2^{m-n}$. A questo punto è chiaro perché i primi $m-n$ bit di un indrizzo indicizzano la pagina, mentre i restanti $n$ si riferiscono all'offset.","x":-1639,"y":-3699,"width":1238,"height":840,"color":"4"},
		{"id":"a809a009a3c7f901","type":"text","text":"## Nota sul paging e sulle architetture\n\nSiamo abituati a ragionare in byte (8-bit). Quindi se dico che la memoria virtuale è $1024$ byte mi aspetto di avere $1024$ *words* indicizzabili da $log(1024) = 10$ bit.\n\nE questo in linea di principio è vero.\n\nSe però uso un'architettura a 32-bit una *word* consta di $4$ byte, quindi nello stesso spazio avrò chiaramente $256$ *words* indicizzabili da $8$ bit.\n\nA livello di indicizzazione di pagina non cambia nulla.\nSe scelgo come size della pagina $16$ byte ho in entrambi i casi $2^{m-n} = 2^{10-4} = 2^6 = 64$ pagine, motivo per cui mi servono sempre i primi $6$ bit dell'indirizzo.\n\nNel secondo caso però i bit restanti sono $2$, contro i $4$ dell'architettura a 8-bit.\n\nIn un moderno sistema a 64-bit ($8$ byte) notiamo che con questi numeri avremmo $128$ *words* indicizzabili da $7$ bit, ovvero in una pagina da $16$ byte entrano solo due *words*. Questo riduce la lunghezza strettamente necessaria dell'indirizzo, ma in pratica verrà comunque gestito come gruppo di $64$ bit, non potendo essere più corto di una *word*.\n\nIn linea di principio, un indirizzo a $64$ bit può indicizzare $2^{64}$ *words* da $64$ bit, ovvero la massima memoria virtuale (e quindi fisica) possibile sarebbe $2^{64} \\cdot 64$ bit, ovvero $2^{66}$ byte $= 2^{26}$ Terabyte = $16 \\cdot 32$ Exabyte","x":-1639,"y":-2739,"width":619,"height":700,"color":"4"},
		{"id":"f3560ddcee0e71de","type":"text","text":"## Nota sulla nota sul paging e sulle architetture (...)\n\nTutto molto bello, ma resta un discorso teorico o comunque non convenzionale a livello implementativo.\n\nIn pratica è necessario (nonché più economico...?) avere la possibilità di referenziare il singolo bit di memoria, motivo per cui a 32-bit si ha uno spazio di memoria virtuale pari a $2^{32}$ byte, ovvero $4$ Gigabyte, e a 64-bit si arriva \"solo\" a $2^{64}$ byte $= 16$ Exabyte.\n","x":-959,"y":-2389,"width":558,"height":350,"color":"4"},
		{"id":"e4716290f3d5b096","type":"file","file":"Memoria/AddressBinding/Traduzione Indirizzi.png","x":-959,"y":-2719,"width":558,"height":266},
		{"id":"19cda58d82f6e368","type":"text","text":"## Pro e Contro dei vari Address Binding\n\n1. **Absolute Code (Compile Time Binding)**:\n\tIn realtà non entra in classifica, è proprio la versione base e non serve nemmeno un SO.\n\t\n1. **Statically Relocatable Code (Load Time Binding)**:\n\tNon posso modificare gli indirizzi in corso d'opera, quindi quando alloco devo mettermi nel caso peggiore e creare quindi frammentazione interna. Inoltre, in questo tipo di allocazione **NON ENTRA IN GIOCO LA MMU**, quindi nessuno gestisce i Segmentation Fault. Segue che da qualsiasi programma posso scegliere di scrivere (ad esempio con una syscall write()) all'indirizzo, compreso quello di un altro processo o del SO. Naturalmente, oggi il SO richiede la *Kernel Mode* per fare una cosa del genere, ma in passato no (tipo MS-DOS).\n\tIl vantaggio? Non serve la MMU, ovvero non serve supporto HW. Che oggi è un vantaggio sostanzialmente inutile, ma alcuni sistemi \"intermedi\" (troppo complessi per fare Absolute Code ma troppo poco per richiedere un HW che offra MMU) la usano.\n\tQuesto in realtà porta ad un altro svantaggio, perché sono sistemi più vulnerabili ad attacchi come *buffer overflow* (overflow di dati rispetto alla memoria assegnata, che vanno a finire in altri punti della memoria creando il caos) o *injection* (inserimento di codice *malevolo* insieme ai dati).\n\t\n1. **Dynamically Relocatable Code (Execution Time Binding)**:\n\tSe c'è un SO, questo metodo ha quasi tutti pro.\n\tLa MMU gestisce i SIGSEGV e protegge gli altri processi, il SO può riorganizzare tutto come gli è più comodo.\n\tDi contro ogni referenza di memoria richiede tempo di tipo HW (deve runnare la MMU).\n\tNelle slides mette altri contro ma penso sia perché non ha ancora spiegato la paginazione...\n","x":-3899,"y":-3699,"width":600,"height":840,"color":"4"},
		{"id":"ed6ac0281f980f03","type":"text","text":"# Address Binding\n\n1. **Absolute Code (Compile Time Binding)**:\n\tE' specifico per una determinata posizione di memoria. Le variabili e le istruzioni nel codice utilizzano indirizzi assoluti (quindi gli indirizzi logici coincidono con gli indirizzi fisici) espliciti. Se voglio eseguirlo in una zona di memoria diversa devo ricompilare il codice.\n2. **Statically Relocatable Code (Load Time Binding)**:\n\tPuò essere eseguito in qualsiasi posizione di memoria. Utilizza riferimenti relativi anziché assoluti per variabili e istruzioni (resta comunque una corrispondenza tra indirizzi logici e fisici, ma non è esplicita), quindi si può semplicemente ricaricare in memoria piuttosto che ricompilarlo.\n3. **Dynamically Relocatable Code (Execution Time Binding)**:\n    Sfrutta la memoria virtuale, motivo per cui si può spostare anche a runtime. Sfrutta MMU, quindi serve supporto HW.\n\nIn pratica, i pezzi di codice che devono essere modificati a runtime devono essere preferibilmente Dynamically, perché nel chiamare (ad esempio) una grossa malloc non nota a compile time (tipo malloc(n) con n inserito da tastiera) può essere necessario spostare l'intero programma in uno spazio dove entra. \n\nQuesto però richiede complessità aggiuntiva, e se non necessario si evita, usando Statically (ad esempio in una libreria, la cui dimensione su RAM è nota a compile time e si può spostare come blocco a dimensione fissata). \n\nL'Absolute Code in un contesto di SO è scomodo perché deve essere caricato nella esatta porzione di memoria fisica per la quale sono stati scritti staticamente gli indirizzi nel codice, rendendo impossibile un riposizionamento in RAM ed essendo utile solo in sistemi tipo microprocessori.","x":-3254,"y":-3699,"width":753,"height":840,"color":"4"},
		{"id":"6dbca290cf842d6e","type":"text","text":"# Premessa: Indirizzi\n\n- **Logici**: Sono interni al programma e relativi solo e soltanto ad esso, ne definiscono la logica (appunto) interna. Se dichiaro un puntatore di tipo array come\n\t\n\t\tint vettore[10];\n\t\tint valore = vettore[2];\n\tallora $2$ è un indirizzo logico, in questo caso di offset rispetto al puntatore.\n -\n- **Virtuali**: La premessa agli indirizzi virtuali è la seguente:\n\t- Il SO assegna un range di memoria virtuale al processo;\n\t- Il compilatore/linker alloca i puntatori, quindi assegna loro un indirizzo all'interno del range di memoria virtuale, detto appunto *indirizzo virtuale*.\n\n\tA questo punto agli *astratti* indirizzi logici corrisponderanno degli indirizzi virtuali.\n\n\tEsempio: il compilatore assegna al puntatore `vettore` un valore come `0xABADCAFE`, e lascia spazio nei successivi `10*sizeof(int)` indirizzi. All'indirizzo logico `2` di `vettore[2]` corrisponderà l'indirizzo virtuale `0xABADCAFE + 2*sizeof(int)`.\n-\n- **Fisici**: Quelli \"veri\" della RAM, in cui vengono mappati gli indirizzi virtuali di tutti i processi. Non necessariamente all'indirizzo virtuale `0xABADCAFE` corrisponde l'indrizzo fisico `0xABADCAFE`, perché un sistema di *Memory Management Unit (**MMU**)* può spostare la mappatura di ogni indirizzo virtuale in fisico a seconda delle necessità.","x":-2447,"y":-2739,"width":730,"height":700,"color":"4"},
		{"id":"69f392e5d5620920","type":"file","file":"Memoria/memory_hierarchy.png","x":-2447,"y":-3229,"width":730,"height":342},
		{"id":"9a0af77adce9ad06","type":"file","file":"Memoria/AddressBinding/Address Binding.png","x":-3254,"y":-2739,"width":753,"height":700},
		{"id":"652e671c121210e0","type":"text","text":"# Translation Look-aside Buffer (TLB)\n\nC'è una cache anche per la PT, si chiama TLB.\n\nCostituisce un *trade-off* tra la voglia di utilizzare i registri per velocizzare il paging e la necessità di usare la RAM perché mica posso usare 4Mb (se va bene, quindi a 32-bit, altrimenti diventano 8Pb) di registri.\n\nTipicamente ha un numero di entrate bel range $[8, 2048]$, ed esattamente come la cache sfrutta la località.\n\nNaturalmente si pone un problema: la PT è specifica del processo, come gestisco una cache che vedono tutti i processi? \n\n- Livello basic: faccio un wipe totale del TLB a ogni Context Switch;\n- Livello assurdo wow chi l'avrebbe mai detto: salvo sempre una copia del TLB nel PCB del processo.","x":710,"y":-2739,"width":530,"height":700,"color":"4"},
		{"id":"62a83dc4f208244f","type":"text","text":"### Initializing Memory when Starting a Process\n\n1. Process requests for k pages;\n2. If k frames are free then allocate those to the process, otherwise free frames no longer needed (swapping-out);\n3. OS puts each page into a frame and sets the corresponding mapping into the page table (in main memory);\n4. OS marks all previous TLB entries as invalid (i.e., flushes the cache) or restores TLB entries from saved PCB;\n5. As process runs, OS loads TLB missed entries possibly replacing existing entries if TLB is full.\n\n\n#### Saving/Restoring Memory Upon Context Switch\nThe PCB must now contain:\n- The value of the Page Table Base Register (PTBR)\n- Possibly a copy of the TLB entries\n\nOn a context switch:\n- Copy the PTBR value to the PCB\n- Copy the TLB to the PCB (optional)\n- Flush the TLB (if TLB is not saved to/restored from the PCB)\n- Restore the PTBR (i.e., with the value of the new running process)\n- Restore the TLB (if it was previously saved)","x":710,"y":-3699,"width":530,"height":840,"color":"1"},
		{"id":"a23e13dca8a3ad1d","type":"text","text":"# Sharing Pages\nPaging systems can make it very easy to share blocks of memory, since memory doesn't have to be contiguous anymore\n\nThis can be done by simply duplicating page entries of different\nprocesses to the same page frames (both for code and data)\n\nOnly if code is reentrant:\n- it does not write to or change the code (i.e., it is non self-modifying)\n- the code can be shared by multiple processes, as long as each has their own\ncopy of the data and registers, including the instruction register","x":1280,"y":-3699,"width":541,"height":479,"color":"1"},
		{"id":"0c73604c03c3a581","type":"text","text":"# \"Reentrant\"\n\nCodice che non deve preoccuparsi della sincronizzazione, in pratica. Credo. Sicuramente è spiegato meglio [qui](https://it.wikipedia.org/wiki/Codice_rientrante).","x":1280,"y":-3180,"width":541,"height":321,"color":"4"},
		{"id":"ee6c1653941f5cf9","type":"text","text":"# Segmentazione\n\nUn punto di vista diverso rispetto al Paging, ovvero dividere i programmi non in pagine ma in segmenti.\n\nUna Segment Table (**ST**) ha come indice il numero di segmento e come valori gli indirizzi *base* e *limit* che li individuano in memoria.\nQuesto porta come vantaggio una maggiore semplicità nel tenere traccia del codice: una ST ha al più una mezza dozzina di entrate, contro le $\\sim 2^{20}$ di una PT, e può quindi essere tenuta nei registri.\n\n### Combinare Segmentazione e Paging\nSi possono ottenere vantaggi non indifferenti scegliendo di fare paging non sulle singole pagine ma sui segmenti, ovvero gruppi contigui di pagine. Ad esempio, ha senso mappare interamente in RAM l'**heap** del processo se questo è utilizzato, e ha senso deallocarlo in blocco se non lo è. Questo sempre premesso che le pagine contigue non necessariamente sono mappati in frame contigui.\n\nL'indirizzo virtuale a questo punto ha i primi bit (credo siano 3) che indicizzano il segmento e i restanti divisi come prima in pagina e offset. Si noti che sacrificare 3 bit della pagina riduce il numero di pagine utilizzabili, ma in 64-bit passare da $2^{52}$ a $2^{49}$ (e quindi da $\\sim 16$ Eb a $\\sim 2$ Eb di memoria a disposizione del singolo processo) non è una grossa perdita.\n\n","x":-2447,"y":-4520,"width":730,"height":720,"color":"4"},
		{"id":"c117519b0d042f3b","type":"text","text":"# Ulteriori note\n\nE' ovviamente necessario stipare da qualche parte le ST e le PT. Dove?\n\n- Segment tables in a small number of registers page tables in main memory with TLB cache. Faster but the number of segments is limited.\n- Both segment tables and page tables in main memory with TLB cache. TLB lookup done using segment index and page index. Slower but more flexible.\n\nPer condividere la memoria è sufficiente condividere il segmento piuttosto che cercare nella PT le relative pagine.\n\n### Pros and cons (gli piace proprio)\n\n- Questo POV \"mischia\" gli approcci del compilatore, che ragiona per segmenti, e del SO che invece ragiona a pagine.\n- Nonostante le allocazioni inizino come blocchi di codice, finiscono in RAM come singoli frame $\\Rightarrow$ elimino la frammentazione esterna.\n- Di contro è un processo un po' più lento (e qui ci fidiamo).\n- Questo non elimina la frammentazione interna. Se faccio solo paging perdo $\\sim 0.5$ pagine di spazio complessivo, se faccio sia frammentazione che paging ne perdo $\\sim 0.5$ per frammento.","x":-3899,"y":-4520,"width":600,"height":720,"color":"5"},
		{"id":"374ffdc5ef9b8c37","type":"file","file":"Memoria/Paging/Segmentation+Paging.png","x":-3254,"y":-4331,"width":753,"height":343},
		{"id":"4e690bb692a0c595","type":"text","text":"# Tabelle multilivello\n\nAnche solo in un sistema a 32-bit la PT occupa 4Mib, ed è inverosimile pensare di tenerla sempre tutta in memoria\n\nQuindi si pagina la tabella delle pagine.\n\n### Tabelle di hash (HT)\n\nCredo che sostituisca le PT ma non mi è ben chiaro in che modo.\n\nPare sia indicizzata dai possibili output di una fantomatica *hash function* (*\"piuttosto che da interi\"*).\n\n### Inverted Page Table\n\nColpo d'occhio sui processi (PID) a cui sono assegnati attualmente i frame.","x":-4560,"y":-4520,"width":600,"height":720,"color":"5"},
		{"id":"742f4065dd5c5cbc","type":"text","text":"# Gestione Page Fault\n\nCome descritto nel .txt con il bit di validità, con l'aggiunta dei *TLB hit* e *miss* (come con la cache, e d'altronde è una cache, tutto sembra essere la cache di qualcos'altro).\n\nIl problema relativo al capire quale pagina del segmento genera il fault è specifico dell'architettura e richiede supporto HW, che serve anche a salvare lo stato della CPU (e del sistema in generale) per capire come riprendere l'esecuzione.\n\nCi sono infatti due tipi di istruzioni.\n\n- **idempotenti**, per le quali è sufficiente eseguire nuovamente la riga di codice;\n- **non-idempotenti**, come `MOV [%R1], +(%R2)`, che incrementa il valore in `R2` e poi se il riferimento a memoria `[%R1]` fa page fault... eseguo da capo incrementando di nuovo il valore in `R2`? Ovviamente no. Prima di eseguire istruzioni non-idempotenti si gestisce l'eventuale page fault.\n\n### Page Fetching e Page Replacement\n\nIl SO deve stabilire quando è necessario caricare una pagina in memoria fisica (**fetching**) e quale pagina rimuovere se questa è piena (**replacement**).\nIdealmente l'obiettivo è ottimizzare il processo e dare l'impressione di utilizzare la capacità del disco con la velocità della RAM, nonostante l'accesso a disco sia $\\sim 10^5$ volte più lento dell'accesso a memoria.","x":-1639,"y":-4300,"width":1238,"height":500,"color":"4"},
		{"id":"e9bab4cd14415702","type":"text","text":"# Page Fetching\n\n Ci sono tre diverse strategie di fetching:\n\n- **Startup** - Tutte le pagine del processo sono caricate in memoria all'avvio;\n- **Overlays** - La decisione spetta al programmatore;\n- **Demand** - Il SO carica una pagina in memoria solo quando il processo la richiede. Detto anche *lazy swapper* o *pager*.\n\nOvviamente nella maggior parte dei moderni SO si usa quest'ultima.\n\n#### Prefetching\n\nIl pager può provare a ottimizzare assumendo che i processi mostrino località. Quando un processo richiede una pagina, questo carica in RAM anche le pagine contigue.","x":-960,"y":-4920,"width":559,"height":520,"color":"4"},
		{"id":"6b5bb4e98e9e2a28","type":"text","text":"# Page Replacement\n\nSe in RAM c'è abbastanza spazio per fare fetching, tutto bene.\n\nAltrimenti devo decidere quali pagine rimuovere per fare spazio a quelle nuove.\n\nSono possibili diversi algoritmi con diversi vantaggi e svantaggi.\n\n- **Random** - Autoesplicativo, pare funzioni meglio di quanto si possa pensare;\n- **FIFO** - In pratica assume che la pagina più \"vecchia\" sia la meno utilizzata, questo ovviamente non è sempre vero;\n- **MIN (OPT)** - In teoria l'algoritmo ottimale (detto *Minimo* o *Ottimale*), prova a predire la pagina che servirà di meno in futuro. Il come, chiaramente, è un *utile esercizio per il lettore*.\n\t- **LRU** - Rimuove la pagina *Last Recently Used*, cioè in pratica approssima un algoritmo *Ottimale* assumendo che il passato possa predire il futuro.","x":-1639,"y":-4920,"width":559,"height":520,"color":"4"},
		{"id":"760de5855566da94","type":"text","text":"# Second Chance Algorithm (or Clock Algorithm)\n\nPartiamo col dire che è meno precisa di Additional-Reference Bit. Ma allora perché lo si usa? Ovvio, perché è più veloce. Il mondo informatico è tutto un *trade-off*.\nIn pratica è un Single-Bit Reference + FIFO.\n\n- C'è una lista dei frame che si aggiorna secondo una FIFO, che a ogni interrupt del clock rimuove l'ultimo elemento per metterlo in testa;\n- Questo determina soltanto la pagina di partenza da cui il SO scorre la lista.\n- Ogni pagina ha in Single-Bit, inizialmente settato a 1. Puoi vederla come una \"vita\" in stile Super Mario, perché...\n- ... se il SO trova un 1 lo decrementa e passa al frame successivo (da cui *Second Chance*);\n- Se invece trova uno zero questa sarà la vittima. Rimpiazza la pagina e riscrive 1.\n\nNon sembra avere molto senso, vero? Eppure pensa che ne esiste una versione *enhanced*.\n\n#### Enhanced Second Chance Algorithm\n\nSi basa su un'idea abbastanza semplice: \"It is cheaper to replace a page which has not been modified, since the OS does not need to write this back to disk\". In pratica, l'HW tiene conto dell'eventuale modifica con un bit apposito. Si crea quindi una gerarchia di preferenze.\n\n- **(0, 0)** - Nè recentemente usata né modificata. Le vittime perfette.\n- **(0, 1)** - Non usata recentemente, ma modificata.\n- **(1, 0)** - Usata recentemente, ma non modificata.\n- **(1, 1)** - Se possibile, questa pagina andrebbe mantenuta in memoria.\n\nIl SO scorre la lista alla ricerca del primo frame **(0, 0)**, se non lo trova scorre nuovamente cercando un frame **(0, 1)**, e così via.","x":-3254,"y":-5480,"width":753,"height":820,"color":"4"},
		{"id":"b5aedc73d018cc9e","type":"text","text":"# Belady's Anomaly\n\nSe incremento la memoria fisica diminuisco i page fault, giusto?\n\nNo. O almeno, non sempre.\n\nAlcuni algoritmi, come FIFO, possono addirittura peggiorare le proprie prestazioni con un aumento di memoria. Intuitivamente, questo è dovuto al fatto che non considera l'uso delle pagine e le rimuove \"a giro\". Infatti, in pratica, è un algoritmo di Round Robin e soffre degli stessi problemi (vedi Scheduling Algorithms, in basso a sinistra).\n\nAltri, come LRU, possono solo migliorare. Rimuovendo le pagine inutilizzate da più tempo tende a mantenere sempre in memoria le pagine referenziate più spesso (soprattutto secondo la legge empirica del 90-10).","x":-1639,"y":-5480,"width":559,"height":440,"color":"4"},
		{"id":"ab7ce62182178f88","type":"text","text":"# Swap Space\n\nSpazio su disco per le pagine che non entrano in RAM. Può essere una partizione dedicata (e.g. Linux) o una cartella del filesystem (e.g. MacOS).\n\nGeneralmente quando si fa **swap out** (ovvero fetching, dal punto di vista del SO) si salva una copia della pagina richiesta.\n\nOra, le pagine possono essere di due tipi, e sono gestite in modi diversi.\n\n- Codice, quindi *read-only*. Non essendo modificabile, è possibile risalire all'originale dal codice sorgente\n- Dati, quindi modificabile. Devo farne ogni volta una copia.","x":-960,"y":-5480,"width":559,"height":440,"color":"4"},
		{"id":"23b1b309c92014a7","type":"text","text":"# La LRU perfetta non esist...\n\nNo, per davvero. Come la implemento in pratica?\n\n- Salvando i tempi di accesso e facendo uno scan lineare di tutte le pagine confrontandola con il *timestamp* attuale. Lentissimo, passiamo oltre.\n- Aggiornando una lista ordinata, così l'algoritmo si limita a controllare l'ultimo elemento. In pratica ho una SCL di supporto di $2^{20}$ elementi di cui devo cambiare un numero assurdo di puntatori per ogni accesso a memoria. In pochissimo tempo. Inverosimile.\n\nIniziamo a capire perché l'algoritmo **Random** funziona sorprendentemente bene.\n\nIn realtà molte implementazioni della MMU forniscono il supporto HW necessario a implementare LRU in modo decente, ma non ottimale. In pratica si perde per strada l'ordine esatto di accesso, mantenendone uno approssimativo. Vediamo come.\n\n- **Single-Reference Bit** - Ogni frame ha un bit che viene settato a 1 in accesso. Periodicamente (interrupt del clock) questo bit viene rimesso a 0, in modo che LRU possa scegliere sostanzialmente a caso tra gli zeri. Per comodità lo chiameremo Gianni.\n- **Additional-Reference Bit** - Chi l'avrebbe mai detto, invece di un solo bit ne uso di più. Per contare, vero? Più o meno. Non conto i singoli accessi, ma \"hai fatto almeno un accesso dall'ultimo interrupt del clock?\" (che si vede da Gianni, che è un bit a parte rispetto agli 8 che contano). A ogni interrupt faccio due cose:\n\t- Shifto a destra gli 8 bit che contano;\n\t- Copio Gianni nel *leftmost bit*, che sarebbe il più significativo degli 8.\n\n\tA questo punto LRU ha a disposizione una pool molto più ristretta (e quindi precisa) per scegliere la sua vittima.\n- **Second Chance Algorithm** - Merita una card dedicata, la trovi a sinistra.","x":-2447,"y":-5480,"width":730,"height":820,"color":"4"},
		{"id":"05216adedc2d6235","type":"text","text":"# Thrashing\n\nQuando il **working set** dei processi occupa più spazio della memoria fisica inizio a fare replacement con pagine attualmente in uso.\n\nQuesto aumenterà significativamente il page fault, e conseguentemente il tempo verrà monopolizzato dalla MMU (piuttosto che dalla ALU, che vorrebbe tanto fare calcoli utili ma non ha i dati).\n\nUn possibile modo di diminuire il rischio di thrashing è sostituire il processo di fetching/replacement *globale* (per come descritto prima) con uno **locale** per ogni singolo processo, in modo da mandare in thrashing solo il processo che esagera col proprio working set.\n\nMa come faccio a sapere quanti frame assegnare a ogni singolo processo?","x":171,"y":-4920,"width":430,"height":520,"color":"4"},
		{"id":"fdb26cc1e8ca8651","type":"text","text":"# Prevedere il working set\n\nFormalmente, il working set $\\Delta$ è l'insieme di pagine referenziate dal processo negli ultimi T (milli)secondi, che generalmente include almeno $O(10^{8})$ istruzioni. Bisogna considerare che per gestire un page fault si perde un tempo corrispondente a $\\sim O(10^{6\\div 7})$ istruzioni.\n\nVisto che così è complicato, si sceglie di inferire una stima di $\\Delta_i$ per campionamento ogni $k$ (e.g. $10^3$) istruzioni eseguite.\n\nAll'atto pratico, il numero di frames riservato per $\\Delta$ viene scelto in modo da mantanere il *page-fault rate* $\\tau$ entro dei valori di soglia prestabiliti.","x":171,"y":-5480,"width":430,"height":440,"color":"4"},
		{"id":"9132abad1267a121","type":"file","file":"Memoria/Thrashing/Thrashing.png","x":710,"y":-4815,"width":529,"height":310},
		{"id":"f03ea06b8cc06adb","type":"file","file":"Memoria/Thrashing/WorkingSet.png","x":710,"y":-5373,"width":530,"height":227},
		{"id":"d4d33725ee010f29","type":"text","text":"# Premesse","x":-9228,"y":-4682,"width":217,"height":50,"color":"6"},
		{"id":"925b75588817e4f2","type":"text","text":"# Generale","x":-9228,"y":-4207,"width":217,"height":50,"color":"6"},
		{"id":"f9bd700671836856","type":"text","text":"# Assembly","x":-9228,"y":-3632,"width":217,"height":60,"color":"6"},
		{"id":"5d912aa428876e90","type":"text","text":"# Altro","x":-9228,"y":-3032,"width":217,"height":50,"color":"6"},
		{"id":"05a52d5c383fdd33","type":"file","file":"Demetrescu/vonneumannDemetrescu.txt","x":-8688,"y":-3801,"width":400,"height":400,"color":"4"},
		{"id":"91a7b729904ab462","type":"file","file":"Demetrescu/IA-32.txt","x":-8071,"y":-3802,"width":400,"height":400,"color":"4"},
		{"id":"4ed8448bbff5587f","type":"file","file":"Demetrescu/funzioni_con_parametri.txt","x":-7440,"y":-3802,"width":400,"height":400,"color":"4"},
		{"id":"d2c45ccedbf34eb0","type":"file","file":"Demetrescu/ABI.txt","x":-6820,"y":-3802,"width":400,"height":400,"color":"4"},
		{"id":"78c933cd845defb1","type":"file","file":"Demetrescu/Ottimizzazione.txt","x":-8688,"y":-3207,"width":400,"height":400,"color":"4"},
		{"id":"1b3e6646aedc9b50","type":"file","file":"TdP/vonneumann.txt","x":-8688,"y":-4382,"width":400,"height":400,"color":"4"},
		{"id":"394c80ddc305d5fc","type":"file","file":"Demetrescu/memoria.txt","x":-2447,"y":-3699,"width":730,"height":400,"color":"4"},
		{"id":"8c7076684bac10a2","type":"text","text":"\n# Condizioni di Deadlock\n\nPossono verificarsi dei *deadlock* se l'ambiente consente le seguenti situazioni:\n\n- **_Mutual Exclusion_** - Una data risorsa non può essere eseguita da più *thread* contemporaneamente. Questo è necessario se si pensa alle sezioni critiche, ed è ovvio se si pensa, ad esempio, alla modalità schermo intero;\n- **_Hold-and-Wait_** - I processi possono bloccare le risorse e devono necessariamente aspettare una `signal` per rilasciarle;\n- **_Circular Waiting_** - Si possono verificare situazioni in cui in un set di $N$ _threads_ l'$i$-esimo aspetta una `signal` dall'$(i+1)\\%n$-esimo. \n\nPerché si concretizzi una situazione di *deadlock* è necessario che si verifichino contemporaneamente tutte e $4$ le condizioni. Segue che per **prevenirlo** è sufficiente che anche solo una di queste non sia verificata.\n\nPer individuare un *deadlock* è necessario un algoritmo di scan su grafo orientato $G = (V, E)$, detto **_Resource Allocation Graph (RAG)_** per trovare i loop. Se $V$ è il numero di vertici ed $E$ il numero di frecce, un algoritmo di ricerca in profondità (**DFS**, *depth-first search*) richiede un tempo di ordine $|V|+|E|$. **_Qui le slides dicono che il problema è $O(|V|^2)$ perché $|E| = O(|V|^2)$. Non trovo alcuna corrispondenza, se non Wikipedia che riporta una complessità $O(n^2)$ dove $n$ è il numero di processi._**\n\nUn modo alternativo per la prevenzione dei *deadlock* consiste nel definire degli stati sicuri (**_Safe States_**) nei quali non si verifica almeno una delle condizioni sopracitate.","x":-1837,"y":5130,"width":1111,"height":493,"color":"4"},
		{"id":"28ef98e44e010a54","type":"text","text":"# Safe State\n\nUno *Stato* (inteso come insieme di thread attivi) è definito *Sicuro* se esiste almeno una sequenza ordinata dei *thread* tale che **_per ogni thread_** è rispettata la condizione\n\n$$\nm_i - c_i \\leq R - C + \\sum_{j < i} c_j\n$$\ndove\n\n- $m_i$ è il massimo numero di risorse che può richiedere l'i-esimo thread;\n- $c_i$ è il numero di risorse attualmente assegnate all'i-esimo thread;\n- $R$ è il numero totale di risorse;\n- $C = \\sum_i^n c_i$ è il numero complessivo di risorse attualmente assegnate ai thread.\n\nSegue naturalmente che\n\n- $R - C$ è il numero di risorse disponibili (non assegnate ad alcun thread);\n- $m_i - c_i$ è il massimo numero di risorse che l'i-esimo thread *potrebbe* ancora richiedere;\n- $\\sum_{j < i} c_j$ è il numero di risorse assegnate a tutti i thread precedenti all'i-esimo.\n\nL'idea è che se il thread $i$-esimo può richiedere tutte le risorse potenzialmente necessarie, questo potrà terminare l'esecuzione per primo e le rilascerà a disposizione del thread $(i+1)$-esimo. Si noti che\n\n- Ogni sequenza che rispetta la condizione di Safe State è un possibile ordine di esecuzione dei thread;\n- Un furbo test preliminare prima di testare tutte le sequenze può essere $m_i \\leq R$ $\\forall i$. Se anche solo un thread potrebbe richiedere più risorse di quelle disponibili lo stato è sicuramente unsafe;\n- Essendo una sequenza ordinata, per $N$ threads è in linea di principio necessario testare $N!$ sequenze;\n- L'algoritmo che generalizza questi $N!$ test a $M$ diversi tipi di risorse è detto **_Algoritmo del Banchiere (Banker's Algorithm)._**","x":-1837,"y":5697,"width":1111,"height":740,"color":"4"},
		{"id":"0bac8ddd0cc0ea48","type":"text","text":"# Livello base - Lock\n\nImmagina il *lock* come un lasciapassare, un oggetto unico che può avere solo una persona per volta. Chi ha il *lock* può entrare nelle sezioni critiche, gli altri aspettano. Quando costui finisce i suoi doveri nella sezione critica libera il *lock*, che viene assegnato a uno dei processi/*thread* in attesa. Viene implementato tramite due primitive:\n- `Lock.acquire()` --> si mette in attesa che il *lock* si liberi, quindi lo prende per sè;\n- `Lock.release()` --> libera il *lock* e sveglia uno dei *thread* nella *pool* di attesa creata da `acquire`.\n\nNell'esempio di Bob e Carla (che non so perché non si chiami Alice) il codice diventa simmetrico:\n\n\tLock.acquire()\n\tif(!milk):\n\t\tbuy_milk()\n\tLock.release()\n\nA questo punto si rende necessario rendere le primitive istruzioni atomiche, ovvero non interrompibili da un *context-switch* dello *scheduler*.","x":-599,"y":4019,"width":921,"height":540,"color":"4"},
		{"id":"933c1f33f83329d3","type":"text","text":"# Come si implementa la sincronizzazione?\n\nIn generale si possono individuare delle **SEZIONI CRITICHE**, come ad esempio zone di memoria condivisa, sulle quali è fondamentale che più processi/*thread* non operino simultaneamente per evitare incongruenze. La soluzione è **bloccare l'accesso alla sezione critica** nel momento in cui un *thread* vi entra, per poi liberarlo quando ne esce.\n\nUn esempio può essere il seguente. Siamo a casa dei *thread* Bob e Carla, la sezione critica è andare a comprare il latte se non ce n'è. Assumendo che le singole istruzioni siano atomiche (ovvero non interrompibili), una soluzione *naive* può essere quella di sinistra, che rispetta i criteri di:\n- **_Mutual Exclusion_**: solo un *thread* alla volta può entrare nella sezione critica, ovvero solo uno tra Bob e Carla compra il latte se necessario;\n- **_Liveness_**: se non c'è alcun *thread* in sezione critica, tutti quelli che vogliono entrarci devono poterlo fare, ovvero almeno uno tra Bob e Carla deve poter comprare il latte ($\\Rightarrow$ non permettere a nessuno di entrare in una zona critica non è una buona soluzione);\n- **_Bounded Waiting_**: l'attesa per l'ingresso nella sezione critica non deve essere indefinita, ovvero sia Bob che Carla, a seconda dello *scheduling* dei rispettivi *thread*, hanno la possibilità di andare a comprare il latte.\n\nTuttavia si può fare di meglio. Posto di avere un'implementazione HW che lo consente, esistono delle primitive atomiche *ad-hoc* per la sincronizzazione.","x":-1837,"y":4020,"width":1111,"height":540,"color":"4"},
		{"id":"d1b1da8e14a89c26","type":"text","text":"# Livello intermedio - Semaforo (estensione del lock)\n\nImmaginalo come un semaforo di un parcheggio coperto. Ci sono $N$ posti liberi (valore di inizializzazione del semaforo) e ogni macchina quando accede decrementa il contatore di posti. Se il counter è zero o negativo le macchine che vogliono entrare devono aspettare che ne esca una. Tutte queste operazioni sono svolte dalla funzione `wait` (anche detta *P* o *Down*, di decremento, che in pratica controlla se il numero è positivo, se non lo è aspetta, se lo è lo decrementa di 1). Quando una macchina esce, segnala che si è liberato un posto, chiamando appunto la funzione `signal` (anche detta *V* o *Up*, che incrementa).\n\nA livello implementativo puoi pensarlo come una classe contenente il contatore e le implementazioni delle funzioni `wait` e `signal`, oltre a una struttura che gestisce la coda dei processi in attesa.\n\nSe il semaforo può assumere solo valori 0 e 1 si ricade nel caso di *lock* (ma in questo caso viene chiamato **_mutex_**... perché sì. Credo stia tipo per \"mutually exclusive\").\n\nAltrimenti, posso inizializzare a zero e aspettare che qualcosa mi dia il verde, tipo `waitpid`.","x":-600,"y":4619,"width":922,"height":442,"color":"4"},
		{"id":"26cfad6010ff7969","type":"text","text":"# Cos'è un Deadlock\n\nUn _**deadlock**_ è una situazione in cui risulta impossibile sbloccare una o più risorse tramite funzioni _signal_, verosimilmente perché l'esecuzione della `signal(Risorsa)` ha come requisito `Risorsa` stessa o perché le condizioni di sblocco entrano in un loop che non si può più rompere.\n\nIntuitivamente, una condizione in cui due o più *thread* aspettano un evento che può essere generato solo da quei *thread* stessi.\n\nDa non confondere con la _Starvation_, che si verifica quando un _thread_ attende indefinitamente una risorsa mentre altri _thread_ stanno effettivamente progredendo nell'utilizzo di quella risorsa (in questo caso il sistema non è completamente bloccato).","x":-1837,"y":4800,"width":1111,"height":261,"color":"6"},
		{"id":"fad3582cc9b8fe57","type":"text","text":"# Dove è necessario sincronizzare i thread?\n\nIl conflitto per le risorse può avvenire su due livelli:\n- **_Process Contention Scope (PCS):_** più *thread* Utente dello stesso processo (NON mappati in altrettanti thread kernel) dovrebbero essere sincronizzati dal processo (ovvero dal programmatore), ma il SO può intervenire in caso di conflitti irrisolti;\n- **_System Contention Scope (SCS):_** più *thread* Kernel oppure più _thread_ di diversi processi devono essere sincronizzati dallo scheduler del SO.\n\nDue cose da notare:\n- è il Kernel a dover notificare al processo se c'è conflitto per le risorse tra i suoi *thread*. Questo viene fatto con le **_UPCALL_**, una sorta di \"inverso\" delle *syscall* (ovvero Kernel $\\rightarrow$ User). Le librerie che gestiscono i *thread* hanno degli *upcall handler*;\n-  Il processo può in linea di principio non sincronizzare i propri *thread*. Questo non crea errori a livello di integrità della macchina (perché poi diventano *thread* Kernel sincronizzati dal SO) ma a livello di correttezza del codice (perché le modifiche a memoria possono non risultare ordinate correttamente).\n\n","x":-1837,"y":3540,"width":1111,"height":420,"color":"4"},
		{"id":"004837f0a7396bbf","type":"file","file":"Processi/Threads/naive_sync.png","x":-2785,"y":3925,"width":846,"height":400},
		{"id":"e00a97cccf420735","type":"text","text":"# Resource Allocation Graph\n\nMetodo grafico per visualizzare le dinamiche tra le risorse che vengono assegnate e i thread che le richiedono.\n\nCi sono due tipi di vertici (thread e risorse) e due tipi di frecce\n\n- thread --> risorsa (Richiesta)\n- risorsa --> thread (Assegnazione)\n\nSe una risorsa è libera (cioè non assegnata ad alcun thread, o il thread a cui era assegnata termina l'esecuzione) questa può andare ai thread che la richiedono. Un thread che fa richiesta di una risorsa ne ha bisogno per completare l'esecuzione e liberare tutte le risorse che sta bloccando.\n\nA questo punto è ovvio che **_condizione necessaria_** perché si verifichi un deadlock è che in questo grafico vi sia un loop.\n\nNon è sufficiente, perché è possibile che ogni risorsa possa essere assegnata contemporaneamente a più thread, motivo per cui in genere al posto di scrivere solo \"$r_3$\" si mettono anche dei pallini a simboleggiare la molteplicità della risorsa, che qui non c'è...","x":-3400,"y":4800,"width":526,"height":659,"color":"4"},
		{"id":"9c55c12867f0cfe8","type":"text","text":"# Estensione RAG\n\nL'uso dei _Safe State_ porta alla definizione di un terzo tipo di freccia, detta **_claim_**.\n\nIn pratica una freccia di claim $(t_i, r_j)$ indica che il processo $t_i$ *potrebbe* in futuro richiedere la risorsa $r_j$.\n\nSegue che soddisfare una claim significa rendere la freccia tratteggiata $(t_i, r_j)$ una freccia di assegnazione $(r_j, t_i)$.\n\nSe nell'esempio sotto soddisfo $(t_4, r_2)$ creo una freccia verde $(r_2, t_4)$ generando potenzialmente un ciclo se $(t_3, r_2)$ diventa una freccia rossa di richiesta $\\Rightarrow$ Unsafe State","x":-3400,"y":5539,"width":526,"height":460,"color":"4"},
		{"id":"b38a5df100f9850b","type":"text","text":"# [Algoritmo del Banchiere](https://it.wikipedia.org/wiki/Algoritmo_del_banchiere)\n\nAlgoritmo che decide se assegnare o meno le risorse ai processi.\n\nI thread devono preventivamente dichiarare il proprio $m_i$. A questo punto i criteri per l'assegnazione sono sostanzialmente tre:\n\n- Le risorse devono essere disponibili;\n- La richiesta deve essere coerente con il numero massimo di risorse potenzialmente necessarie al thread (e.g. se un thread dichiara $m_i = 8$ e utilizza $c_i = 6$, una richiesta di ulteriori $4$ risorse non è coerente);\n- A seguito dell'assegnazione il sistema deve essere ancora in un Safe State.\n\nSe anche una sola delle condizioni non è verificata, la richiesta viene rifiutata.\n\nWikipedia lo spiega meglio di me, link nel titolo.","x":-2778,"y":5697,"width":839,"height":740,"color":"4"},
		{"id":"27e4fdde4c9ad72d","type":"file","file":"Processi/Deadlock/Deadlock 2.png","x":-2338,"y":4800,"width":399,"height":261},
		{"id":"61fad2ad255cf82a","type":"file","file":"Processi/Deadlock/Deadlock 1.png","x":-2779,"y":4800,"width":403,"height":261},
		{"id":"7c61dcb5932faf1f","type":"text","text":"# Categorie di Algoritmi di Scheduling\n\nGli algoritmi di _scheduling_ si dividono in due categorie, che differiscono sostanzialmente per la capacità di interrompere un processo in esecuzione.\n\n### **_Non-preemptive Scheduling_**\nGli algoritmi che rientrano in questa categoria non interrompono i processi in esecuzione, ma si limitano a scegliere il successivo. Questo significa che un processo _running_ resterà tale fino al suo completamento oppure fino a quando non deciderà volontariamente di sospendersi (e.g. per aspettare il completamento di una lettura o scrittura su I/O). \n- I processi mantengono il proprio _CPU Burst_ finché vogliono, salvo ovviamente non ricevano un segnale brutale come _SIGKILL_;\n- Non essendoci un meccanismo per interrompere i processi lunghi, questi possono ritardare l'esecuzione di processi più brevi che seguono nella coda (**_Convoy Effect_**);\n- Nel complesso, gli algoritmi _non-preemptive_ sono passivi e statici;\n- Tendenzialmente implementati in sistemi _embedded_ in cui è più importante massimizzare l'utilizzo attivo della CPU piuttosto che la _responsiveness_.\n\n\n###  **_Preemptive Scheduling_**\nQuesti algoritmi possono interrompere i processi durante il loro _Burst_, scegliendo poi il successivo. Spesso utilizzano un **_timer_** che invia un _interrupt_ a intervalli di tempo regolari (detti **_time slice_**), oppure l'algoritmo è reattivo ad **_eventi di sincronizzazione_** (e.g. la notifica di ritorno da un'operazione di I/O, quale ad esempio \"heyy ho finito di scrivere <3\").\n\n- Presenta la complessità aggiuntiva dello scegliere (e implementare) la logica e i parametri di _interrupt_ (e.g. la lunghezza del _time slice_);\n- In pratica è un _non-preemptive scheduler_ che può scegliere quando interrompere i processi (ci si riferisce a questo superpotere come **_preemption_**), motivo per cui ha un ruolo attivo e dinamico;\n - Poter interrompere i processi è un'arma contro il _convoy effect_, ma dipende dall'implementazione;\n - Fondamentale nei sistemi utente, perché ottimizza la _responsiveness_ (e.g. muovere il mouse è un bombardamento di *interrupt*).","x":-6569,"y":1684,"width":698,"height":1191,"color":"4"},
		{"id":"c5128c9a62b77d1c","type":"text","text":"# Istruzioni Privilegiate - La Kernel Mode\n\nIl SO è una macchina molto complessa e delicata, che deve gestire un gran quantitativo di operazioni in modo efficiente. Proprio per questo farà di tutto per non farti mettere mano nel suo lavoro certosino.\n\nCi sono istruzioni molto pericolose che non possono essere lasciate al libero arbitrio d'uso dell'utente o dei programmi, come HLT, che blocca il processore in attesa di un interrupt, o INT che ne genera uno.\n\nQuindi c'è un singolo bit protetto nella CPU che autorizza o meno certe operazioni, in particolare\n\n- 1 - Corrisponde alla **User Mode**. Istruzioni come HLT vengono ignorate o trattate come errori.\n- 0 - Corrisponde alla **Kernel Mode**. Viene gestita solo dal SO, e tutte le operazioni sono consentite.\n\nL'HW deve pertanto supportare almeno queste due modalità, ma sono implementabili gerarchie di privilegi più fini. Tipiche richieste vietate in User Mode possono essere l'accesso diretto all'I/O o alla RAM, passaggio in Kernel Mode o modifica delle strutture dati del SO.\n\nQualsiasi tipo di evento che fa passare la CPU in Kernel Mode è detto **TRAP**, mentre con molta fantasia il passaggio inverso è detto **Return from TRAP**.","x":-5787,"y":-496,"width":857,"height":480,"color":"4"},
		{"id":"7f02462535d305da","type":"file","file":"Sicurezza e syscall/ItsATrap.png","x":-5787,"y":67,"width":857,"height":387},
		{"id":"c0aaa4d8737bbd67","type":"text","text":"### Quanti processi?\n\nIn pratica, il SO deve anche anche rendersi conto di quanti processi contemporanei è verosimile autorizzare, posticipando o addirittura negando l'avvio di quelli per i quali non c'è abbastanza spazio.","x":-260,"y":-5480,"width":300,"height":440,"color":"4"},
		{"id":"2277df60d0b7b90f","type":"text","text":"# Memoria Secondaria","x":2860,"y":-1920,"width":360,"height":60,"color":"3"},
		{"id":"deedc18089e093f1","type":"text","text":"### 64-bit\n\nGiusto per ridere, a 64-bit il SO può gestire una memoria apparente di $2^{76}$ byte $= 64$ Zib $\\simeq 64$ Zettabyte ($O(10^{21})$). Considera che i Terabyte sono $O(10^{12})$.","x":-29,"y":-1940,"width":400,"height":194,"color":"4"},
		{"id":"46a10f1736b333eb","type":"file","file":"Memoria/Binaryvdecimal.png","x":-1280,"y":-1311,"width":600,"height":464},
		{"id":"edd84b5881ba408b","type":"text","text":"# Attenzione alle conversioni!!\n\nLavorando con i [byte](https://it.wikipedia.org/wiki/Byte) il fatto che $2^{10} \\simeq 10^3$ (per esempio Gib $\\simeq$ Gb) porta a fare errori tanto più grandi quanto è grande il prefisso.","x":-1210,"y":-684,"width":461,"height":160,"color":"6"},
		{"id":"ccea465ee5a66f66","type":"text","text":"# Processi","x":-2248,"y":1480,"width":329,"height":50,"color":"6"},
		{"id":"a8d94719750798b3","type":"file","file":"Processi/Threads/thread.png","x":-1120,"y":2510,"width":400,"height":256},
		{"id":"b21a9f5130d5c590","type":"text","text":"# Threads","x":-1460,"y":2056,"width":250,"height":60,"color":"6"},
		{"id":"7baf25458002b00c","type":"text","text":"# Kernel Memory\n\nIl Kernel, contrariamente a tutto il resto del sistema, non può permettersi di fare Page Fault. Alloca memoria direttamente e solo in RAM ignorando la *feature* dei frame. Ha due modi principali per farlo.\n\n- **Buddy Allocator** - All'inizio, tutta la memoria fisica disponibile, diciamo $64$ Kb, viene trattata come un unico grande blocco di memoria. Se devo allocare $7$ Kb l'algoritmo dividerà il blocco da $64$ in due da $32$ (da cui *Buddy*), e continuerà iterativamente fino a trovare un *Best Fit*, in questo caso alla coppia da $8$. Il primo dei due blocchi da $8$ viene allocato, il secondo resta libero. Interessante notare che in deallocazione questo algoritmo controlla sempre se anche il *Buddy* del segmento è libero, in modo da poter riunire i blocchi e limitare la frammentazione interna.\n- **Slab Allocator** - Anzitutto divide i propri oggetti (strutture, dati, ...) per dimensione. Poi riserva dei range di memoria fisica (detti *Slab*) per ogni dimensione che può voler allocare. Il vantaggio pratico è che se in una certa zona so che allocherò solo oggetti lunghi, diciamo, $7$ Kb posso inserirli direttamente compattati, eliminando la frammentazione interna.","x":-4930,"y":-2260,"width":545,"height":700,"color":"4"},
		{"id":"06c47d975b9c7d82","type":"text","text":"# Dischi Magnetici\n\nIncludono i *Dischi Rigidi* (HDD) e i *Floppy*.\nDispositivi con uno o più *platters* coperti da un mezzo magnetico sia sopra che sotto, ovvero ogni *platter* ha due *heads* $H$ divise in anelli concentrici detti *tracks* (utile conoscere $\\#tracks/head := T$). Tutti i *tracks* con lo stesso raggio formano un *cylinder*. Ogni *track* è divisa in *sectors* ($\\#sectors/track := S$), tipicamente da $B = 512$ byte. A questo punto la formuletta magica per la capacità è $$C = H\\cdot T\\cdot S\\cdot B$$Evviva! Fino agli anni '80 mettevano $S$ indipendente dalla distanza dal centro della *track*, poi hanno capito che per sfruttare meglio la velocità angolare dovevano aumentare la densità di *sectors* più esterni. Gli hanno dato perfino un nome, si chiama Zone Bit Recording (ZBR). Chissà quanto ne andava fiero il suo creatore.\n\nUn blocco di dati è identificato dal trittico $(head, track, sector)$, e il trasferimento dati consta di tre passi:\n\n- **Posizionamento**, la *r/w head* si allinea alla coordinata *track*. Rappresenta il collo di bottiglia del processo $(\\sim 10\\,\\, ms)$;\n- **Rotazione**, il disco ruota fino a selezionare il giusto *sector* $(\\sim 4\\,\\, ms)$;\n- **Trasferimento**, il passaggio elettronico detto *transfer rate* o *bandwidth*, che si aggira intorno ai $100\\,\\,Mb/s$ $(\\sim 1\\,\\,ms)$.\n\nPer migliorare le prestazioni o riduco le dimensioni o aumento $\\omega$.","x":2740,"y":-2739,"width":600,"height":700,"color":"4"},
		{"id":"c93ccfe2826bfc84","type":"file","file":"Memoria/HardDisk.png","x":2000,"y":-2642,"width":678,"height":506},
		{"id":"c5eb197b387106c9","type":"text","text":"#### Rischi\n\nLa distanza tra la *r/w head* e il disco è molto sottile. In caso di contatto, il disco si danneggia o si rompe.\n\nQuando il computer è spento, le testine vengono \"parcheggiate\" dove non possono fare danni.\n\n","x":2740,"y":-3459,"width":260,"height":600,"color":"4"},
		{"id":"6494019ed201af83","type":"text","text":"#### Protocolli\nSono connessi tramite il *I/O Bus* con protocolli come *EIDE, ATA, SATA, USB. FC, SCSI*.\n#### Controllers\n\nAi capi del Bus ci sono\n- **Host Controller**, lato CPU, che ne prende gli ordini;\n- **Disk Controller**, che gestisce la *cache* del disco nella quale vengono appoggiati i dati trasferiti elettronicamente sul Bus.\n","x":3080,"y":-3459,"width":260,"height":600,"color":"4"},
		{"id":"857795b982b5006c","type":"text","text":"#### Indicizzazione\n\nLa memoria fisica viene vista come un array unidimensionale.\n\nL'elemento 0 è il primo settore del *track* più esterno della base di un cilindro.\n\nSi prosegue ruotando ed esaurendo la *track*, si passa a quella subito sopra nello stesso cilindro.\n\nEsaurito il cilindro più esterno si passa a quello immediatamente più interno.","x":2400,"y":-3459,"width":260,"height":600,"color":"4"},
		{"id":"1f6e7fb2cae77036","type":"text","text":"#### Disk Scheduling\n\nQuello che può fare il SO per ottimizzare i tempi di r/w da disco magnetico.\n\nNon credo di voler approfondire, essendo tecnologia vecchia...","x":3420,"y":-3459,"width":260,"height":600,"color":"5"},
		{"id":"e4d567401ca48648","type":"text","text":"# Dischi a Stato Solido (SSD)\n\nNon ha un'implementazione specifica, può essere *flash memory* come *DRAM* mantenuta \"sveglia\" da una batteria.\n\nNon ha parti mobili, e accede ai blocchi in modo diretto.\nLa lettura è velocissima e non ha bisogno di Scheduling alcuno.\nSono talmente veloci che il collo di bottiglia può diventare l'*I/O Bus*, motivo per cui hanno iniziato a collegarle al *PCI Bus*. Cioè l'hanno messo tipo al tavolo dei grandi.\n\nTutti questi vantaggi hanno dei contraltari.\n\n- La scrittura è limitata. Non esiste l'*overwriting* diretto, ma bisogna cancellare e riscrivere.\n- Non solo! Il singolo blocco ha un numero limitato di cicli di *overwriting* disponibili nel corso della vita del prodotto.\n- Spesso dereferenzia la memoria anziché cancellarla, quindi serve un sistema di *garbage collection*.","x":3420,"y":-2739,"width":600,"height":700,"color":"5"},
		{"id":"7837e938756397ea","type":"text","text":"#### Nastri Magnetici\n\nSono lentissimi e si usavano una volta come backup dei dischi magnetici, i quali li hanno fortunatamente sostituiti.\n\nDetti anche \"memoria terziaria\", pensa te quanto dovevano fare schifo.","x":3760,"y":-3459,"width":260,"height":600,"color":"4"},
		{"id":"b3de1e1183a15476","type":"text","text":"#### Strutture RAID\n\nMetti in parallelo tanti dischi magnetici di bassa qualità con gli stessi dati dentro *et voilà*, avrai creato un *Redundant Array of Inexpensive Disks*.\n\nNo, non è uno scherzo.\nServe ad aumentare le *performance* e la *reliability* a fronte della possibilità di *disk failure*.\n\nQueste strutture hanno addirittura 7 livelli di complessità.\n\nPare che ad oggi siano passati da *Inexpensive* a *Independent*, che per il marketing è meglio.","x":2060,"y":-3459,"width":260,"height":601,"color":"4"},
		{"id":"561a1434023c1429","type":"file","file":"Demetrescu/segnali.txt","x":-5760,"y":-881,"width":381,"height":282,"color":"4"},
		{"id":"b763de7850a80c53","type":"file","file":"Sicurezza e syscall/privilege.png","x":-5340,"y":-881,"width":383,"height":283},
		{"id":"ebda4cf153d6ae26","type":"text","text":"# Alterazioni del Flusso Normale\n\nSi definisce **_flusso del controllo normale_** una situazione in cui il flusso delle istruzioni alla CPU è dettato\nunicamente dalla struttura del programma. Possono esserci eventi che alterano questo schema.\n\n- **_Alterazione Asincrona (INTERRUPT)_** - è un evento generato all'esterno della CPU, da dispositivo, come premere Ctrl+x su terminale, o la terminazione di un timer. Il SO tipicamente usa un timer per dividere l'utilizzo delle risorse tra i vari processi che le richiedono. Sono \"asincrone\" nel senso che possono avvenire in qualsiasi momento, indipendentemente dal codice.\n\t- Il programma non è tenuto a gestire subito un _Interrupt_. Se sta eseguendo operazioni delicate, l'HW impedisce alla CPU di elaborare l'_Interrupt_ finché il programma non esce dalla sezione critica. Questo supporto HW è detto **disabling interrupts**;\n\t- e.g. un _Interrupt_ non può essere gestito durante l'esecuzione di operazioni *atomiche*, che vanno cioè eseguite per intero senza interruzioni, pena ad esempio lasciare la memoria in uno stato inconsistente. Un esempio è l'operazione di scrittura in memoria: se eseguita solo parzialmente, si potrebbero modificare solo la metà dei byte, creando un dato insensato. \n\n- **_Alterazione Sincrona_** - è un evento generato dalla CPU stessa mentre elabora il codice del programma in esecuzione. Si dice *sincrona* poiché avviene in un punto del codice ben determinato, e il programma è costretto a fermarsi per gestirla. Ci sono tre tipi di alterazioni sincrone:\n\t- **TRAP (o Software Interrupt)** - è un'istruzione speciale dell'ISA (_syscall_) con cui un processo può esplicitamente passare il controllo al SO, ad esempio per prendere un input da tastiera. Si tratta di un'interruzione **volontaria recuperabile**, nel senso che il processo poi riprende dall'istruzione successiva;\n\n\t- **FAULT**: evento generato in seguito a una condizione di errore. **Non è volontaria** e **può essere recuperabile**. \n\t\t- e.g. un *fault* recuperabile è il PAGE FAULT, ovvero il processo prova ad accedere a dati in memoria che sono stati virtualizzati su disco: il controllo passa al SO che  ricarica i dati in memoria e passa nuovamente il controllo al processo dall'istruzione che aveva dato il *fault*;\n\t\t- e.g. un *fault* non recuperabile è una divisione per 0;\n\n\t- **ABORT**: evento fatale quanto raro, provoca la terminazione del processo. Un esempio è un malfunzionamento HW. **Non è volontario né recuperabile**.\n\nOgni tipo di interruzione possibile è identificato da un numero, che fa da indice in una tabella salvata nel SO e detta **INTERRUPT VECTOR**, i cui elementi sono puntatori a funzioni **HANDLER**, ovvero un gestore dell'errore corrispondente.\n\nNotare che dal punto di vista dell'efficienza un'alterazione del flusso normale è un disastro, perché bisogna fare un backup dei dati del processo per poi gestire il nuovo codice e infine passare nuovamente la palla al processo.\n\n**_In sintesi: mentre molte interruzioni del flusso normale di esecuzione richiedono il passaggio alla modalità kernel per essere gestite, non tutte fanno automaticamente passare la CPU in modalità kernel. Dipende dal tipo di interruzione e dalla sua gestione specifica all'interno del sistema operativo._**","x":-5787,"y":520,"width":857,"height":1100,"color":"4"},
		{"id":"1829ebdad1c10164","type":"text","text":"# Verso l'Hardware","x":-2242,"y":908,"width":329,"height":50,"color":"3"},
		{"id":"16683038ca807a6e","type":"text","text":"# Sistema Operativo","x":-2242,"y":1033,"width":329,"height":74,"color":"5"},
		{"id":"d28c649c75ac5104","type":"text","text":"# Verso il Software","x":-2242,"y":1181,"width":329,"height":50,"color":"6"},
		{"id":"0d18d001289cc624","type":"text","text":"# Nota di nomenclatura!\n\nSui nomi delle alterazioni del flusso normale la gente tende a fare confusione.\n\n**_Non mi risulta che tutti e soli gli eventi che fanno passare la CPU in Kernel Mode si chiamino Trap, così come non mi risulta che un Interrupt sia una Trap._**\n\nPer la nomenclatura che probabilmente è quella corretta segui la nota sotto, perché mi fido più di Demetrescu.","x":-4699,"y":67,"width":380,"height":387,"color":"4"},
		{"id":"651b3e34405ca302","type":"text","text":"# Memoria Centrale (RAM)","x":-2287,"y":-287,"width":420,"height":61,"color":"3"},
		{"id":"90f8b175ee0fef4f","type":"file","file":"Demetrescu/processi.txt","x":-2380,"y":1684,"width":593,"height":306,"color":"4"},
		{"id":"9f547af6eb5bcda0","type":"text","text":"# Creazione","x":-2208,"y":2056,"width":250,"height":60,"color":"6"},
		{"id":"e2cb98b1a469f746","type":"file","file":"Demetrescu/processiV.txt","x":-2380,"y":2197,"width":593,"height":340,"color":"4"},
		{"id":"6f102d8a296c67cf","type":"text","text":"# CPU Scheduler (Short-Term)","x":-4500,"y":2330,"width":482,"height":50,"color":"6"},
		{"id":"64979b6fb82965c3","type":"text","text":"###### Dove cerca il prossimo processo da eseguire?","x":-3948,"y":2195,"width":258,"height":75,"color":"6"},
		{"id":"efa5f9c31e4d06bc","type":"file","file":"Processi/process_state.png","x":-3500,"y":1392,"width":560,"height":227},
		{"id":"0eb83793c297bd77","type":"text","text":"# Process Execution State\n\nA partire da quando viene creato fino al momento della sua rimozione dalla memoria, un processo (a livello implementativo si intende sempre il **PCB**) può trovarsi in uno dei seguenti stati:\n\n- **New** - Il processo è stato appena creato;\n- **Ready** - Il processo è pronto ad iniziare o proseguire la sua esecuzione. Lo _Scheduler_ sceglie il prossimo processo da eseguire tra quelli in questo stato;\n- **Running** - La CPU sta eseguendo le istruzioni del processo;\n- **Waiting** - Il processo sta aspettando una risorsa (e.g. una zona di memoria condivisa attualmente utilizzata da un altro processo), un'operazione di I/O (e.g. l'inserimento di un numero da tastiera) o semplicemente il suo turno nello scheduling della CPU;\n- **Terminated** - Il processo ha terminato la sua esecuzione, e aspetta che il SO lo rimuova dalla memoria.\n\nIntuitivamente, dal momento che più processi contemporaneamente possono trovarsi nello stesso stato, a ognuna di queste etichette corrisponderà una _**queue**_, ad eccezione degli stati **running** (a meno che non ci siano più _core_ in parallelo) e **terminated** (il SO tende ad eliminare istantaneamente tutti i dati di un processo terminato).\n\nNel momento in cui entra in funzione lo _Scheduler_, il SO sposta il processo che stava _runnando_ nella _queue_ appropriata e cerca il nuovo processo da eseguire nella coda di **_ready_**.\n\nInoltre, è sempre compito dello _Scheduler_ spostare, ad esempio, i processi dagli stati _new_ e _waiting_ a quello di _ready_ nel momento in cui sono disponibili le risorse necessarie all'esecuzione.\n\n","x":-3640,"y":1684,"width":840,"height":671,"color":"4"},
		{"id":"da735d0e411a3e63","type":"text","text":"###### Come sceglie il prossimo processo da eseguire?","x":-4833,"y":2451,"width":268,"height":75,"color":"6"},
		{"id":"890280218841edc0","type":"text","text":"### Quando si attiva lo Scheduler CPU?\nSi attiva a intervalli regolari (_time slice_) scanditi dal _timer_, oppure ogniqualvolta un processo\n\n-  passa da _RUNNING_ a _WAITING_, come nel caso di una richiesta di I/O o la chiamata di una syscall wait(). In questo caso è strettamente necessario selezionare un nuovo processo;\n- passa da _RUNNING_ a _READY_, tendenzialmente a causa di un _Interrupt_ del timer;\n- passa da _WAITING_ a _READY_, come nel caso di un ritorno da I/O o da syscall wait();\n- viene creato (_NEW_);\n- termina (_TERMINATED_). Anche in questo caso è strettamente necessario selezionare un nuovo processo.\n","x":-3640,"y":2440,"width":840,"height":320,"color":"4"},
		{"id":"9ed99aa483da3638","type":"text","text":"# Batch Systems (per cultura)\n\nI \"batch systems\" si riferiscono a sistemi operativi o ambienti informatici in cui le attività vengono eseguite in lotti (batch), senza interazione immediata con l'utente. In un sistema batch, gli utenti preparano un insieme di comandi o job in anticipo e li presentano al sistema operativo per l'esecuzione. Il sistema operativo quindi esegue i job uno dopo l'altro senza richiedere un'interazione diretta con l'utente durante l'esecuzione di ciascun job.\n\nCaratteristiche principali dei batch systems:\n\n1. **Pianificazione e Esecuzione Automatica:** Gli utenti preparano uno o più job insieme a tutti i dati necessari e li inviano al sistema operativo per esecuzione. Il sistema operativo pianifica l'esecuzione dei job in base a determinati criteri.\n    \n2. **Assenza di Interazione Utente:** Durante l'esecuzione dei job, non è richiesta l'interazione diretta dell'utente. Il sistema operativo esegue i job in modo sequenziale senza richiedere input dall'utente tra un job e l'altro.\n    \n3. **Ottimizzazione delle Risorse:** I batch systems sono progettati per ottimizzare l'utilizzo delle risorse del sistema. Possono eseguire automaticamente una sequenza di job senza la necessità di costante monitoraggio umano.\n    \n4. **Elaborazione in Lotti:** Le attività vengono elaborate in lotti piuttosto che in modo interattivo. Questo è particolarmente utile per attività ripetitive o computazioni intensive che richiedono un tempo significativo.\n    \n5. **Output Salvato:** I risultati o l'output dei job possono essere salvati su file o stampati per consentire agli utenti di esaminare i risultati in un secondo momento.\n    \n6. **Storico e Monitoraggio:** I sistemi batch spesso mantengono un registro delle attività eseguite e forniscono strumenti di monitoraggio per verificare lo stato dei job in esecuzione o completati.\n    \n\nQuesti sistemi batch erano particolarmente comuni nei primi giorni dell'informatica e sono ancora utilizzati in alcune applicazioni specifiche oggi, specialmente in contesti di elaborazione di grandi volumi di dati o di esecuzione di processi automatizzati.\n\nEcco alcuni esempi pratici di situazioni in cui i sistemi batch potrebbero essere utilizzati:\n\n1. **Elaborazione Notturna delle Transazioni Bancarie:**\n    \n    - Un istituto finanziario può eseguire un sistema batch durante la notte per elaborare tutte le transazioni finanziarie effettuate durante la giornata. Ciò include l'aggiornamento dei saldi dei conti, la generazione di estratti conto e altre operazioni di elaborazione dati.\n2. **Compilazione di Programmi Software:**\n    \n    - In un ambiente di sviluppo del software, la compilazione di programmi complessi può richiedere tempo. I sistemi batch possono essere utilizzati per automatizzare il processo di compilazione di grandi progetti software durante le ore non lavorative.\n3. **Calcolo Scientifico Intensivo:**\n    \n    - In ambiti scientifici, come la simulazione di modelli complessi o il rendering grafico, i sistemi batch possono essere utilizzati per gestire l'esecuzione di calcoli intensivi durante periodi di inattività del sistema.\n4. **Produzione di Rapporti Periodici:**\n    \n    - Un'azienda può generare rapporti periodici, come rapporti finanziari mensili, mediante un sistema batch che elabora i dati accumulati durante il mese e produce i rapporti senza richiedere l'intervento dell'utente.\n5. **Elaborazione di Grandi Batch di Dati:**\n    \n    - In applicazioni di analisi dei dati, come la creazione di modelli statistici su grandi insiemi di dati, i sistemi batch possono essere utilizzati per eseguire analisi complesse senza interrompere l'interazione dell'utente.\n6. **Stampa di Documenti in Massa:**\n    \n    - In ambienti in cui è necessario stampare grandi volumi di documenti, come fatture o estratti conto, i sistemi batch possono gestire la coda di stampa in modo che la stampa avvenga in modo automatico senza richiedere l'intervento costante dell'utente.\n\nIn questi esempi, l'uso di sistemi batch consente di automatizzare processi ripetitivi, di ottimizzare l'utilizzo delle risorse e di pianificare l'esecuzione delle attività quando il sistema è meno sollecitato.","x":-5787,"y":1684,"width":857,"height":416},
		{"id":"127fb02c474f9e0c","type":"text","text":"# Criteri e logiche di un CPU Scheduler\n\nQui entriamo nella tana del Bianconiglio.\n\nPartiamo da quello che idealmente vorremmo ottenere. Ci piacerebbe\n\n- **_MASSIMIZZARE_**\n\t- **Utilizzo della CPU**, ovvero la frazione di tempo in cui la CPU è occupata. In sistemi reali si attesta tipicamente nel range $(0.4,\\, 0.9)$;\n\t- **Throughput**, ovvero i processi completati per unità di tempo. Può variare tra $10/s$ e $1/h$;\n\t- **Responsiveness**, ovvero la reattività del sistema rispetto ai comandi degli utenti. Sostanzialmente è l'inverso del _Response Time_.\n\n- **_MINIMIZZARE_**\n\t- **Tournaround Time**, il tempo \"di orologio\" di completamento di un processo, dallo stato *NEW* allo stato *TERMINATED*;\n\t- **Waiting Time**, il tempo speso dal processo nella *ready queue*. Non nella _waiting queue_? No. Lo _Scheduler_ non ha alcun potere sui processi _waiting_, pertanto non può ottimizzare il loro tempo di permanenza in questa _queue_;\n\t- **Response Time**, il tempo che intercorre tra il comando il ricevimento della risposta completa;\n\t- **Context Switch**, è vero che durano poco ma nel farli si perde tempo di utilizzo attivo della CPU;\n\t- **Overhead**, ovvero gli _switch_ tra User e Kernel Mode.\n\nSi può intuire che è impossibile ottimizzare tutte queste cose insieme.\n\nAd esempio, aumentare il _time slice_ riduce il numero di *Context Switch* ma anche la _Responsiveness_.\n\nQuindi a seconda di qual è l'obiettivo si fa _trade-off_ tra queste possibili ottimizzazioni.\n\nIl criterio è scrivere lo _Scheduler_ basandosi su una certa _policy_, ovvero scegliendo cosa sacrificare.\n\n- Per Sistemi Interattivi si ottimizzano il tempo di risposta e la _responsiveness_;\n-  Per Sistemi Batch si massimizza il _throughput_ (minimizzando l'_Overhead_) e si minimizza il _Waiting time_, tipicamente minimizzando gli _interrupt_ durante i _burst_ CPU, anche a costo di penalizzare il tempo di risposta.;\n- ...\n\nMettere in atto diversi criteri di _scheduling_ significa implementare diversi **_algoritmi_**.","x":-5787,"y":2140,"width":857,"height":1000,"color":"4"},
		{"id":"c09d363d1d2b82e8","type":"text","text":"###### Quando si attiva?","x":-3923,"y":2464,"width":208,"height":50,"color":"6"},
		{"id":"b22b50e9b1a8c2f4","type":"text","text":"###### Cosa comporta il cambiamento di processo in esecuzione?","x":-4418,"y":2451,"width":320,"height":75,"color":"6"},
		{"id":"4f7a30ec90f5f7a1","type":"text","text":"# Teoria di un CPU Scheduler (modulo del Kernel)\n\nNel momento in cui ci sono più processi che richiedono l'utilizzo della CPU, si rendono necessari dei criteri per stabilire come spartirne l'uso. In particolare, il _**CPU Scheduler**_ ha tre obiettivi di ottimizzazione principali:\n\n- **Utilizzo CPU** - cerca di mantenere la CPU occupata per più tempo possibile, minimizzando i \"momenti morti\";\n- __Fairness__ - cerca di essere \"giusto\" nello scheduling, ovvero di impedire che un processo venga privato della CPU per troppo tempo;\n- **Response Time** - cerca di impedire che un processo che richiede interazione con l'utente (o che deve inviare un segnale per sbloccare un altro processo) non resti bloccato per troppo tempo.\n\nQuesti obiettivi devono tenere conto del fatto che sostituire un processo in esecuzione con uno pronto ad essere eseguito richiede a sua volta l'utilizzo della CPU, investito però \"a vuoto\" (non sta effettivamente eseguendo alcuna istruzione di processo).\n\nLo *Scheduler* **_può_** entrare in azione in diverse situazioni.\n\n- A seguito di una **Alterazione Asincrona** (**_interrupt_**), come ad esempio\n\t- Al segnale di un **_timer_** (non è il clock della CPU!) che a intervalli regolari \"avvisa\" la CPU che è il momento di cambiare;\n\t- Un input da tastiera, che invia un segnale di terminazione del processo;\n- A seguito di una Alterazione Sincrona, come\n\t- Una **_trap_**, come ad esempio una System Call che fa richiesta di lettura da un dispositivo I/O (e la CPU passa all'operazione di I/O o a un altro processo? $\\Rightarrow$ dipende dallo *Scheduler*. In questo caso può perfino _non attivarsi_, perché il suo compito è solo quello di decidere l'ordine di esecuzione dei programmi, non di effettuare il vero e proprio _Context Switch_ dall'esecuzione di una _task_ ad un'altra: quest'ultimo compito spetta al modulo _Dispatcher_);\n\t- Un **_fault_** (o **_exception_**), come una divisione per zero (il processo semplicemente termina perché non è un errore recuperabile) o un _page fault_, a seguito del quale lo _Scheduler_ passa la palla all'*handler* corrispondente;\n\nIn tutto questo, il compito del SO è di coordinare le attività in modo da ottimizzare il lavoro dello Scheduler.\n\n\n\n","x":-4699,"y":641,"width":880,"height":860,"color":"4"},
		{"id":"8fac94dbd27f5a21","type":"text","text":"# Context Switch\n\nL'atto di sospendere un processo _running_ per eseguirne uno _ready_ è detto **_Context Switch_**\n\nHa un tempo caratteristico di $\\sim 10\\mu s$, ed è un'operazione molto costosa per due motivi principali:\n\n- bisogna salvare il PCB del processo uscente e caricare quello del processo entrante;\n- il cambio di processo aumenterà la probabilità di fare *cache miss*.\n\nIl _Context Switch_ **NON** è generato _solo_ dallo _Scheduler_, ma avviene ogniqualvolta avviene una transizione di esecuzione da un processo ad un altro.\n\nUn esempio può essere il seguente: un processo invoca una _syscall write_. La CPU passa all'_handler_ della _syscall_ (gli _handler_ degli _interrupt_ nel Kernel sono considerabili sempre _ready_), il quale esegue la scrittura su I/O. Al termine, la CPU torna nuovamente al processo chiamante, senza che lo _Scheduler_ sia mai entrato in azione.\n\nQuindi un *Context Switch* può avvenire se e solo se, alternativamente,\n\n- arriva un segnale che richiede una gestione in modalità Kernel da parte della CPU;\n- lo _Scheduler_ cambia il processo in esecuzione senza dover passare dalla Kernel Mode.","x":-4699,"y":2620,"width":880,"height":520,"color":"4"},
		{"id":"4fe1989d7b05db02","type":"text","text":"# Dispatcher (modulo del Kernel)\n\nQuello che chiamiamo complessivamente _Context Switch_ è l'effetto delle azioni del modulo **_Dispatcher_** del Kernel, che si attiva ogniqualvolta si ha un'alterazione del flusso normale.\n\nIl suo tempo di esecuzione (**Dispatch Latency**) deve quindi essere particolarmente basso.\n\nOltre a gestire i _PCB_ dei processi entranti e uscenti, spostare la CPU tra Kernel e User Mode e \"saltare\" alla riga di comando da eseguire può monitorare il tempo di uso della CPU, e può prendere decisioni da *scheduler* interrompendo il _CPU Burst_ prima del timer.\n\nIn un sistema multi-core, è suo compito la coordinazione tra di essi.\n","x":-4699,"y":3220,"width":880,"height":320,"color":"4"},
		{"id":"da8d7ccc61fb288f","type":"text","text":"# Glossario dello Scheduling\n\n1. **Arrival Time (Tempo di Arrivo)**: È il momento in cui un processo arriva nel sistema e richiede l'elaborazione dalla CPU. Ogni processo ha il proprio tempo di arrivo.\n    \n2. **Completion Time (Tempo di Completamento)**: È il momento in cui un processo termina l'elaborazione e rilascia la CPU. Indica quando effettivamente un processo è stato completato.\n    \n3. **Burst Time (Tempo di Burst)**: È il tempo necessario per eseguire un processo senza interruzioni sulla CPU, cioè quanto tempo impiega un processo per eseguire la sua intera esecuzione. Viene spesso rappresentato come una stima o una media. **_Attenzione_**, perché si può intendere il tempo residuo di esecuzione a partire dall'istante corrente (nel qual caso sarebbe meglio parlare di _tempo di burst residuo_).\n4. **CPU Burst**: può voler dire cose diverse a seconda del contesto:\n\t- si può intendere la fase durante la quale un processo utilizza la CPU per eseguire **TUTTE** le proprie istruzioni;\n\t- si può intendere la fase durante la quale un processo utilizza la CPU per eseguire le proprie istruzioni **prima di rilasciare volontariamente la CPU**.\n    \n4. **Turnaround Time (Tempo di Turnaround)**: È la differenza tra il tempo di completamento e il tempo di arrivo di un processo. Indica quanto tempo ci è voluto per completare l'intero ciclo di vita del processo, includendo il tempo di attesa nella coda di esecuzione e il tempo di esecuzione effettivo sulla CPU.\n    \n5. **Waiting Time (Tempo di Attesa)**: È la somma di tutti i periodi di tempo durante i quali un processo è stato pronto per l'esecuzione ma è stato in attesa nella coda dei processi pronti (ready queue) per essere eseguito sulla CPU. Indica quanto tempo un processo ha trascorso in attesa di essere eseguito.\n    \n\nQueste metriche sono utilizzate per valutare le prestazioni degli algoritmi di scheduling della CPU. Misurano aspetti chiave come l'efficienza, il tempo di risposta, il tempo di completamento e il grado di utilizzo della CPU. Comprendere queste metriche è fondamentale per progettare e ottimizzare algoritmi di scheduling che massimizzano l'efficienza e minimizzano i tempi di attesa e di esecuzione dei processi.","x":-3640,"y":2780,"width":840,"height":900,"color":"4"},
		{"id":"022b5d49d94bc857","type":"file","file":"Demetrescu/pipelining.txt","x":-3740,"y":933,"width":200,"height":273,"color":"4"},
		{"id":"f104b3656720780b","type":"text","text":"# Scheduling dei Processi","x":-3440,"y":1040,"width":440,"height":60,"color":"6"},
		{"id":"6c0f163753eb8b85","type":"text","text":"# Not now,  preemption!\n\n\tDa grandi poteri derivano grandi responsabilità.\n\t\nPoter scegliere quando interrompere un processo significa anche poter scegliere un momento sbagliato. Questo è il caso in situazioni in cui\n\n- il Kernel sta gestendo una _system call_ (e.g. sezione critica, scrittura su I/O) o una qualsiasi eccezione;\n- un processo sta modificando una zona di memoria condivisa con altri processi, e rischia di aggiornare solo parte dei dati rendendo la _shared memory_ inconsistente (il che può portare ad una **Race Condition**).\n\nGestire queste situazioni può richiedere strumenti come ad esempio\n- **_Primitive di Sincronizzazione_** - se sono in una zona di _shared memory_ verosimilmente ho acquisito un _lock_, e sarebbe meglio evitare di interrompermi finché ce l'ho;\n- **_Disabilitare gli interrupt_** - se sto eseguendo sezioni critiche, non voglio essere interrotto. Quest'arma va usata con **molta** cautela, perché oltre a peggiorare la _responsiveness_ rischia di rompere i meccanismi di sincronizzazione e causare _deadlock_.","x":-6569,"y":2940,"width":698,"height":600,"color":"4"},
		{"id":"3cbd143423e3f10a","type":"text","text":"# Focus: Comunicazione\n\nOgni processo può essere\n- **indipendente** - viene eseguito in modo \"isolato\", senza che ci sia scambio di informazioni con altri processi;\n- **cooperativo** - durante la sua esecuzione può inviare e/o ricevere messaggi, o leggere/scrivere in un'area di memoria condivisa da altri processi.\n\nLa cooperazione tra processi presenta numerosi vantaggi, tra cui\n\n- **Condivisione di Informazioni** - Più processi possono aver bisogno di accedere alle stesse informazioni. Piuttosto che allocare memoria per contenere tali informazioni per ognuno dei processi (per poi eventualmente sincronizzare il tutto!) è più comodo *condividere la memoria*;\n- **Rapidità di Calcolo** - Può essere comodo \"spezzare\" un problema in \"sottoproblemi\" da eseguire in parallelo, permettendo poi a ognuno di essi, per esempio, di comunicare i propri risultati al processo padre tramite l'invio di _messaggi_. Questo schema è anche detto **Modularità**.","x":-8049,"y":247,"width":698,"height":506,"color":"4"},
		{"id":"013481a47473bf04","type":"file","file":"Sicurezza e syscall/syscall.png","x":-6872,"y":56,"width":870,"height":409},
		{"id":"558ba900733523b5","type":"text","text":"# System Call\n\nStando a quanto detto, sembrerebbe impossibile eseguire da utente le istruzioni privilegiate. Ma è davvero così?\n\nNo, non è impossibile. Basta chiederlo gentilmente tramite le **System Call** (*syscall*), e il SO valuterà se è il caso di eseguirle o meno.\n\nRappresentano un \"cuscinetto\" tra User e Kernel Mode, e sono tipicamente scritte in C/C++ e fornite da librerie API scritte direttamente dagli sviluppatori del SO.\n\nQuesto significa che in realtà l'utente chiama una funzione *wrapper* con dentro, ad esempio, la *read()*, e i dettagli implementativi sono nascosti dalla API. Quando viene chiamata la **vera** *syscall* (definita a livello di _ISA_,`INT $0x80` è la chiamata alle *syscall* in Assembly) la palla passa al Kernel, che salva in registri dedicati lo stato della User Mode e usa una sua funzione `sys_read()` che esegue le vere operazioni.\n\nAl termine della *syscall*, il Kernel usa una versione privilegiata della `RET` (`IRET`) per tornare alla User Mode.\n\nSi possono passare i parametri tramite registri, tabelle o direttamente pushando in stack.","x":-6872,"y":-496,"width":870,"height":480,"color":"4"},
		{"id":"dc4fb6069113402c","type":"text","text":"# Riassunto Segnali\n\nI segnali sono uno strumento del Kernel per notificare eventi al processo.\n\nA ogni segnale è associato un *handler* di default, ovvero del codice incaricato di gestire le conseguenze di quel segnale (e.g. l'handler di **SIGSEGV** termina il processo e stampa a schermo _Segmentation Fault_).\n\nE' possibile sostituire l'handler di default con uno personalizzato tramite la funzione\n\n\tsigaction (int signum, struct sigaction* act, struct sigaction* oldact);\n\ndove `signum` è il segnale da gestire (le costanti associate ai segnali, come SIGSEGV, si trovano in `signal.h`) e la `struct sigaction` contiene tutti i parametri che definiscono l'handler.","x":-6872,"y":-920,"width":870,"height":360,"color":"4"},
		{"id":"66990f7c63e2d405","type":"text","text":"# Scheduling Algorithms","x":-7906,"y":2249,"width":412,"height":62,"color":"6"},
		{"id":"8ebd810af3667125","type":"text","text":"# Shortest Remaining Time First (SRTF)\n\nVariante _preemptive_ di _SJF_, si attiva a ogni nuovo processo che arriva nella _ready queue_, sostituendolo se ha un tempo di **_burst residuo_** inferiore rispetto al processo in esecuzione.\n\nPreferire l'uno o l'altro dipende dal problema specifico, perché\n- In entrambi si può verificare _starvation_;\n- Entrambi sono, a modo loro, _unfair_:\n\t- _SJF_ lo è se arriva un processo _CPU-bound_ molto lungo;\n\t- _SRTF_ lo è se arrivano tanti processi brevi. Quantomeno questo modo di essere _unfair_ evita il _Convoy Effect_.\n","x":-8740,"y":1216,"width":590,"height":363,"color":"4"},
		{"id":"307924e88efadd9d","type":"text","text":"# Categorie di System Call\n\n- **Gestione File** - Servono a gestire operazioni di creazione ed eliminazione, apertura e chiusura, lettura e scrittura, ottenimento e modifica degli attributi, ...\n\t- Queste syscall possono essere applicabili anche alle *directories*, dipendentemente dall'implementazione.\n\n- **Controllo Processi** - Servono a gestire i processi, in particolare creazione, caricamento in memoria, terminazione (che è la versione gentile, altrimenti si possono anche uccidere senza pietà), ottenimento/modifica degli attributi, come anche ordini di attesa o di invio di segnali, e allocazione o liberazione della memoria.\n\n- **Gestione Dispositivi** - Richiedono o rilasciano un dispositivo I/O, leggono o scrivono su di esso, gestiscono il processo di *mount* e *unmount*. I dispositivi possono essere tanto fisici (e.g. HDD) quanto virtuali (e.g. partizione del disco).\n\t- Alcuni SO rappresentano i dispositivi di I/O come file speciali nel *filesystem*. L'accesso a questi *file* richiama il driver appropriato (e.g. la directory /dev su un sistema UNIX).\n\n- **Gestione Informazioni di Sistema** - Modificano data e ora, i dati di sistema e dei processi o gli attributi dei file.\n\t- Questo tipo di operazioni permettono anche di salvare lo stato dei processi per fare *debugging* (e.g. _Memory Dump_).\n\n- **Comunicazione** - Creano o chiudono canali di comunicazione, inviano o ricevono messaggi, fanno *mount/unmount* dei dispositivi esterni. Ci sono due modelli di comunicazione:\n\t- **_Message Passing_** - I processi comunicano tra loro inviandosi dei messaggi;\n\t- **_Shared Memory_** - I processi condividono una zona di memoria, che sarà quindi una risorsa condivisa sulla quale sarà necessario implementare costrutti di sincronizzazione come semafori, mutex e monitor.","x":-8048,"y":-655,"width":698,"height":798,"color":"4"},
		{"id":"e2aefc482d1e7497","type":"text","text":"# Message Passing\n\nDal momento che richiede una chiamata a _System Call_ per ogni messaggio è lo schema di comunicazione più esplicito (quindi più facile da implementare), ma al contempo è il più lento.\n\nLa situazione ottimale in cui viene utilizzato è quella di diversi computer connessi da una rete che scambiano piccole quantità di dati.\n\nIl prerequisito per inviare o ricevere messaggi è quello di stabilire un _canale di comunicazione_. Questo può avvenire per\n\n- **Comunicazione Diretta** - il mittente deve sapere il nome del ricevitore. Per una comunicazione simmetrica, deve essere vero anche il contrario. A ogni coppia mittente-ricevitore corrisponde un _link_ (canale) di comunicazione;\n- **Comunicazione Indiretta** - si usano _porte_ o _mailbox_ condivise. Più processi possono condividere le stesse porte. Il SO deve fornire syscall per creare ed eliminare le mailbox, così come per stabilire connessioni con esse e inviare o ricevere messaggi da esse.\n\nCome gestisco l'invio e la ricezione di più messaggi?\n\nPosso implementare la gestione delle code in diversi modi.\n\n- **Zero Capacity**: Non esiste una coda di messaggi, i mittenti devono aspettare che il destinatario accetti il messaggio precedente;\n- **Bounded Capacity**: La coda ha una capienza finita, i mittenti si fermano solo se la coda è piena;\n- **Unbounded Capacity**: La coda ha una capienza virtualmente infinita, i mittenti non vanno mai in blocco forzato.","x":-8767,"y":113,"width":644,"height":774,"color":"4"},
		{"id":"7c939ee2ebe1207c","type":"file","file":"Processi/ICP.png","x":-8644,"y":-655,"width":398,"height":685},
		{"id":"ba2b6213e4637219","type":"text","text":"# Nota sulla sincronizzazione dei processi!\nI processi di scheduling presentati qui sono basati sull'assunzione che **NON** avvenga comunicazione tra processi. _Tendenzialmente_, lo scheduler CPU si occupa di *fainess* e di *response time*, mentre sta al programmatore implementare una sincronizzazione esplicita in caso di schemi di comunicazione tra processi","x":-8049,"y":1278,"width":698,"height":200,"color":"4"},
		{"id":"1c983ed53f331726","type":"text","text":"# Shared Memory\n\nLe System Call sono necessarie solo per collegarsi o scollegarsi dal segmento di memoria condivisa, motivo per cui è lo schema di condivisione più veloce.\n\nParticolarmente utile in caso sia necessario condividere grandi quantità di dati su un singolo computer.\n\nNon è ottimale, viceversa, in caso di più computer connessi da una rete.\n\nSi tratta dello schema più complesso da gestire, poiché l'accesso alla memoria condivisa va sincronizzato manualmente.","x":-8049,"y":858,"width":698,"height":358,"color":"4"},
		{"id":"4ff852d5afad6346","type":"text","text":"# Shortest Job First (SJF)\n\nAlgoritmo _non-preemptive_ che assegna la CPU al processo con il minor tempo di _burst_ (**tempo di esecuzione totale**) nella _ready queue_. Si attiva solo alla terminazione o alla sospensione volontaria di un processo.\n\nPer costruzione, è ottimale per minimizzare l'_average waiting time_, ma bisogna tenere a mente che\n\n- Prevedere il tempo di esecuzione fino a terminazione è un compito dispendioso, nonché praticamente impossibile;\n- I processi _CPU-bound_ (ovvero, che trascorrono la maggior parte del tempo in _CPU Burst_) tendono di fatto ad essere sfavoriti rispetto a processi _I/O-bound_ (che invece passano la maggior parte del tempo ad attendere l'I/O). Questi ultimi avranno comunque meno tempo di _burst_, e quindi implicitamente priorità, portando i primi alla _**starvation**_ (eccessivamente prolungato \"digiuno\" dall'utilizzo della CPU).","x":-8740,"y":1684,"width":590,"height":516,"color":"4"},
		{"id":"8d0dc0d08efb8898","type":"file","file":"Processi/Deadlock/Potential Deadlock.png","x":-2778,"y":5199,"width":839,"height":356},
		{"id":"077958ec99cf0920","type":"text","text":"# Implementazione di un CPU Scheduler\n\nAnzitutto possono esserci diversi tipi di _Scheduler_.\n- _**short-term**_ - è quello standard della CPU, si attiva ogni $\\sim 10\\div 100\\,ms$ (questo intervallo di tempo è dettato dal _timer_, e si chiama **_time slice_**) e regola come scegliere il prossimo processo da eseguire. In un supermercato, il suo compito sarebbe indirizzare le persone alle casse;\n- **medium-term** - anche detto _Process Swapping Scheduler_. Gestisce i processi nella _waiting queue_ decidendo se e quando sbloccarli, monitora le risorse e sospende i processi troppo esosi in caso di sovraccarico del sistema. Nella metafora del supermercato, il suo compito è quello di autorizzare le persone a mettersi nella fila per le casse (la _ready queue_);\n- **long-term** - gira poco frequentemente ed è tipico dei _Batch Systems_. Definisce il livello di _multiprogrammazione_, ovvero il numero totale di processi nella _ready queue_, e decide quali processi possono passare dalla _new queue_ alla _ready queue_. Nella ormai inclita metafora del supermercato, gestisce il flusso di persone nella struttura (i famosi _ingressi contingentati_ in tempo di COVID).\n\n","x":-4699,"y":1684,"width":880,"height":416,"color":"4"},
		{"id":"a468bd8ba770bd4b","type":"text","text":"# First-Come-First-Serve (FCFS)\n\nProbabilmente il più semplice e immediato algoritmo di tipo _non-preemptive_.\n\nLa _ready queue_ è vista come una pila _First-In-First-Out_, i processi sono eseguiti in ordine di arrivo.\n\nSemplice da implementare e da capire, ma non essendoci alcuna ottimizzazione sulla scelta del processo successivo è ad altissimo rischio di _Convoy Effect_ (e.g. se cambio processo per fare un breve I/O, questo viene messo in fondo alla coda).","x":-7254,"y":1684,"width":614,"height":516,"color":"4"},
		{"id":"b73522939cb2e340","type":"file","file":"Processi/Sincronizzazione Processi (Scheduler CPU)/MLQ.png","x":-7238,"y":2994,"width":583,"height":220},
		{"id":"26f21190e660b29e","type":"text","text":"### Nota su MLQ\n\nIn _MLQ_ senza _feedback_ i processi **_non possono cambiare queue_** in corso d'opera, né per effetto dello *scheduling* né per altro.","x":-7238,"y":3260,"width":583,"height":134,"color":"4"},
		{"id":"30f61bfe887b9609","type":"text","text":"# Multi-Level Feedback-Queue (MLFQ)\n\nCome _MLQ_, ma ogni processo può cambiare _queue_ secondo uno schema _preemptive_. Tipicamente\n\n- il processo inizia nella _queue_ a priorità maggiore;\n- se non cede la CPU volontariamente (e quindi viene interrotto dal _timer_), la sua priorità decrementa.\n\t- I processi _CPU-bound_ tendono a discendere rapidamente la gerarchia delle priorità;\n- se cede la CPU volontariamente la sua priorità aumenta;\n\t- I processi _I/O-bound_ resteranno ad alta priorità.\n- in caso di _starvation_ di un processo non viene implementato l'_Aging_, ma viene aumentata la priorità per un certo intervallo di tempo.\n\nÈ l'algoritmo più flessibile, ma anche il più complesso da implementare: è necessario definire parametri come numero di code, algoritmo di scheduling di ogni coda, criteri di upgrade o downgrade tra le code, criterio di assegnazione iniziale di un processo a una coda, ...","x":-8049,"y":2375,"width":698,"height":500,"color":"4"},
		{"id":"61b2fd4819af306d","type":"text","text":"# Algoritmi realmente usati\n\n- **_Linux_** ha usato un algoritmo di _scheduling_ chiamato **O(1)**, in riferimento alla sua capacità di selezionare rapidamente un processo da eseguire in tempo costante, indipendentemente dal numero di processi nel sistema. Poi è passato al **Completely Fair Scheduler (CFS)**;\n- **_Windows_** utilizza uno scheduler basato sulle priorità;\n- **_Apple_** per i suoi *iOS* usa il **Grand Central Dispatch (GCD)**, che è una variante di un Multi-Level Feedback-Queue (MLFQ).","x":-9409,"y":2480,"width":589,"height":395,"color":"4"},
		{"id":"ee4978ec280e0156","type":"text","text":"# Lottery Scheduling\n\nAlgoritmo _preemptive_ non-deterministico che assegna dei \"biglietti della lotteria\" ai processi per poi estrarre un \"vincitore\" a ogni scadenza del timer. Più biglietti ai processi brevi, meno ai processi lunghi (una sorta di simulazione di SJF). A ogni processo viene dato almeno un biglietto (virtualmente per evitare la starvation).","x":-9409,"y":1684,"width":589,"height":396,"color":"4"},
		{"id":"c948ce6320acafbe","type":"file","file":"Processi/Sincronizzazione Processi (Scheduler CPU)/LotterySimplified.png","x":-9409,"y":1275,"width":589,"height":246},
		{"id":"113ca9ce4e51d6e6","type":"text","text":"# Threads\n\nImmagina un processo come un insieme di sottoprocessi. Ad esempio, un _editor di testo_ deve eseguire compiti come attendere l'input, controllare la grammatica, gestire la _GUI_... e visto che sono indipendenti gli uni dagli altri sarebbe magnifico eseguirli in parallelo.\n\nSiffatti sottoprocessi prendono il nome di **_threads_**, e trasformano i processi in un insieme di moduli in esecuzione parallela che cooperano (in caso di più *core*, il parallelismo è gestito dallo _Scheduler_).\n\nUn _thread_ è definito come _**la più piccola unità di esecuzione che può essere pianificata ed eseguita dalla CPU**_. Questo significa che sono completamente definiti da\n\n- un valore del **Program Counter**;\n- una **Stack** in memoria;\n- un **set di registri generici**.\n\nQueste informazioni (oltre ovviamente all'*ID* del *thread*) sono contenute nel *Thread Control Block* (**_TCB_**). Ogni *thread* fa riferimento a un processo genitore, e ogni processo genitore condivide con ogni *thread* figlio codice, dati e zona di memoria.\n\nI _thread_ si dividono in due macro-categorie:\n\n- **_Kernel threads_** - sono gestiti direttamente dal SO, che quindi ne ha pieno controllo e ottimizza le operazioni di sincronizzazione dello _Scheduler_. Sono gestiti da un sottosistema noto come _Thread Library_ (o _Thread Package_). Presentano due principali criticità:\n\t- \"spezzettare\" i processi in sottoprocessi aumenta la complessità del Kernel, aumentando il rischio di errori e complicando la fase di _debugging_;\n\t- lavorando nello spazio del Kernel, l'accesso alle risorse è mediato dalle _system call_. Questo, insieme ai frequenti _context switch_, rallenta il sistema;\n\n- **_User threads_** - gestiti dall'utente con apposite librerie o _API_ di supporto (e.g. i _POSIX threads_ **_pthreads_**, o i _Java threads_). Non sono necessarie _system call_ né la Kernel Mode per assegnare le risorse o attuare i _context switch_, quindi risultano più veloci e leggeri nell'esecuzione. Questo permette anche di implementare i _thread_ in SO che non li supportano in modo nativo. Di contro, tuttavia,\n\t- la sincronizzazione spetta all'utente;\n\t- il SO non sa nulla dei thread in spazio utente, quindi li gestisce come programma concorrente.\n\nSe il SO li supporta in modo nativo, per sfruttare appieno i _thread utente_ questi vengono mappati in thread kernel (spesso viene fatto da un'unità chiamata _**LWP**_, _Lightweight Processor_). Ci sono diversi modi di farlo.\n\n- **_Many-To-One_**: Più *thread utente* sono mappati in un singolo *thread kernel*. L'utente scrive un parallelismo che non verrà mai implementato;\n- _**One-To-One**:_ $N$ _thread utente_ sono mappati in $N$ _thread kernel_. La gestione del processo di *mapping* può rallentare il sistema, motivo per cui spesso c'è un limite al numero di *thread* creabili;\n- **_Many-To-Many_**: $N$ thread utente sono mappati in $M \\leq N$ *thread kernel*. Unisce i vantaggi dei metodi precedenti. Se possibile si mantiene il parallelismo dato da *One-To-One*, altrimenti più *thread utente* vengono mappati in un solo *thread kernel*. Presente anche in variante *Two-Level*, che esegue esplicitamente in parallelo il *multiplexing* di *Many-To-Many* e il collegamento diretto di *One-To-One*.","x":-599,"y":2336,"width":921,"height":1144,"color":"4"},
		{"id":"b18a396618049aa5","type":"file","file":"Processi/Threads/parallelism.png","x":-453,"y":2100,"width":629,"height":170},
		{"id":"7a3d011be3a94fb1","type":"file","file":"Demetrescu/SO.txt","x":-3420,"y":67,"width":400,"height":387,"color":"4"},
		{"id":"820b6d0e3117c760","type":"file","file":"TdP/SO_basic.txt","x":-2780,"y":441,"width":400,"height":400,"color":"4"},
		{"id":"06528774c7a17e8f","type":"text","text":"# Sicurezza","x":-4385,"y":-287,"width":250,"height":61,"color":"6"},
		{"id":"a2ca84c1f075532c","type":"file","file":"Sicurezza e syscall/syscall_esempi.png","x":-7990,"y":-1553,"width":583,"height":633},
		{"id":"d149b3dfbe917b55","type":"text","text":"**_“Mi chiami il presidente”\n\"Ma signore, è lei il presidente”\n“Bene, allora so già tutto”_**\n\nLe _system call_ servono **_solo_** se devo passare dalla _User Mode_ alla _Kernel Mode_.\n\nNon devo \"chiamare il sistema\"... se il sistema sono io.\n\nNessun modulo del Kernel (_Scheduler_, _Dispatcher_, _driver_, ...) usa le _system call_.","x":-7254,"y":-920,"width":360,"height":360,"color":"4"},
		{"id":"d5c101f97e76cc55","type":"text","text":"# Nota sul modulo Dispatcher\n\nDa non confondere con gli **_oggetti dispatcher_**, utilizzati nella programmazione multi-threading!","x":-4699,"y":3580,"width":880,"height":100,"color":"4"},
		{"id":"e864bef1d25309b9","type":"text","text":"# Aggiunte\n### Stack Pointer\nOltre allo Stack Pointer esp si definisce uno Stack Base Pointer che punta alla base dello Stack Frame del chiamante.\nQuando chiamo una funzione posso pushare il vecchio valore di ebp e usare quello al posto di esp, mentre esp \"scende\" insieme alle variabili locali.\n\n### Creazione Processi\n\nAggiunte: Windows ha una syscall, spawn() che unisce le syscall fork() e exec() di Unix.\n\nPer specificare quale figlio aspettare c'è la syscall waitpid(pid_t pid, int \\*status, int options).","x":-2380,"y":2675,"width":593,"height":465,"color":"4"},
		{"id":"e067d5bbcbdb0467","type":"text","text":"## Nota di nomenclatura II\n\nSembra che queste cose abbiano una doppia chiave di lettura.\n- C'è chi le chiama tutte interruzioni, intendendole come \"_io programma stavo facendo roba e mi hanno interrotto_\";\n- Vederle come alterazioni del flusso normale è più una visione \"dall'alto\", come se parlasse il SO.","x":-6872,"y":520,"width":412,"height":315,"color":"4"},
		{"id":"8287aebf1f270337","type":"file","file":"Demetrescu/processiIII.txt","x":-6400,"y":520,"width":398,"height":315,"color":"4"},
		{"id":"65691212673b8e15","type":"text","text":"# Buffering e System Call **_write_**\n\nNel caso in cui un programma C chiami una _printf_, questa è una richiesta di tipo I/O, ma non è di per sé una chiamata alla _system call write_. La _printf_ è infatti una funzione _wrapper_, che svolge diverse operazioni _tra cui_ chiamare la _write_.\n\nUna di queste operazioni è il **_buffering_**, ovvero il riempimento di un _buffer_ di memoria in modo da ridurre le chiamate alla write alle sole situazioni in cui questo è pieno (o in cui, ad esempio, si incontra il carattere speciale '\\\\n', i dettagli dipendono dall'implementazione).\n\nQuindi il buffer può riempirsi (senza che venga invocata la _write_) nel mentre che il programma sta proseguendo la sua esecuzione. Inoltre, ad ogni canale di output (e.g. **stdout**) possono essere associati più _buffer_, e possono verificarsi situazioni in cui un secondo buffer viene stampato prima del primo, ma i **due buffer non possono mischiarsi**, perché la _write_ è un'istruzione atomica.\n\nInfine, **_la write non è necessariamente un'istruzione bloccante_**. Questo significa che nonostante sia una _system call_ di I/O il processo chiamante non deve aspettare il ritorno da essa. Molte operazioni di I/O, specie quelle sui _buffer_, non sono bloccanti.","x":-6569,"y":1071,"width":698,"height":549,"color":"4"},
		{"id":"4a9e0af6fa1f8472","type":"text","text":"# Sincronizzazione Thread","x":-354,"y":3716,"width":431,"height":69,"color":"6"},
		{"id":"45cd529f8bc60a75","type":"text","text":"## Problemi di questa soluzione\nPosto che questa soluzione funziona, ha diverse criticità.\n- Difficile verificare l'effettivo funzionamento;\n- Asimmetrica. Se fossero più di due thread la complessità aumenterebbe molto;\n- Bob va in *busy waiting* ogni volta che gli viene data la CPU.","x":-2782,"y":4360,"width":840,"height":200,"color":"4"},
		{"id":"ec02cf92e35c5eb6","type":"text","text":"# Livello avanzato - Monitor (mutex + metodi)\nUn *monitor* è una \"scatola\" (quindi tipicamente implementata con una classe) associata ad una risorsa condivisa.\n\nNon è ad accesso esclusivo ma ad **_esecuzione esclusiva_**, ovvero solo il *thread* che detiene il *lock* del *monitor* può eseguire i metodi (funzioni) del *monitor* sulla risorsa a lui associata.\n\nAll'interno di questa scatola sono implementate (oltre ai metodi) due funzioni di sincronizzazione interna, **_wait_** e **_signal_**.\n\nNel caso in cui il *thread* detentore del *lock* (che chiamiamo **A**) abbia necessità di aspettare prima di eseguire quello che deve eseguire (tramite i metodi del *monitor*) può chiamare la funzione *wait* sul semaforo di sincronizzazione interna. Questa funzione rilascia temporaneamente il *lock* del *monitor* e mette il *thread* **A** in una queue di attesa interna. Un altro *thread* esterno (che chiamiamo **B**, potenzialmente in una *queue* esterna) può a questo punto prendere il *lock*, eseguire le proprie operazioni e uscire, passando il *lock* a un altro *thread* **C**. Questo gioco va avanti così finché uno di questi thread, diciamo **D**, invoca una *signal*. Questo fa sì che il *thread* **A** si \"risvegli\" tornando ad essere un candidato a prendere il *lock*. Quando **D** esce e rilascia il lock, *lo* prende uno dei processi \"svegli\" in una delle code (interna o esterna). Quando riprende il *lock*, **A** esegue le sue operazioni ed esce rilasciandolo nuovamente.\n\nQuale coda ha la priorità è un dettaglio implementativo.\n\nSeguono aggiunte varie ed eventuali.\n\n- Esiste una terza primitiva, **_broadcast_**, che è una *signal* per tutti i processi in attesa.\n- A rigore quello dentro al *monitor* non è un semaforo. Le differenze sono infatti che\n\t- La *wait* nel semaforo blocca il primo *thread* in *queue* e può essere chiamato in qualsiasi momento (perché in pratica decrementa un contatore), mentre nel *monitor* il *thread* deve star eseguendo un metodo (in pratica blocca il thread e rilascia il lock);\n\t- La *signal* nel semaforo incrementa il contatore anche se non ci sono *thread* attualmente in attesa, permettendo a un futuro thread di entrare. Nel *monitor*, se non c'è alcun processo in *queue* il segnale viene perso.\n- Esistono due modi di implementare la *signal*, detti **Mesa** e **Hoare**. Pare che la prima sia di utilizzo più comune e la seconda utilizzata a titolo di esempio nei libri. Non riporto dettagli implementativi.\n- Problema tipico da risolvere con un *monitor*: **Readers-Writers**.","x":-600,"y":5117,"width":922,"height":950,"color":"4"},
		{"id":"f9cd9cbd5670ae73","type":"text","text":"# Questioni pratiche: implementare i thread\n\nUno potrebbe farsi domande quali ad esempio\n\n1. Se un *thread* chiama una `fork` viene copiato l'intero processo (e quindi tutti i _thread_ fratelli) o solo il chiamante?\n\t- In teoria, se il nuovo processo chiama una `exec` non c'è bisogno di copiare tutto, altrimenti sì;\n\t- In pratica, dipende dall'implementazione del SO. Diverse versioni di UNIX forniscono diverse versioni della `fork` in questo senso. \n\n2. Se un processo *multi-threaded* riceve un segnale, a quale *thread* viene consegnato?\n\tCi sono più possibilità, ugualmente valide:\n\t\n\t- Al *thread* a cui si applica il segnale;\n\t- A ogni *thread* che aspettano un segnale;\n\t- A ogni *thread*;\n\t- Ad un *thread* specifico adibito a ricevere e gestire segnali.\n\t\n\tNotare che nei primi due casi spetta al SO tenere traccia di quali *thread* sono in attesa di segnali.\n\tDiverse versioni di UNIX forniscono diverse versioni della `signal` (tipicamente il comando UNIX per inviare segnali si chiama `kill`) per notificare eventi ai processi o ai singoli *thread*:\n\t- `kill(pid, signal)`\n\t- `pthread_kill(tid, signal)`\n\t\n\tUNIX permette anche al singolo *thread* ($\\Rightarrow$ al programmatore) di modificare il proprio *handler* di default.\n\n## Server e Thread Pools\n\nIl *multi-threading* su **server** prevede la creazione di un *thread* per ogni richiesta da gestire. Il problema è che se ne possono creare troppi e la loro gestione può diventare complessa.\n\nUna soluzione è usare le **_Thread Pools_**.\n- All'avvio creo un certo numero di _thread_ che metto in una _pool_;\n- Quando devo gestire una richiesta, ne risveglio uno. Se non ce ne sono, aspetto.\n- Quando finisce la gestione della richiesta, il *thread* torna a dormire nella *pool*.\n\nSeparare la richiesta (*job* da eseguire) dal processo di creazione del *thread* (chi lo esegue) permette di\n\n- Guadagnare tempo e ridurre l'**_overhead_** (il \"lavoro in più\"). Dover creare ogni volta da capo il processo/thread che esegue un *job* è molto più costoso che averlo pronto e doverlo solo risvegliare;\n- Organizzare con uno _scheduler_ l'esecuzione periodica di un certo *thread* in *stand-by*, oppure l'esecuzione al verificarsi di certe condizioni.","x":425,"y":2336,"width":1000,"height":1144,"color":"4"},
		{"id":"b34d99bdf2278892","type":"file","file":"Processi/Threads/pthreads.png","x":1520,"y":2495,"width":582,"height":827},
		{"id":"1dad249a05ab28b1","type":"text","text":"### Lock in C++ (disable_interrupts)\n\tClass Lock\n\t{\n\t\tpublic void acquire(Thread t);\n\t\tpublic void release();\n\t\tprivate int value; // 0=FREE, 1=BUSY\n\t\tprivate Queue q;\n\t\tLock()\n\t\t{\n\t\t\tthis.value = 0; // Lock is initially free\n\t\t\tthis.q = null;\n\t\t}\n\t}\n\n\tpublic void acquire(Thread t)\n\t{\n\t\tdisable_interrupts();\n\t\tif(this.value) { // lock is held by someone\n\t\tq.push(t); // add t to waiting queue\n\t\tt.sleep(); // put t to sleep\n\t\t}\n\t\telse this.value = 1;\n\t\tenable_interrupts();\n\t}\n\n\tpublic void release()\n\t{\n\t\tdisable_interrupts();\n\t\tif(!q.is_empty())\n\t\t{\n\t\t\tt = q.pop(); // extract a waiting thread from q\n\t\t\tpush_onto_ready_queue(t); // put t on ready queue\n\t\t}\n\t\telse this.value = 0;\n\t\tenable_interrupts();\n\t}\n\n","x":425,"y":4380,"width":778,"height":409,"color":"2"},
		{"id":"5c0597c2efcb77b1","type":"text","text":"# disable_interrupts\n\nBasa il _lock_ sulla possibilità dell'HW di ritardare gli *interrupt* fino al termine delle operazioni critiche.\n\nCi sono però diversi problemi in una simile implementazione:\n- Perdita di responsività del SO. Una sorta di *inversione di priorità* per cui un processo poco importante che fa un *lock* con *disable_interrupts* può bloccare processi a priorità maggiore;\n- Invoca il Kernel, che notoriamente porta ad un *overhead*;\n- Se ho più *core* blocco gli *interrupt* per tutti? E se stanno eseguendo altri *thread* che contemporaneamente chiedono il *lock*?\n","x":425,"y":3920,"width":778,"height":400,"color":"4"},
		{"id":"206e2718cacccb39","type":"text","text":"# Glossario della Sincronizzazione\n\n\n- _**Race Condition**_ - Situazione in cui il risultato complessivo dell'esecuzione di più *thread* dipende dal loro ordine di esecuzione. Ovviamente da evitare.\n- _**Polling**_ - Situazione in cui un processo/_thread_ chiede compulsivamente qualcosa ad un altro, un po' come Ciuchino che chiede a Shrek \"siamo arrivati?\".\n- **_Busy Waiting_** - Situazione in cui il processo/_thread_ occupa la CPU in modo non produttivo, ad esempio facendo _Polling_ con un ciclo `while(not_now){}` che blocca il programma testando `not_now` finché non smette di essere vera (e chiaramente spetta ad un altro processo.","x":-1439,"y":2940,"width":713,"height":540,"color":"4"},
		{"id":"c835796226556bf7","type":"text","text":"# test&set\n\nUn modo alternativo per implementare un lock è sfruttare le istruzioni _atomiche_, come `test&set`, che legge un valore e scrive 1 in memoria.\n\nImmaginati il _lock_ (`sharedVariable`) come la preda, e i vari *thread* in attesa come i predatori. Il primo che ottiene la CPU per poter attaccare la preda indifesa (eseguire `test&set` quando il *lock* è libero) ottiene il _lock_.\n\nCi sono due problemi principali:\n- Tutti i processi a cui viene data la CPU quando `sharedVariable` è occupata vanno in _**busy waiting**_;\n- Non c'è alcun ordine deterministico (come una _queue_) in cui i processi possono accedere al _lock_ $\\Rightarrow$ è un'implementazione **_unfair_**.","x":1300,"y":3920,"width":802,"height":400,"color":"4"},
		{"id":"6b26542e75b5a010","type":"text","text":"## Implementazione di un *lock*\n\nLa CPU in linea di principio può andare in *context-switch* in qualsiasi momento. O meglio, i casi sono due:\n- Il *running thread* cede volontariamente la CPU eseguendo, ad esempio, una *syscall* per operazioni di I/O. In questo caso è sufficiente che il codice del *thread* non preveda una cosa del genere quando entra in una sezione critica;\n- C'è un *interrupt* esterno che blocca brutalmente l'esecuzione indipendentemente da cosa vorrebbe fare il *thread*.\n\nIl lock si può implementare in due modi: disabilitando gli _interrupt_ oppure con _istruzioni atomiche_.\n\n","x":425,"y":3520,"width":1677,"height":320,"color":"4"},
		{"id":"28c7d6f803083c2b","type":"text","text":"### Lock in C++ (test&set)\n\n\t// Inizializza la variabile condivisa a 0 (lock non acquisito)\n\tsharedVariable = 0;\n\n\t// Acquisizione del lock\n\twhile (test_and_set(&sharedVariable) == 1) {\n\t// Busy Waiting finché il lock è detenuto da un altro thread\n\t}\n\n\t// Sezione critica\n\n\t// Rilascio del lock\n\tsharedVariable = 0;\n","x":1300,"y":4380,"width":802,"height":409,"color":"4"},
		{"id":"10e69b68374e69a4","type":"text","text":"### Semaforo in C++\n\n\tClass Semaphore\n\t{\n\t\tpublic void wait(Thread t);\n\t\tpublic void signal();\n\t\tprivate int value;\n\t\tprivate int guard;\n\t\tprivate Queue q;\n\n\t\tSemaphore(int val)\n\t\t {\n\t\t\t// initialize semaphore\n\t\t\t// with val and empty queue\n\t\t\tthis.value = val;\n\t\t\tthis.q = null;\n\t\t}\n\t}\n\n\n\tpublic void wait(Thread t)\n\t{\n\t\twhile(test&set(this.guard) == 1)\n\t\t{\n\t\t\t// while busy do nothing\n\t\t}\n\t\n\t\tthis.value -= 1;\n\t\tif(this.value < 0)\n\t\t{\n\t\t\tq.push(t);\n\t\t\tt.sleep_and_reset_guard_to_0();\n\t\t}\n\t\telse\n\t\t{\n\t\t\tthis.guard = 0;\n\t\t}\n\t}\n\n\tpublic void signal()\n\t {\n\t\twhile(test&set(this.guard) == 1)\n\t\t{\n\t\t// while busy do nothing\n\t\t}\n\t\n\t\tthis.value += 1;\n\t\tif(!q.isEmpty())\n\t\t {\n\t\t\t // this.value <= 0\n\t\t\tt = q.pop();\n\t\t\tpush_onto_ready_queue(t);\n\t\t}\n\t\tthis.guard = 0;\n\t\t}","x":1300,"y":4860,"width":802,"height":359,"color":"2"},
		{"id":"5ebb9d2dabcdc329","type":"text","text":"### Esempio (scheduling constraints con semafori)\nDue thread paralleli possono essere\n\n\tstudy()\n\tS.signal()\ne\n\n\tS.wait()\n\ttake_exam()","x":425,"y":4860,"width":778,"height":359,"color":"4"},
		{"id":"a6494ec2a3a14739","type":"file","file":"Processi/Deadlock/Potentially Unsafe.png","x":-3397,"y":6081,"width":521,"height":356},
		{"id":"fc632d9a9c345ef1","type":"file","file":"Memoria/Paging/PagingPageTable.png","x":-5160,"y":-4519,"width":542,"height":720},
		{"id":"7b74698d9783de73","type":"text","text":"# Il problema della Fairness\n\nAlgoritmi come *SJF* e *MLFQ* (che promuovendo esplicitamente i job con tempo di esecuzione previsto più breve imita il *best-behaviour* di *SJF*) sono **_UNFAIR_**, ovvero permette situazioni in cui alcuni processi a bassa priorità hanno un _waiting time_ altissimo.\n\nNon sempre aumentare i burst CPU per questi processi risolve il problema, perché rischia di aumentare l'*average waiting time* dell'intero sistema.","x":-10107,"y":2150,"width":698,"height":260,"color":"4"},
		{"id":"021f1343bdb23d3b","type":"text","text":"# Come collego un dispositivo esterno all'HW?\n\nIntuitivamente, se l'HW esistente è collegato dal **bus**, per aggiungere un dispositivo esterno basta collegarlo al bus.\n\nEsiste un bus dedicato ai dispositivi I/O integrati, detto appunto _**bus di I/O**_, ma si possono utilizzare in generale i _**bus di espansione**_ come USB e PCIe.\n\nUna volta collegato alle linee fisiche dell'HW, esistono principalmente due schemi tramite i quali il SO identifica la locazione del dispositivo (ovvero tramite i quali lo \"mappa\" nelle sue risorse virtualizzate): **_memory-mapped_** e **_port-mapped_**","x":1200,"y":-215,"width":786,"height":320,"color":"4"},
		{"id":"5d67baa15b95e53b","type":"file","file":"Input-Output/controller_driver.png","x":1200,"y":-684,"width":786,"height":420},
		{"id":"4d11f59d7f807802","type":"text","text":"# Collegamento dell'HW","x":-643,"y":640,"width":380,"height":50,"color":"3"},
		{"id":"65f8df716b94268d","type":"text","text":"# Come fa il SO a dialogare con un dispositivo I/O?\n\nIl dialogo con un dispositivo I/O Si articola in diversi passaggi.\n\n1. **_Richiesta di I/O_** - Non è come la signora al bar che di punto in bianco sceglie di raccontarti la sua vita. Ogni dialogo con un dispositivo di I/O parte da una esplicita richiesta da parte di un processo o da parte dell'HW stesso (e.g. se inserisco una chiavetta USB sarà l'HW a notificare al SO la presenza di un nuovo dispositivo);\n2. **_Gestione della richiesta_** - Il SO attiva un modulo del Kernel detto **_Sottosistema di I/O_** che si occupa di\n\t- identificare il dispositivo I/O di destinazione;\n\t- determinare la modalità di I/O (e.g. lettura, scrittura, ...);\n\t- scegliere il _**driver**_ appropriato.\n\n\tIl *driver* è a sua volta un modulo del Kernel, ma è **_dispositivo-specifico_**. Una volta attivato, collabora con il _Sottosistema di I/O_ per creare il canale di comunicazione con il dispositivo.\n\t\n3. **_Comunicazione_** - Il *driver* inizia a comunicare con il **_controller_** del dispositivo. Costui è il primo strato di HW che si incontra, ed è un **_chip_** che traduce i comandi _software_ del _driver_ in azioni meccaniche, e viceversa. Inizia lo scambio di dati. A questo punto possono verificarsi due situazioni degne di nota:\n\t- il dispositivo è strutturato come **_filesystem_** riconoscibile dal SO (e.g. una chiavetta USB). Il SO si preoccupa allora di **_montare_** l'albero della chiavetta su una foglia del proprio _filesystem_, in modo da renderne esplorabile il contenuto;\n\t- la comunicazione è solo e soltanto tra dispositivo e memoria. In questo caso il SO può scegliere di delegare le operazioni pesanti (e.g. il trasferimento di grandi volumi di dati da una periferica di archiviazione alla memoria secondaria) al **_Controller DMA (Direct Memory Access)_**, che svolge le operazioni in modo **_indipendente dalla CPU_**, la quale si limita a fare _polling_. Può comunque intervenire in caso di errori o _interrupt_ qualsiasi.\n4. **_Chiusura del canale di comunicazione_** - Il _controller_ invia un _interrupt_ alla CPU per notificarle il termine delle operazioni.","x":2170,"y":-684,"width":787,"height":789,"color":"4"},
		{"id":"f259623a35cf9802","type":"text","text":"# Mapping dei dispositivi di I/O\n\nA livello software, è possibile implementare a seconda delle esigenze diversi tipi di _mapping_ dei dispositivi I/O.\n\n### **_Memory-Mapped I/O (MMIO)_**\n\nIn questo schema di comunicazione la CPU parla direttamente con i dispositivi di I/O (in particolare con i **_registri_** dei rispettivi **_Controller_**) senza passare per la RAM.\n\nQuesto risultato viene ottenuto tramite due operazioni:\n\n- si associano alcuni indirizzi che originariamente portavano a locazioni nella RAM ai suddetti registri;\n- si utilizza una particolare linea del bus I/O, detta **_Memory/Input-Output (M/#IO)_**, per decidere se l'indirizzo porta a una locazione in RAM (la linea non è attiva, ovvero trasmette valore 0) o ad un dispositivo I/O (trasmette 1, la linea è attiva).\n\nIn questo modo i registri dei (controller dei) dispositivi I/O diventano semplici locazioni di memoria, e possono essere gestiti con istruzioni \"_MOV-like_\" dell'Assembly di base.\n\nQuesto semplifica il codice del driver, la portabilità e certamente la vita del programmatore.\n\nDi contro, gli indirizzi associati all'I/O \"sprecano\" memoria fisica, poiché rendono inutilizzabile l'intero frame che li contiene (ma c'è da dire che a 64bit posso sprecarne quanta ne voglio, e quando questa affermazione non sarà più vera io sarò morto da un pezzo).\n### _**Port-Mapped I/O (PMIO)**_\n\nSe MMIO è sempre implementabile perché usa risorse standard, per PMIO serve supporto HW specifico. In particolare, parliamo di un *chipset* che fornisce uno spazio di indirizzamento (o per farla breve, altra memoria) dedicato all'I/O.\n\nOgni registro del controller è mappato in una _**porta**_, ovverosia uno di questi \"nuovi\" indirizzi associati alla memoria del *chipset*, e le operazioni di I/O avvengono tramite istruzioni speciali quali _**IN**_ (lettura) e **_OUT_** (scrittura) senza che venga chiamata in causa la linea M/#IO.\n\nL'esatta implementazione HW mi è oscura, ma forse in questa sede non serve approfondire.\n","x":1200,"y":169,"width":786,"height":992,"color":"4"},
		{"id":"7bdf1dc58118080b","type":"file","file":"Input-Output/IO_CPU_POV.png","x":3100,"y":-331,"width":440,"height":436},
		{"id":"13a15e4783d53ebf","type":"file","file":"Input-Output/DMA_scheme.png","x":3100,"y":-684,"width":440,"height":300},
		{"id":"6b0a964076e74b05","type":"text","text":"# Bus\n\nI vari componenti dell'HW comunicano attraverso il **_bus_**, visualizzabile come una rete autostradale di rame stampata sulla scheda madre.\n\nPrincipalmente è suddiviso in tre categorie:\n\n- _**Bus dei dati**_ - Autoesplicativo, vi circolano i dati da scambiare tra dispositivi;\n- _**Bus degli indirizzi**_ - Dedicato agli indirizzi di memoria, fa da spola tra CPU e RAM;\n- _**Bus di controllo**_ - Dedicato a comandi quali inizio/fine trasmissioni, modalità di I/O, ...\n\nNei moderni sistemi informatici questi tre concetti spesso si fondono, e si preferisce riferirsi ai vari bus in relazione al compito che svolgono. Esempi in tal senso sono\n\n- _**Bus di Sistema**_ - Canale privilegiato tra CPU e RAM, _controller_ di periferiche e _chipset_;\n- **_Bus del Sistema Locale (Local Bus)_** - Canale privilegiato ad alta velocità tra CPU e componenti integrati (e.g. memoria cache, GPU, ...);\n- **_Bus di I/O_** - Canale privilegiato tra CPU e dispositivi **integrati** di I/O.\n\nQuesti sono detti _**bus interni**_. Vi sono poi i **_bus esterni_** (o _**bus di Espansione**_), che includono una grande varietà di bus secondari e che consentono l'aggiunta di GPU, periferiche ed altri dispositivi esterni. Esempi comuni sono\n\n- _**Universal Serial Bus (USB)**_ - Sappiamo tutti cos'è, ed è molto flessibile;\n- _**Advanced Technology Attachment (ATA)**_ - Interfaccia standard per la connessione di dispositivi di memoria secondaria come HDD o SSD, utilizza la _trasmissione parallela_;\n\t- **_Serial-ATA (SATA)_** - Versione seriale di ATA, che quindi non utilizza la trasmissione parallela;\n- **_Peripheral Component Interconnect (PCI)_** - Utilizzato per connettere una grande varietà di componenti, presente in svariate versioni quali _PCI-X_, _PCIe_, ...\n- _**Ethernet**_ - Gestisce i pacchetti di comunicazione di rete.\n\nTali bus differiscono per molti aspetti, quali ad esempio protocollo di trasferimento dati e velocità.\n\nL'implementazione HW può prevedere\n\n- _**linee fisicamente separate**_: si tende a separare i bus dati, indirizzi e controllo nel bus di Sistema per minimizzare le interferenze tra di essi, o anche il bus PCIe ha linee diverse che supportano diverse velocità di trasmissione dei dati;\n- **_linee condivise_**: alcuni bus di espansione come USB e SATA possono condividere le stesse linee fisiche per l'alimentazione e il controllo.","x":160,"y":169,"width":853,"height":992,"color":"4"},
		{"id":"eee85e14dae1ee1c","type":"text","text":"# Controller\n\n Ogni *Controller* ha un set di registri per comunicare con CPU e DMA. Questi sono\n \n - **_Registri di Stato_** - forniscono informazioni sullo stato del dispositivo di I/O alla CPU (e.g. inattivo, pronto per l'input, occupato, errore, transazione completata);\n- **_Registri di configurazione/controllo_**: utilizzati dalla CPU per configurare e controllare il dispositivo (e.g. impostare la modalità _write_, avviare/interrompere le operazioni, ...);\n- **_Registri dati_**: utilizzati per leggere dati da o inviare dati al dispositivo di I/O.\n\nTipicamente, a ogni dispositivo I/O è associata una _queue_ in cui i processi attendono che il dispositivo diventi disponibile o che consegni dati.","x":2170,"y":208,"width":787,"height":343,"color":"4"},
		{"id":"1fb92b9bd42e2c32","type":"file","file":"Input-Output/addressing_IO.png","x":2170,"y":700,"width":787,"height":416},
		{"id":"771c1bd426fd8f47","type":"text","text":"# Quindi la differenza è...\n\n... che se in Assembly scrivo \n\n\tMOV DX, 1234h\n\tMOV AL, [DX]\n\nsto leggendo il contenuto dell'indirizzo di memoria `0x1234` che mi porta poi alla periferica (devo usare il canale M/#IO del Control Bus), mentre invece se scrivo\n\n\tMOV DX, 1234h\n\tIN AL, DX\n\nmi interfaccio direttamente col chip di I/O corrispondente su di un I/O Address Space.\n\nNotare che entrambi gli approcci scrivono `0x1234` sull'Address Bus e invocano la READ sul Control Bus.\n\n","x":3100,"y":379,"width":440,"height":573,"color":"4"},
		{"id":"255c19cad945a18f","type":"text","text":"# Operazioni di Input/Output","x":328,"y":-80,"width":518,"height":50,"color":"3"},
		{"id":"cffda0fb3a359471","type":"text","text":"# Come scrivo un Sistema Informatico?\n\nI primi sistemi informatici erano scritti interamente in Assembly.\n\nQuesto garantiva un controllo diretto sull'HW, e di conseguenza una forte possibilità di ottimizzazione. Di contro, l'implementazione era specifica del sistema, il che riduceva al minimo la portabilità.\n\nAd oggi, la strategia consiste nel'utilizzare una combinazione di linguaggi:\n\n- Livelli più bassi in **_Assembly_**;\n- Corpo principale in **_C_**;\n- Programmi di sistema in C, **_C++_** e linguaggi interpretati come **_Python_**.\n\nLa distinzione tra il _cosa fare_ (la logica e le regole di funzionamento del sistema, anche dette per qualche motivo **_politiche_**) e il _come farlo_ (l'implementazione a livello di linguaggio) è alla base della progettazione di un SO (e.g. \"non conviene utilizzare lo stesso linguaggio per ogni politica\"), in quanto incrementa\n\n- **_Flessibilità_** - La facilità di aggiunta e/o modifica delle politiche;\n- _**Riusabilità**_ - Autoesplicativo, anche in senso di portabilità. Non serve riscrivere il codice;\n- **_Stabilità_** - ... del Sistema rispetto all'aggiunta di una nuova politica (e.g. non voglio che una nuova _feature_ che aggiungo vada in conflitto con quello che già funziona).","x":160,"y":1310,"width":853,"height":597,"color":"4"},
		{"id":"9f60f09a269a32aa","type":"text","text":"# Manage Multiprogramming Memory\n\n- Sharing\n\t- Several processes coexist in main memory at the same time\n\t- Cooperating processes can share portions of address space\n\n- Transparency\n\t- Processes should not be aware that memory is shared\n\t- Processes should not be aware of which portions of physical memory they are assigned to\n\n- Protection/Security\n\t- Processes must not be able to corrupt each other or the OS\n\t- Processes must not be able to read data of other processes\n\n- Efficiency\n\t- CPU and memory performance should not degrade badly due to sharing\n\t- Keep memory fragmentation low","x":1280,"y":-4380,"width":541,"height":640,"color":"1"},
		{"id":"50134cc52be508aa","type":"file","file":"OS_Design.pdf","x":2170,"y":1310,"width":787,"height":597,"color":"4"},
		{"id":"2066cad210080a20","type":"text","text":"# Struttura di un Sistema Informatico\n\nI primi sistemi informatici (e.g. **_MS-DOS_**) avevano una struttura talmente semplice da permettere alle applicazioni in spazio utente di accedere direttamente all'HW ($\\Rightarrow$ niente Kernel Mode!). Questo chiaramente portava con sé grossi problemi di sicurezza.\n\nNegli anni '70 i sistemi UNIX introducono la **_struttura monolitica_**, in cui è presente un unico grande modulo (**_Kernel_**) che raccoglie tutte le funzionalità da fornire alle applicazioni del livello Utente.\n\nPer migliorare la flessibilità rispetto all'aggiunta di nuove funzionalità, negli anni '80 il SO **_Mach_** introduce una struttura modulare detta **_microkernel_**, che deve il suo nome all'idea di ridurre i compiti del Kernel lasciando gran parte del lavoro alla User Mode, dove vengono ad esempio gestiti (come moduli separati) il *filesystem* e i *driver*. Il Kernel si limita a gestire la comunicazione tra processi (**_IPC_**), la memoria e la CPU.\n\nAd oggi, si tende ad implementare sistemi ibridi che sfruttano i vantaggi di entrambi gli approcci. Ad esempio, un Kernel monolitico può supportare i **_Loadable Kernel Modules (LKMs)_**, ovvero moduli che estendono le funzionalità del Kernel di base direttamente a runtime. In pratica, questo è lo stato dell'arte tra i SO più noti:\n\n- SO come **_Linux_** e **_Solaris_** implementano un Kernel monolitico con l'aggiunta dei *LKMs* (anche detto complessivamente **_modular monolithic_**);\n- La linea di SO **_Windows NT_** (che include *Windows 11*) è un ibrido che consta principalmente di un blocco monolitico a cui si affianca un microkernel per diversi sottosistemi;\n- **_Apple Mac OS X_** è un'*insolita* combinazione di Kernel monolitico (BSD UNIX), microkernel (Mach) e LKMs.","x":1200,"y":1251,"width":786,"height":716,"color":"4"},
		{"id":"c02fca4457eea4a1","type":"text","text":"# Software Design","x":-602,"y":1580,"width":298,"height":59,"color":"6"}
	],
	"edges":[
		{"id":"95151c4e7f8fbc92","fromNode":"f259623a35cf9802","fromSide":"right","toNode":"1fb92b9bd42e2c32","toSide":"left"},
		{"id":"d293de9c75d36484","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"651b3e34405ca302","toSide":"bottom"},
		{"id":"4f3fd12e72b50247","fromNode":"16683038ca807a6e","fromSide":"left","toNode":"f104b3656720780b","toSide":"right"},
		{"id":"54a1b680c224da4b","fromNode":"f104b3656720780b","fromSide":"left","toNode":"4f7a30ec90f5f7a1","toSide":"right"},
		{"id":"3398396f12b7d67c","fromNode":"16683038ca807a6e","fromSide":"right","toNode":"c02fca4457eea4a1","toSide":"left"},
		{"id":"1df4ae7e3b3f3880","fromNode":"16683038ca807a6e","fromSide":"bottom","toNode":"ccea465ee5a66f66","toSide":"top"},
		{"id":"c94d1eb183cd2ea4","fromNode":"f104b3656720780b","fromSide":"bottom","toNode":"ccea465ee5a66f66","toSide":"left"},
		{"id":"5d94b490a5b2e514","fromNode":"ccea465ee5a66f66","fromSide":"left","toNode":"f104b3656720780b","toSide":"bottom"},
		{"id":"f4396814055bce28","fromNode":"4f7a30ec90f5f7a1","fromSide":"bottom","toNode":"077958ec99cf0920","toSide":"top"},
		{"id":"1b4788b11ebf0238","fromNode":"077958ec99cf0920","fromSide":"left","toNode":"9ed99aa483da3638","toSide":"right"},
		{"id":"1dd016202fbf2fdc","fromNode":"3cbd143423e3f10a","fromSide":"bottom","toNode":"1c983ed53f331726","toSide":"top"},
		{"id":"9078d105834790b6","fromNode":"7c61dcb5932faf1f","fromSide":"left","toNode":"66990f7c63e2d405","toSide":"right"},
		{"id":"2c527e4b10454f12","fromNode":"66990f7c63e2d405","fromSide":"top","toNode":"e286057ad92c4f0c","toSide":"bottom"},
		{"id":"7b732ebd6b98fb05","fromNode":"66990f7c63e2d405","fromSide":"right","toNode":"a468bd8ba770bd4b","toSide":"left"},
		{"id":"9571cd60a5124870","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"4ff852d5afad6346","toSide":"right"},
		{"id":"66573d7025a6c12e","fromNode":"7c61dcb5932faf1f","fromSide":"bottom","toNode":"6c0f163753eb8b85","toSide":"top"},
		{"id":"f5136f611675b525","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"2a9d90b8cc31da54","toSide":"right"},
		{"id":"f463b513261aace8","fromNode":"a468bd8ba770bd4b","fromSide":"left","toNode":"e286057ad92c4f0c","toSide":"right"},
		{"id":"d893929f320106c9","fromNode":"4ff852d5afad6346","fromSide":"bottom","toNode":"2a9d90b8cc31da54","toSide":"top"},
		{"id":"567c9121d0606efb","fromNode":"66990f7c63e2d405","fromSide":"right","toNode":"005e7e1e1c753ec3","toSide":"left"},
		{"id":"c328310a1108ab59","fromNode":"005e7e1e1c753ec3","fromSide":"bottom","toNode":"b73522939cb2e340","toSide":"top"},
		{"id":"27e340efb990c46f","fromNode":"66990f7c63e2d405","fromSide":"bottom","toNode":"30f61bfe887b9609","toSide":"top"},
		{"id":"0d30eb082ccf3688","fromNode":"005e7e1e1c753ec3","fromSide":"left","toNode":"30f61bfe887b9609","toSide":"right"},
		{"id":"2feb230814305d21","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"ee4978ec280e0156","toSide":"bottom"},
		{"id":"6adf051489ec3ca2","fromNode":"ccea465ee5a66f66","fromSide":"right","toNode":"113ca9ce4e51d6e6","toSide":"left"},
		{"id":"cbec9e6171417d9a","fromNode":"113ca9ce4e51d6e6","fromSide":"top","toNode":"b18a396618049aa5","toSide":"bottom"},
		{"id":"b3a442e2fbe1e6d6","fromNode":"113ca9ce4e51d6e6","fromSide":"right","toNode":"f9cd9cbd5670ae73","toSide":"left"},
		{"id":"d79a4b17e6be3f2e","fromNode":"113ca9ce4e51d6e6","fromSide":"bottom","toNode":"4a9e0af6fa1f8472","toSide":"top"},
		{"id":"d6f0d98646ef8786","fromNode":"4a9e0af6fa1f8472","fromSide":"left","toNode":"fad3582cc9b8fe57","toSide":"right"},
		{"id":"e20e3517047dbf43","fromNode":"fad3582cc9b8fe57","fromSide":"bottom","toNode":"933c1f33f83329d3","toSide":"top"},
		{"id":"dbbc61ed301cfd99","fromNode":"933c1f33f83329d3","fromSide":"left","toNode":"004837f0a7396bbf","toSide":"right"},
		{"id":"8a06bf0ae88cd109","fromNode":"004837f0a7396bbf","fromSide":"bottom","toNode":"45cd529f8bc60a75","toSide":"top"},
		{"id":"3458496fb70e45db","fromNode":"45cd529f8bc60a75","fromSide":"right","toNode":"933c1f33f83329d3","toSide":"left"},
		{"id":"42a43d777eddf699","fromNode":"4a9e0af6fa1f8472","fromSide":"bottom","toNode":"0bac8ddd0cc0ea48","toSide":"top"},
		{"id":"71489c7da900eae1","fromNode":"0bac8ddd0cc0ea48","fromSide":"top","toNode":"6b26542e75b5a010","toSide":"left"},
		{"id":"f9fb8571fc15d11c","fromNode":"0bac8ddd0cc0ea48","fromSide":"bottom","toNode":"d1b1da8e14a89c26","toSide":"top"},
		{"id":"15798cc8c3766df7","fromNode":"d1b1da8e14a89c26","fromSide":"right","toNode":"5ebb9d2dabcdc329","toSide":"left"},
		{"id":"9d981c6cd76b382b","fromNode":"d1b1da8e14a89c26","fromSide":"bottom","toNode":"ec02cf92e35c5eb6","toSide":"top"},
		{"id":"e08a6e14da48b53a","fromNode":"61fad2ad255cf82a","fromSide":"right","toNode":"27e4fdde4c9ad72d","toSide":"left"},
		{"id":"3b73f401a4430ae2","fromNode":"27e4fdde4c9ad72d","fromSide":"left","toNode":"61fad2ad255cf82a","toSide":"right"},
		{"id":"9600f852b160883f","fromNode":"26cfad6010ff7969","fromSide":"left","toNode":"27e4fdde4c9ad72d","toSide":"right"},
		{"id":"3a544c663e5af73e","fromNode":"26cfad6010ff7969","fromSide":"bottom","toNode":"8c7076684bac10a2","toSide":"top"},
		{"id":"cfbee7a02809a3c9","fromNode":"933c1f33f83329d3","fromSide":"right","toNode":"0bac8ddd0cc0ea48","toSide":"left"},
		{"id":"eec7b20bf6a64276","fromNode":"0bac8ddd0cc0ea48","fromSide":"left","toNode":"26cfad6010ff7969","toSide":"right"},
		{"id":"390f1c28413c1b85","fromNode":"8c7076684bac10a2","fromSide":"left","toNode":"8d0dc0d08efb8898","toSide":"right"},
		{"id":"9dcad2358fc814cb","fromNode":"8d0dc0d08efb8898","fromSide":"left","toNode":"e00a97cccf420735","toSide":"right"},
		{"id":"583dbca61d1454cf","fromNode":"8c7076684bac10a2","fromSide":"bottom","toNode":"28ef98e44e010a54","toSide":"top"},
		{"id":"a0c6776ccaf2b63a","fromNode":"e00a97cccf420735","fromSide":"bottom","toNode":"9c55c12867f0cfe8","toSide":"top"},
		{"id":"18ec5dd67397394a","fromNode":"28ef98e44e010a54","fromSide":"left","toNode":"b38a5df100f9850b","toSide":"right"},
		{"id":"c8a53e70710242cb","fromNode":"9c55c12867f0cfe8","fromSide":"bottom","toNode":"a6494ec2a3a14739","toSide":"top"},
		{"id":"b160f9150bb7ee41","fromNode":"ed6ac0281f980f03","fromSide":"left","toNode":"19cda58d82f6e368","toSide":"right"},
		{"id":"86699d4adc27ad53","fromNode":"6dbca290cf842d6e","fromSide":"left","toNode":"9a0af77adce9ad06","toSide":"right"},
		{"id":"7507abfe85a6e554","fromNode":"9a0af77adce9ad06","fromSide":"top","toNode":"ed6ac0281f980f03","toSide":"bottom"},
		{"id":"571b4df7d4649dfd","fromNode":"69f3dd73ee95ff32","fromSide":"right","toNode":"7d169a16a8cca630","toSide":"left"},
		{"id":"828f3ed4f1df74af","fromNode":"69f3dd73ee95ff32","fromSide":"right","toNode":"58f52445ff3fb61e","toSide":"left"},
		{"id":"98d30276bbac9479","fromNode":"69f3dd73ee95ff32","fromSide":"bottom","toNode":"e4716290f3d5b096","toSide":"top"},
		{"id":"bf3d050c573b60d5","fromNode":"a809a009a3c7f901","fromSide":"right","toNode":"e4716290f3d5b096","toSide":"left"},
		{"id":"585153ac4f249aa4","fromNode":"e4716290f3d5b096","fromSide":"left","toNode":"a809a009a3c7f901","toSide":"right"},
		{"id":"69173c86f8cfb215","fromNode":"69f3dd73ee95ff32","fromSide":"bottom","toNode":"a809a009a3c7f901","toSide":"top"},
		{"id":"a478b13a8954f96b","fromNode":"a809a009a3c7f901","fromSide":"right","toNode":"f3560ddcee0e71de","toSide":"left"},
		{"id":"6d2aaf39cbed1436","fromNode":"f3560ddcee0e71de","fromSide":"right","toNode":"346edb2cd343ae50","toSide":"left"},
		{"id":"28ca28c9bd29dbfb","fromNode":"346edb2cd343ae50","fromSide":"bottom","toNode":"deedc18089e093f1","toSide":"top"},
		{"id":"63b6e17c3e3869ec","fromNode":"edd84b5881ba408b","fromSide":"top","toNode":"46a10f1736b333eb","toSide":"bottom"},
		{"id":"44ad6a4d17bbb04b","fromNode":"346edb2cd343ae50","fromSide":"right","toNode":"652e671c121210e0","toSide":"left"},
		{"id":"389909bba676d73e","fromNode":"a23e13dca8a3ad1d","fromSide":"bottom","toNode":"0c73604c03c3a581","toSide":"top"},
		{"id":"3bf4a9b4f5cea38d","fromNode":"652e671c121210e0","fromSide":"top","toNode":"62a83dc4f208244f","toSide":"bottom"},
		{"id":"449edb8fb12460cc","fromNode":"62a83dc4f208244f","fromSide":"right","toNode":"a23e13dca8a3ad1d","toSide":"left"},
		{"id":"5c9a0e053f0aad07","fromNode":"a23e13dca8a3ad1d","fromSide":"left","toNode":"62a83dc4f208244f","toSide":"right"},
		{"id":"509cee5635115cba","fromNode":"ee6c1653941f5cf9","fromSide":"left","toNode":"374ffdc5ef9b8c37","toSide":"right"},
		{"id":"4cc9780356b854be","fromNode":"374ffdc5ef9b8c37","fromSide":"left","toNode":"c117519b0d042f3b","toSide":"right"},
		{"id":"2026858fb723c170","fromNode":"4e690bb692a0c595","fromSide":"left","toNode":"fc632d9a9c345ef1","toSide":"right"},
		{"id":"1cc3c26491c15394","fromNode":"69f3dd73ee95ff32","fromSide":"top","toNode":"742f4065dd5c5cbc","toSide":"bottom"},
		{"id":"63c24152615b505d","fromNode":"742f4065dd5c5cbc","fromSide":"top","toNode":"e9bab4cd14415702","toSide":"bottom"},
		{"id":"15f69df2a41b8a3b","fromNode":"742f4065dd5c5cbc","fromSide":"top","toNode":"6b5bb4e98e9e2a28","toSide":"bottom"},
		{"id":"780d602ef9a08740","fromNode":"62a83dc4f208244f","fromSide":"top","toNode":"e9bab4cd14415702","toSide":"right"},
		{"id":"403047f28a694c6d","fromNode":"e9bab4cd14415702","fromSide":"right","toNode":"62a83dc4f208244f","toSide":"top"},
		{"id":"9f8dc2221891f2f8","fromNode":"6b5bb4e98e9e2a28","fromSide":"top","toNode":"b5aedc73d018cc9e","toSide":"bottom"},
		{"id":"9c5ed8b3d94683e7","fromNode":"6b5bb4e98e9e2a28","fromSide":"left","toNode":"23b1b309c92014a7","toSide":"right"},
		{"id":"3bf40c61746fa239","fromNode":"23b1b309c92014a7","fromSide":"left","toNode":"760de5855566da94","toSide":"right"},
		{"id":"1b5c1f25dfeb08c2","fromNode":"6b5bb4e98e9e2a28","fromSide":"top","toNode":"ab7ce62182178f88","toSide":"left"},
		{"id":"f0600a4436663ad2","fromNode":"742f4065dd5c5cbc","fromSide":"right","toNode":"05216adedc2d6235","toSide":"left"},
		{"id":"1bedea8102e4294d","fromNode":"ab7ce62182178f88","fromSide":"left","toNode":"6b5bb4e98e9e2a28","toSide":"top"},
		{"id":"0fbc13db8479476e","fromNode":"e9bab4cd14415702","fromSide":"top","toNode":"ab7ce62182178f88","toSide":"bottom"},
		{"id":"f4e795e9a1ce9d6f","fromNode":"ab7ce62182178f88","fromSide":"bottom","toNode":"e9bab4cd14415702","toSide":"top"},
		{"id":"f660b2978b3bd069","fromNode":"6b5bb4e98e9e2a28","fromSide":"right","toNode":"e9bab4cd14415702","toSide":"left"},
		{"id":"6e43c1eaf117c27c","fromNode":"05216adedc2d6235","fromSide":"right","toNode":"9132abad1267a121","toSide":"left"},
		{"id":"d56c1f5bac3b324f","fromNode":"05216adedc2d6235","fromSide":"top","toNode":"fdb26cc1e8ca8651","toSide":"bottom"},
		{"id":"b2e4d396fa33d604","fromNode":"fdb26cc1e8ca8651","fromSide":"right","toNode":"f03ea06b8cc06adb","toSide":"left"},
		{"id":"8f50d906d38e1b31","fromNode":"c117519b0d042f3b","fromSide":"left","toNode":"4e690bb692a0c595","toSide":"right"},
		{"id":"7da6d5dec7c7d5d0","fromNode":"06528774c7a17e8f","fromSide":"left","toNode":"c5128c9a62b77d1c","toSide":"right"},
		{"id":"7f41b52fcbac8526","fromNode":"651b3e34405ca302","fromSide":"left","toNode":"06528774c7a17e8f","toSide":"right"},
		{"id":"b019c7f6be2c305b","fromNode":"f9bd700671836856","fromSide":"right","toNode":"05a52d5c383fdd33","toSide":"left"},
		{"id":"c3beda2541535d14","fromNode":"05a52d5c383fdd33","fromSide":"right","toNode":"91a7b729904ab462","toSide":"left"},
		{"id":"daca2ba5fa9b4844","fromNode":"91a7b729904ab462","fromSide":"right","toNode":"4ed8448bbff5587f","toSide":"left"},
		{"id":"f2f94906ad373bd3","fromNode":"4ed8448bbff5587f","fromSide":"right","toNode":"d2c45ccedbf34eb0","toSide":"left"},
		{"id":"8406e3f2eef269a6","fromNode":"5d912aa428876e90","fromSide":"right","toNode":"78c933cd845defb1","toSide":"left"},
		{"id":"d69f2f6196e4db02","fromNode":"925b75588817e4f2","fromSide":"right","toNode":"1b3e6646aedc9b50","toSide":"left"},
		{"id":"8b3a7cbf0334b6c7","fromNode":"69f392e5d5620920","fromSide":"top","toNode":"394c80ddc305d5fc","toSide":"bottom"},
		{"id":"5d75a4bd6dbe4580","fromNode":"394c80ddc305d5fc","fromSide":"top","toNode":"ee6c1653941f5cf9","toSide":"bottom"},
		{"id":"ef60b7ab0ca1cf94","fromNode":"394c80ddc305d5fc","fromSide":"right","toNode":"69f3dd73ee95ff32","toSide":"left"},
		{"id":"4d25e1c937f6135e","fromNode":"394c80ddc305d5fc","fromSide":"top","toNode":"742f4065dd5c5cbc","toSide":"bottom"},
		{"id":"57c970f29c1be82f","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"06528774c7a17e8f","toSide":"right"},
		{"id":"9844964de2f05915","fromNode":"ccea465ee5a66f66","fromSide":"bottom","toNode":"90f8b175ee0fef4f","toSide":"top"},
		{"id":"74bf4eaec0201823","fromNode":"651b3e34405ca302","fromSide":"left","toNode":"7baf25458002b00c","toSide":"right"},
		{"id":"75e83aa6e12947fe","fromNode":"c5128c9a62b77d1c","fromSide":"bottom","toNode":"7f02462535d305da","toSide":"top"},
		{"id":"357b5482ccf2a312","fromNode":"c5128c9a62b77d1c","fromSide":"left","toNode":"558ba900733523b5","toSide":"right"},
		{"id":"80975f5ba94881a7","fromNode":"c5128c9a62b77d1c","fromSide":"top","toNode":"b763de7850a80c53","toSide":"bottom"},
		{"id":"f053df1d747e382b","fromNode":"05216adedc2d6235","fromSide":"top","toNode":"c0aaa4d8737bbd67","toSide":"bottom"},
		{"id":"74cc06e7a2a5d983","fromNode":"558ba900733523b5","fromSide":"bottom","toNode":"013481a47473bf04","toSide":"top"},
		{"id":"e11feb62499f473b","fromNode":"651b3e34405ca302","fromSide":"top","toNode":"6dbca290cf842d6e","toSide":"bottom"},
		{"id":"e44c555cd7d9a5c8","fromNode":"6dbca290cf842d6e","fromSide":"top","toNode":"69f392e5d5620920","toSide":"bottom"},
		{"id":"de434771f7061d15","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"2277df60d0b7b90f","toSide":"bottom"},
		{"id":"5472c01c63ac8391","fromNode":"2277df60d0b7b90f","fromSide":"top","toNode":"06c47d975b9c7d82","toSide":"bottom"},
		{"id":"0a857a16aed797cc","fromNode":"06c47d975b9c7d82","fromSide":"left","toNode":"c93ccfe2826bfc84","toSide":"right"},
		{"id":"7bd062321b0236f7","fromNode":"06c47d975b9c7d82","fromSide":"top","toNode":"857795b982b5006c","toSide":"bottom"},
		{"id":"1a2293ab3fe042ad","fromNode":"06c47d975b9c7d82","fromSide":"top","toNode":"c5eb197b387106c9","toSide":"bottom"},
		{"id":"c900a68277a420e2","fromNode":"06c47d975b9c7d82","fromSide":"top","toNode":"6494019ed201af83","toSide":"bottom"},
		{"id":"39f3d249f872769f","fromNode":"06c47d975b9c7d82","fromSide":"top","toNode":"1f6e7fb2cae77036","toSide":"bottom"},
		{"id":"89fa4bad04e4b06b","fromNode":"2277df60d0b7b90f","fromSide":"right","toNode":"e4d567401ca48648","toSide":"bottom"},
		{"id":"4de8b5761ab43019","fromNode":"06c47d975b9c7d82","fromSide":"top","toNode":"7837e938756397ea","toSide":"bottom"},
		{"id":"7ded96e1be566134","fromNode":"06c47d975b9c7d82","fromSide":"top","toNode":"b3de1e1183a15476","toSide":"bottom"},
		{"id":"d809f2ba4544c4ac","fromNode":"c5128c9a62b77d1c","fromSide":"top","toNode":"561a1434023c1429","toSide":"bottom"},
		{"id":"7d2263761473f075","fromNode":"561a1434023c1429","fromSide":"left","toNode":"dc4fb6069113402c","toSide":"right"},
		{"id":"4cf4bfa9035fab07","fromNode":"558ba900733523b5","fromSide":"left","toNode":"307924e88efadd9d","toSide":"right"},
		{"id":"b74d525327d12a13","fromNode":"307924e88efadd9d","fromSide":"top","toNode":"a2ca84c1f075532c","toSide":"bottom"},
		{"id":"36e5f0f442a392ec","fromNode":"307924e88efadd9d","fromSide":"bottom","toNode":"3cbd143423e3f10a","toSide":"top"},
		{"id":"8c9b56234cffad97","fromNode":"3cbd143423e3f10a","fromSide":"left","toNode":"e2aefc482d1e7497","toSide":"right"},
		{"id":"d00b912adb5f2b4c","fromNode":"1c983ed53f331726","fromSide":"bottom","toNode":"ba2b6213e4637219","toSide":"top"},
		{"id":"7ec977f1e0bd7e21","fromNode":"7f02462535d305da","fromSide":"right","toNode":"0d18d001289cc624","toSide":"left"},
		{"id":"e74289d651f858e9","fromNode":"c5128c9a62b77d1c","fromSide":"right","toNode":"0d18d001289cc624","toSide":"top"},
		{"id":"abf9f5f7bf9879a8","fromNode":"0d18d001289cc624","fromSide":"bottom","toNode":"ebda4cf153d6ae26","toSide":"top"},
		{"id":"7c4bf2473d0de616","fromNode":"7f02462535d305da","fromSide":"bottom","toNode":"ebda4cf153d6ae26","toSide":"top"},
		{"id":"30f403ef7e79598f","fromNode":"0d18d001289cc624","fromSide":"left","toNode":"7f02462535d305da","toSide":"right"},
		{"id":"4fad9eb217b2945c","fromNode":"4f7a30ec90f5f7a1","fromSide":"left","toNode":"ebda4cf153d6ae26","toSide":"right"},
		{"id":"709043d198b42ea1","fromNode":"ebda4cf153d6ae26","fromSide":"left","toNode":"8287aebf1f270337","toSide":"bottom"},
		{"id":"0bcf6e3fa8e1e2c7","fromNode":"ebda4cf153d6ae26","fromSide":"left","toNode":"e067d5bbcbdb0467","toSide":"bottom"},
		{"id":"e155650249354c9d","fromNode":"90f8b175ee0fef4f","fromSide":"bottom","toNode":"9f547af6eb5bcda0","toSide":"top"},
		{"id":"3e230d75521bf045","fromNode":"9f547af6eb5bcda0","fromSide":"bottom","toNode":"e2cb98b1a469f746","toSide":"top"},
		{"id":"ff6b913cc94dcc42","fromNode":"e2cb98b1a469f746","fromSide":"bottom","toNode":"e864bef1d25309b9","toSide":"top"},
		{"id":"a92d521832c76230","fromNode":"077958ec99cf0920","fromSide":"bottom","toNode":"6f102d8a296c67cf","toSide":"top"},
		{"id":"ae69c871c632855b","fromNode":"e2cb98b1a469f746","fromSide":"left","toNode":"0eb83793c297bd77","toSide":"right"},
		{"id":"26538a8673011a60","fromNode":"6f102d8a296c67cf","fromSide":"right","toNode":"64979b6fb82965c3","toSide":"bottom"},
		{"id":"94e7b597ea7efbd7","fromNode":"64979b6fb82965c3","fromSide":"top","toNode":"0eb83793c297bd77","toSide":"left"},
		{"id":"c098f289aa13bd1f","fromNode":"6f102d8a296c67cf","fromSide":"left","toNode":"da735d0e411a3e63","toSide":"right"},
		{"id":"f2651e427a8bd08e","fromNode":"da735d0e411a3e63","fromSide":"bottom","toNode":"127fb02c474f9e0c","toSide":"right"},
		{"id":"ec414caa5ffc4c92","fromNode":"6f102d8a296c67cf","fromSide":"bottom","toNode":"8fac94dbd27f5a21","toSide":"top"},
		{"id":"e1a285ef8019d655","fromNode":"0eb83793c297bd77","fromSide":"top","toNode":"efa5f9c31e4d06bc","toSide":"bottom"},
		{"id":"32b1798ef58472d5","fromNode":"6f102d8a296c67cf","fromSide":"right","toNode":"c09d363d1d2b82e8","toSide":"top"},
		{"id":"aef1202f028a2b40","fromNode":"c09d363d1d2b82e8","fromSide":"bottom","toNode":"890280218841edc0","toSide":"left"},
		{"id":"d6ced16610d65e1b","fromNode":"0eb83793c297bd77","fromSide":"bottom","toNode":"890280218841edc0","toSide":"top"},
		{"id":"89585a23b563eace","fromNode":"8fac94dbd27f5a21","fromSide":"bottom","toNode":"4fe1989d7b05db02","toSide":"top"},
		{"id":"a84aa16dadb02c19","fromNode":"127fb02c474f9e0c","fromSide":"left","toNode":"7c61dcb5932faf1f","toSide":"right"},
		{"id":"7dbd6673eddea132","fromNode":"66990f7c63e2d405","fromSide":"top","toNode":"ba2b6213e4637219","toSide":"bottom"},
		{"id":"1c049c578abd585d","fromNode":"4ff852d5afad6346","fromSide":"top","toNode":"8ebd810af3667125","toSide":"bottom"},
		{"id":"0c33c7c7108fd164","fromNode":"e2aefc482d1e7497","fromSide":"top","toNode":"7c939ee2ebe1207c","toSide":"bottom"},
		{"id":"350df24d468debd4","fromNode":"b73522939cb2e340","fromSide":"bottom","toNode":"26f21190e660b29e","toSide":"top"},
		{"id":"20a116aea345ea5f","fromNode":"ee4978ec280e0156","fromSide":"top","toNode":"c948ce6320acafbe","toSide":"bottom"},
		{"id":"7ee08ab26ebc2064","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"61b2fd4819af306d","toSide":"top"},
		{"id":"755cc17dfb8b7f39","fromNode":"558ba900733523b5","fromSide":"left","toNode":"d149b3dfbe917b55","toSide":"bottom"},
		{"id":"b5d8f69597eaa52b","fromNode":"4fe1989d7b05db02","fromSide":"bottom","toNode":"d5c101f97e76cc55","toSide":"top"},
		{"id":"9b5820ac5042be2b","fromNode":"7c61dcb5932faf1f","fromSide":"top","toNode":"65691212673b8e15","toSide":"bottom"},
		{"id":"2679a3867009acdf","fromNode":"f9cd9cbd5670ae73","fromSide":"right","toNode":"b34d99bdf2278892","toSide":"left"},
		{"id":"b46522b42417a9cf","fromNode":"5ebb9d2dabcdc329","fromSide":"right","toNode":"10e69b68374e69a4","toSide":"left"},
		{"id":"216dd077101cf6d1","fromNode":"5c0597c2efcb77b1","fromSide":"bottom","toNode":"1dad249a05ab28b1","toSide":"top"},
		{"id":"96b949e1fac0bc41","fromNode":"c835796226556bf7","fromSide":"bottom","toNode":"28c7d6f803083c2b","toSide":"top"},
		{"id":"b717d47de2f11540","fromNode":"6b26542e75b5a010","fromSide":"bottom","toNode":"5c0597c2efcb77b1","toSide":"top"},
		{"id":"6df02014ecdf9742","fromNode":"6b26542e75b5a010","fromSide":"bottom","toNode":"c835796226556bf7","toSide":"top"},
		{"id":"bc20df6e3eaadb8f","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"7b74698d9783de73","toSide":"right"},
		{"id":"7587dac83bdb97bc","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"4d11f59d7f807802","toSide":"left"},
		{"id":"8f3a500ae3d1882f","fromNode":"4d11f59d7f807802","fromSide":"right","toNode":"6b0a964076e74b05","toSide":"left"},
		{"id":"4280ec6efa41a258","fromNode":"4d11f59d7f807802","fromSide":"top","toNode":"255c19cad945a18f","toSide":"left"},
		{"id":"c839bef60036bb31","fromNode":"c02fca4457eea4a1","fromSide":"right","toNode":"cffda0fb3a359471","toSide":"left"},
		{"id":"278f3a3acb12d62b","fromNode":"255c19cad945a18f","fromSide":"right","toNode":"021f1343bdb23d3b","toSide":"left"},
		{"id":"7f2fdc869e3dce1b","fromNode":"6b0a964076e74b05","fromSide":"top","toNode":"021f1343bdb23d3b","toSide":"left"},
		{"id":"cdd516ba97d63180","fromNode":"021f1343bdb23d3b","fromSide":"right","toNode":"65f8df716b94268d","toSide":"left"},
		{"id":"75ccea7ccbb2e7e1","fromNode":"65f8df716b94268d","fromSide":"left","toNode":"5d67baa15b95e53b","toSide":"right"},
		{"id":"cf53f5eca13c5835","fromNode":"021f1343bdb23d3b","fromSide":"bottom","toNode":"f259623a35cf9802","toSide":"top"},
		{"id":"2aad448af6f8ed06","fromNode":"65f8df716b94268d","fromSide":"bottom","toNode":"eee85e14dae1ee1c","toSide":"top"},
		{"id":"14bf0ca2f1dee88e","fromNode":"f259623a35cf9802","fromSide":"right","toNode":"eee85e14dae1ee1c","toSide":"left"},
		{"id":"e5d36d8e9b20c212","fromNode":"1fb92b9bd42e2c32","fromSide":"right","toNode":"771c1bd426fd8f47","toSide":"left"},
		{"id":"ac7202c097a7bc00","fromNode":"65f8df716b94268d","fromSide":"right","toNode":"13a15e4783d53ebf","toSide":"left"},
		{"id":"a52fbe4d44602ae4","fromNode":"65f8df716b94268d","fromSide":"right","toNode":"7bdf1dc58118080b","toSide":"left"},
		{"id":"f0341c042d48f111","fromNode":"cffda0fb3a359471","fromSide":"right","toNode":"2066cad210080a20","toSide":"left"},
		{"id":"16153c0aeafbc473","fromNode":"2066cad210080a20","fromSide":"right","toNode":"50134cc52be508aa","toSide":"left"}
	]
}
{
	"nodes":[
		{"id":"255c19cad945a18f","type":"text","text":"# Operazioni di Input/Output","x":-1300,"y":-26,"width":518,"height":61,"color":"3"},
		{"id":"651b3e34405ca302","type":"text","text":"# Memoria","x":-2184,"y":-26,"width":200,"height":61,"color":"3"},
		{"id":"69f392e5d5620920","type":"file","file":"Memoria/memory_hierarchy.png","x":-2639,"y":-640,"width":1110,"height":520},
		{"id":"2cbd9476c35281f6","type":"file","file":"Sicurezza e syscall/valid_address.png","x":-4424,"y":-1704,"width":388,"height":387},
		{"id":"b763de7850a80c53","type":"file","file":"Sicurezza e syscall/privilege.png","x":-5426,"y":-1244,"width":523,"height":387},
		{"id":"3b4c354f921c302c","type":"text","text":"# Protezione della Memoria\n\nPer proteggere la memoria, a ogni programma viene assegnato un range di indirizzi fisici.\n\nUscire dai limiiti significa generare un interrupt di tipo SIGSEGV (Segmentation Fault).","x":-4786,"y":-1244,"width":1111,"height":387,"color":"4"},
		{"id":"7f02462535d305da","type":"file","file":"Sicurezza e syscall/ItsATrap.png","x":-5760,"y":-797,"width":857,"height":387},
		{"id":"c5128c9a62b77d1c","type":"text","text":"# Istruzioni privilegiate (Kernel Mode)\n\nCi sono istruzioni che non possono essere lasciate all'utente. Esempi possono essere HLT (blocca il processore in attesa di un interrupt) o INT (genera un interrupt). In User Mode è impedito di accedere direttamente all'I/O o alla RAM, passare in Kernel Mode, ...\n\nC'è un singolo bit protetto nella CPU che dice se sta eseguendo un'operazione in modalità Kernel (0) o User (1).\n\nL'HW deve pertanto supportare almeno queste due modalità, ma sono implementabili gerarchie di privilegi più fini.\n\nQualsiasi tipo di evento che fa passare la CPU in Kernel Mode è detto TRAP.","x":-4786,"y":-797,"width":1111,"height":387,"color":"4"},
		{"id":"9aa74fda3231a196","type":"text","text":"# Quindi è impossibile eseguire da utente le istruzioni privilegiate?\n\nNo, non è impossibile. Basta chiederlo gentilmente tramite le SYSTEM CALL, e il SO valuterà se è il caso di eseguirle o meno.","x":-4786,"y":-349,"width":1111,"height":105,"color":"4"},
		{"id":"013481a47473bf04","type":"file","file":"Sicurezza e syscall/syscall.png","x":-4786,"y":-204,"width":1111,"height":523},
		{"id":"558ba900733523b5","type":"text","text":"# SYSCALL\n\nSono il \"cuscinetto\" tra User e Kernel Mode. \n\nTipicamente scritte in C/C++ e fornite da librerie API scritte direttamente dagli sviluppatori del SO. Questo significa che in realtà User chiama una funzione WRAPPER con dentro, ad esempio, la *read()*, e i dettagli implementativi sono nascosti dalla API. Quando viene chiamata la vera syscall (INT $0x80 è la chiamata alle syscall in Assembly)e la palla passa al Kernel, questo salva in registri deditati lo stato della User Mode e usa una sua funzione sys_*read*() che esegue le vere operazioni.\n\nAl termine della syscall, usa una versione privilegiata della ret (IRET) per tornare alla User Mode.\n\nSi possono passare i parametri tramite registri, tabelle o direttamente pushando in stack.","x":-4786,"y":376,"width":1111,"height":323,"color":"4"},
		{"id":"307924e88efadd9d","type":"text","text":"# Ci sono diverse categorie di syscall...\n\nFile Management\n• Include create file, delete file, open, close, read, write, reposition, get file attributes, and set file attributes\n• These operations may also be supported for directories as well as ordinary files\n• The actual directory structure may be implemented using ordinary files on the file system, or through other means\n\nProcess Control\n• Include end, abort, load, execute, create process, terminate process, get/set process attributes, wait for time or event, signal event, and allocate and free memory\n• When one process pauses or stops, then another must be launched or resumed\n• When processes stop abnormally it may be necessary to provide core dumps and/or other diagnostic or recovery tools\n\nDevice Management\n• Include request device, release device, read, write, reposition, get/set device attributes, and logically attach or detach devices\n• Devices may be physical (e.g., disk drives), or virtual/abstract (e.g., files, partitions, and RAM disks)\n• Some systems represent devices as special files in the file system, so that accessing the \"file\" calls upon the appropriate OS device driver (e.g., the /dev directory on any UNIX system)\n\nInformation Maintenance\n• Include calls to get/set the time, date, system data, and process, file, or device attributes\n• Systems may also provide the ability to dump memory at any time\n• Single step programs pausing execution after each instruction, and tracing the operation of programs (debugging\n\nCommunication\n• Include create/delete communication connection, send/receive messages, transfer status information, and attach/detach remote devices\n• 2 models of communication:\n\nMessage passing\nShared memory","x":-5760,"y":-349,"width":857,"height":1048,"color":"1"},
		{"id":"99c05cd2bb5fb531","type":"file","file":"Sicurezza e syscall/syscall_categories.png","x":-6540,"y":-349,"width":698,"height":1048},
		{"id":"06528774c7a17e8f","type":"text","text":"# Sicurezza","x":-3360,"y":-26,"width":250,"height":61,"color":"6"},
		{"id":"fccd506f086b692b","type":"file","file":"Sicurezza e syscall/syscall_waiting.png","x":-5711,"y":928,"width":760,"height":387},
		{"id":"ebda4cf153d6ae26","type":"text","text":"## Mentre eseguo una syscall?\n\nPosso scegliere di aspettare (sincrono col processo) o fare altro nel frattempo (asincrono).","x":-5711,"y":805,"width":760,"height":100},
		{"id":"d944c099d4a52726","type":"file","file":"memoria.txt","x":-2639,"y":-1300,"width":1111,"height":540,"color":"4"},
		{"id":"16683038ca807a6e","type":"text","text":"# Sistema Operativo","x":-2248,"y":924,"width":329,"height":74,"color":"5"},
		{"id":"1829ebdad1c10164","type":"text","text":"# Verso l'Hardware","x":-2248,"y":799,"width":329,"height":50,"color":"3"},
		{"id":"d28c649c75ac5104","type":"text","text":"# Verso il Software","x":-2248,"y":1072,"width":329,"height":50,"color":"6"},
		{"id":"69f3dd73ee95ff32","type":"text","text":"# Aggiunte a questo\n\nPage table uses a cache called Translation Look-aside Buffer (TLB) with \"recent mappings\" for quicker lookups.\n\nThe OS must be aware of which pages are loaded in main memory and which ones are on disk.","x":-1440,"y":-1226,"width":483,"height":392,"color":"2"},
		{"id":"50134cc52be508aa","type":"file","file":"OS_Design.pdf","x":852,"y":832,"width":420,"height":260,"color":"1"},
		{"id":"6bc46856fa34b1e2","type":"text","text":"# So what?\n\nMonolithic vs. Microkernel: Hybrid Trade-off\n• Try to get the best out of both approaches\n• combining multiple approaches to address performance, security, usability needs\n• Linux and Solaris: monolithic + LKMs (i.e., modular monolithic)\n• Windows NT: mostly monolithic + microkernel for different subsystems\n• Apple Mac OS X: monolithic (BSD UNIX) + microkernel (Mach) + LKMs","x":1480,"y":738,"width":1111,"height":448,"color":"1"},
		{"id":"cffda0fb3a359471","type":"text","text":"# Implementazione generale\n\nDecoupling policy (*what* will be done) logic from the underlying mechanism (*how* to do it) is a general design principle in computer science, as it improves system's\n\t• flexibility: addition and modification of policies can be easily supported\n\t• reusability: existing mechanisms can be reused for implementing new policies\n\t• stability: adding a new policy doesn't necessarily destabilize the system\nPolicy changes can be easily adjusted without re-writing the code.\n\nEarly OSs developed in assembly language,\n\t• PRO - direct control over the HW (high efficiency)\n\t• CON - bound to a specific HW (low portability)\nToday, a mixture of languages:\n\t• Lowest levels in assembly\n\t• Main body in C\n\t• Systems programs in C, C++, scripting languages like PERL, Python, etc.","x":-480,"y":738,"width":1111,"height":448,"color":"1"},
		{"id":"65f8df716b94268d","type":"text","text":"# Come dialogo con un dispositivo I/O?\n\nOgni device I/O consta di due parti:\n\t- Il device stesso\n\t• the device controller (chip or set of chips controlling a family of physical devices)\n\nOS talks to a device controller using a specific device driver\n\n• Every device controller has a number of dedicated registers to communicate with it:\n\t• Status registers: provide status information to the CPU about the I/O device (e.g., idle, ready for input, busy, error, transaction complete)\n\t• Configuration/Control registers: used by the CPU to configure and control the device\n\t• Data registers: used to read data from or send data to the I/O device\n\n\n","x":-480,"y":-412,"width":1111,"height":387,"color":"2"},
		{"id":"f259623a35cf9802","type":"text","text":"# How does the CPU know how to address (registers of) I/O devices?\n\nPort-Mapped I/O\n• Each I/O device controller's register is mapped to a specific port\n(address)\n• Requires special class of CPU instructions (e.g., IN/OUT)\n• The IN instruction reads from an I/O device, OUT writes\n• When you use the IN or OUT instructions, the M/#IO is not asserted,\nso memory does not respond and the I/O chip does\n\nMemory-Mapped I/O\n• Memory-mapped I/O \"wastes\" some address space but doesn’t need any special instruction\n• To the CPU I/O device ports are just like normal memory addresses\n• The CPU use MOV-like instructions to access I/O device registers\n• In this way, the M/#IO is asserted indicating the address requested by the CPU refers to main memory","x":-480,"y":36,"width":1111,"height":448,"color":"1"},
		{"id":"76425af58183667e","type":"file","file":"Input-Output/DMA.png","x":700,"y":-1399,"width":724,"height":724},
		{"id":"667a17b2a2c4afbc","type":"text","text":"## Ogni trasferimento dati deve passare per la CPU?\n\nNo. Se bisogna scambiare dati tra memoria e I/O la CPU delega il lavoro al Controller DMA (Direct Memory Access). Al massimo si limita a fare POLLING, cioè a chiedere ogni tot al processo se ha finito.","x":700,"y":-639,"width":724,"height":185,"color":"4"},
		{"id":"13a15e4783d53ebf","type":"file","file":"Input-Output/DMA_scheme.png","x":1480,"y":-1399,"width":543,"height":371},
		{"id":"7bdf1dc58118080b","type":"file","file":"Input-Output/IO_CPU_POV.png","x":1480,"y":-992,"width":543,"height":538},
		{"id":"582cbf0b2f379d20","type":"file","file":"Input-Output/port_mapping_easy.png","x":2100,"y":-412,"width":895,"height":895},
		{"id":"771c1bd426fd8f47","type":"text","text":"## Quindi la differenza è...\n\nChe se in assembly {ATTENZIONE SINTASSI INTEL} scrivo \n\nMOV DX, 1234h\nMOV AL, \\[DX\\]\n\nsto leggendo il contenuto dell'indirizzo di memoria 0x1234 che mi porta poi alla periferica (devo usare il canale M/#IO del Control Bus), mentre invece se scrivo\n\nIN AL, DX\n\nmi interfaccio direttamente col chip di I/O corrispondente su di un I/O Address Space.\n\nNotare che entrambi gli approcci scrivono 0x1234 sull'Address Bus e invocano la READ sul Control Bus.\n\n","x":3060,"y":-412,"width":560,"height":895,"color":"4"},
		{"id":"24babc6f213a28a7","type":"file","file":"Input-Output/memory_port_mapping.png","x":1480,"y":-412,"width":543,"height":895},
		{"id":"1fb92b9bd42e2c32","type":"file","file":"Input-Output/addressing_IO.png","x":700,"y":69,"width":723,"height":382},
		{"id":"5d67baa15b95e53b","type":"file","file":"Input-Output/controller_driver.png","x":700,"y":-412,"width":724,"height":387},
		{"id":"ccea465ee5a66f66","type":"text","text":"# Processi","x":-2248,"y":1510,"width":329,"height":50,"color":"6"},
		{"id":"409f9cd96c788b91","type":"file","file":"processi.txt","x":-2283,"y":1620,"width":400,"height":180,"color":"4"},
		{"id":"e864bef1d25309b9","type":"text","text":"# Aggiunte\n## Stack Pointer\nOltre allo Stack Pointer esp si definisce uno Stack Base Pointer che punta alla base dello Stack Frame del chiamante.\nQuando chiamo una funzione posso pushare il vecchio valore di ebp e usare quello al posto di esp, mentre esp \"scende\" insieme alle variabili locali.\n\n## Process Execution State\nAt each time a process can be in one of the following 5 states:\n\t- New: The OS has set up the process state;\n\t- Ready: The process is ready to be executed yet waiting to be scheduled on to the CPU\n\t- Running: The process is actually executing instructions on the CPU\n\t- Waiting: The process is suspended waiting for a resource to be available or an event to complete/occur (e.g., keyboard input, disk access, timer, etc.);\n\t- Terminated: The process is finished and the OS can destroy it","x":-2638,"y":1840,"width":1111,"height":460,"color":"2"},
		{"id":"4f7a30ec90f5f7a1","type":"text","text":"# Sincronizzazione dei processi e \"democrazia\"\n\nC'è un timer (che non è il clock delle operazioni di base della CPU!) che ogni tot tempo manda degli interrupt alla CPU, il cui Scheduler decide qual è il prossimo processo da eseguire.\n\nIl SO deve essere in grado di coordinare le attività in modo da ottimizzare il lavoro dello Scheduler della CPU.\n\nHardware must ensure that short sequences of instructions (e.g., read- modify-write) are executed atomically by either:\n\t• Disabling interrupts before the sequence and re-enable them afterwards;\n\t• Special instructions that are natively executed atomically.\nQuesto perché sarebbe davvero spiacevole interrompere un'operazione di scrittura prima che abbia finito, lasciando la memoria in uno stato inconsistente.\n\n• Most system calls (e.g., I/O ones) are blocking\n• the caller process (user space) can't do anything until the system call returns\n• the OS (kernel space):\n\t• sets the current process to a waiting state (i.e., waiting for the system call to return)\n\t• schedules a different ready process to avoid the CPU being idle\n• once the system call returns the previously blocked process is ready to be scheduled for execution again\n• NOTE: the whole system is not blocked, only the process which has requested the blocked call is!","x":-4786,"y":805,"width":1111,"height":510,"color":"2"},
		{"id":"efa5f9c31e4d06bc","type":"file","file":"Processi/process_state.png","x":-3580,"y":1900,"width":840,"height":340},
		{"id":"0f5be1b419c22070","type":"file","file":"SO.txt","x":-3435,"y":280,"width":400,"height":400,"color":"4"},
		{"id":"f104b3656720780b","type":"text","text":"# Sincronizzazione","x":-3404,"y":931,"width":339,"height":60,"color":"6"},
		{"id":"66b9c1070bde7f69","type":"file","file":"processiIII.txt","x":-6540,"y":805,"width":698,"height":510,"color":"4"},
		{"id":"50883272249f2785","type":"text","text":"# Creazione Processi\n\nAggiunte: Windows ha una syscall, spawn() che unisce le syscall fork() e exec() di Unix.\n\nPer specificare quale figlio aspettare c'è la syscall waitpid(pid_t pid, int \\*status, int options).\n\n\n\n","x":-3160,"y":1440,"width":420,"height":400,"color":"4"},
		{"id":"077958ec99cf0920","type":"text","text":"# Process Scheduling\n2 main goals of the process scheduling system:\n\t• keep the CPU busy at all times\n\t• deliver \"acceptable\" response times for all programs, particularly for interactive ones\nThe process scheduler must meet these objectives by implementing suitable policies for swapping processes in and out of the CPU.\nNote that these objectives can be conflicting!\n\t• Every time the OS steps in to swap processes it takes up time on the CPU to do so, which is thereby \"lost\" from doing any useful productive work.\n## Process State Queues\nThe OS mantains the PCBs of all the processes in state queues\n\t• There is one queue for each of the 5 states a process can be in\n\t• There is typically one queue for each I/O device (where processes wait for a device to become available or to deliver data)\n\t• When the OS change the status of a process (e.g., from ready to running) the PCB is unlinked from the current queue and moved to the\n\tnew one\n\t• The OS may use different policies to manage each state queue\nHow many PCBs can be in the Running Queue?\n\t• The Running Queue is bound by the number of cores available on the system\n\t• At each time, only one process can be executed on a CPU\nWhat about the other queues?\n\t• They are basically unbounded as there is no theoretical limit on the number processes in new/ready/waiting/terminated states","x":-4786,"y":1440,"width":1111,"height":600,"color":"1"},
		{"id":"a1adbe9bb664a9c2","type":"file","file":"processiV.txt","x":-3580,"y":1440,"width":400,"height":400,"color":"4"},
		{"id":"2bd5a1b48bac530b","type":"file","file":"Sicurezza e syscall/syscall_communication_modes.png","x":-7225,"y":455,"width":583,"height":859},
		{"id":"3cbd143423e3f10a","type":"text","text":"# Comunicazione\n\nProcesses can be either independent or cooperating\n• Independent processes - operate concurrently on a system and can neither affect or be affected by other processes;\n• Cooperating processes - can affect or be affected by other processes in order to achieve a common task.\n\nPerché?\n\n• Information sharing - There may be several processes which need access to the same file (e.g., pipelines)\n• Computation speedup - A problem can be solved faster if it can be broken down into sub-tasks to be solved simultaneously\n• Modularity - The most efficient architecture may be to break a system down into cooperating modules\n• Convenience - Even a single user may be multi-tasking, such as editing,\ncompiling, printing, and running the same code in different windows\n\nCome?\n\n","x":-8020,"y":455,"width":698,"height":545,"color":"2"},
		{"id":"e2aefc482d1e7497","type":"text","text":"### Message Passing\n• Slower as it requires system calls for every message transfer\n• Simpler to set up and works well across multiple computers\n• Preferable when the amount and/or frequency of data transfers is small, or when multiple computers are involved\n• Must support at least system calls for sending and receiving messages\n• A communication link must be established between the cooperating processes before messages can be sent.\n#### Communication (i.e., naming)\nSi può comunicare in due modi:\n\t- Comunicazione diretta: il mittente deve sapere il nome del ricevitore. Per una comunicazione simmetrice, deve essere vero anche il contrario. A ogni coppia mittente-ricevitore corrisponde un link;\n\t-  Comunicazione indiretta: usa porte o mailbox condivise. Più processi possono condividere le stesse porte. Il SO deve fornire syscall per creare ed eliminare le mailbox, così come per inviare e ricevere messaggi da esse.\n\n#### Sincronizzazione e Buffering\nSi possono presentare diverse situazioni.\n\t- Zero Capacity: Non esiste una coda di messaggi, i mittenti devono aspettare che il destinatario accetti il messaggio precedente;\n\t- Bounded Capacity: La coda ha una capienza finita, i mittenti si fermano solo se la coda è piena;\n\t- Unbounded Capacity: La coda ha una capienza virtualmente infinita, i mittenti non vanno mai in blocco forzato.","x":-8020,"y":-349,"width":698,"height":749,"color":"2"},
		{"id":"a2ca84c1f075532c","type":"file","file":"Sicurezza e syscall/syscall_esempi.png","x":-7225,"y":-291,"width":583,"height":633},
		{"id":"97b3e71503c3e19d","type":"text","text":"Possono esserci Scheduler long-term (gira poco frequentemente, tipico dei Batch Systems, definisce il livello di multiprogramming, ovvero quanti processi vengono caricati in RAM), short-term (che è quello della CPU, gira con una frequenza dell'ordine dei 100 millsecondi, regola come scegliere il prossimo processo dalla ready queue) e medium-term (quando c'è tanto carico di lavoro, fanno passare avanti i processi che ci mettono poco, tipo in fila al supermercato). In effetti gli scheduler possono essere visualizzati con un supermercato. Short term indirizza le persone alle casse, medium-term fa saltare la fila a quello che ha solo un paio di cose e long term gestisce il flusso di persone nella struttura (calzante in tempi covid). Chiaro che il più importante è il primo. Un buon sistema di scheduling occupa in modo bilanciato CPU e I/O.","x":-4786,"y":2100,"width":1111,"height":200,"color":"4"},
		{"id":"890280218841edc0","type":"text","text":"### Quando si attiva lo Scheduler CPU?\nQuando un processo\n\t- Passa da RUNNING a WAITING --> Richiesta di I/O o syscall wait();\n\t- Passa da RUNNING a READY --> Interrupt;\n\t- Passa da WAITING a READY --> Ritorno da I/O o da syscall wait();\n\t- Viene creato (NEW) o termina (TERMINATED).","x":-5480,"y":2340,"width":578,"height":280,"color":"4"},
		{"id":"0d183aee8445a447","type":"text","text":"Nei primo e nell'ultimo caso (non-preemptive scheduling) è necessario selezionare un altro processo, mentre nei due intermedi (preemptive scheduling) può continuare quello corrente","x":-5759,"y":2340,"width":250,"height":280,"color":"4"},
		{"id":"6f102d8a296c67cf","type":"text","text":"# CPU Scheduler (Short-Term)","x":-4471,"y":2455,"width":482,"height":50,"color":"6"},
		{"id":"7c61dcb5932faf1f","type":"text","text":"### Non-preemptive Scheduling (più \"statico\")\n\n1. **Caratteristiche Principali:**\n\t-  I processi non vengono interrotti durante il loro tempo di CPU burst.\n\t- Un processo mantiene la CPU fino a quando non completa il suo burst o si sospende volontariamente (ad esempio, per attendere l'I/O).\n2. **Esempio:**\n        - Un algoritmo di ordinamento senza prelazione potrebbe essere il First-Come-First-Served (FCFS) o Shortest Job Next (SJN), dove il processo in esecuzione continua finché non completa la sua esecuzione o decide di attendere volontariamente.\n3. **Vantaggi:**\n    - Semplice da implementare e comprendere.\n    - Minimizza il tempo di attesa medio per i processi brevi.\n4. **Svantaggi:**\n\tPuò portare al problema del \"convoy effect\", dove un processo lungo ritarda l'esecuzione di processi più brevi che lo seguono nella coda.\n\n### Preemptive Scheduling (più \"dinamico\")\n\n1. **Caratteristiche Principali:**\n    - Un processo può essere interrotto durante il suo CPU burst.\n    - La CPU può essere assegnata a un nuovo processo prima che il processo attuale abbia completato il suo burst.\n2. **Esempio:**\n    - Un algoritmo di ordinamento con prelazione potrebbe essere il Round Robin (RR) o l'algoritmo di prioritizzazione in cui un processo può essere interrotto dopo un certo quantum di tempo o se un processo con una priorità più alta diventa disponibile.\n3. **Vantaggi:**\n    - Riduce il tempo di risposta medio e migliora la reattività del sistema.\n    - Può evitare il \"convoy effect\" poiché processi più brevi possono essere eseguiti prima.\n4. **Svantaggi:**\n    - Complessità aggiuntiva nell'implementazione dell'ordinamento con prelazione.\n    - Potenzialmente può portare a un aumento del tempo di attesa per i processi brevi in determinate circostanze.\n\nLa scelta tra ordinamento con e senza prelazione dipende dalle esigenze specifiche del sistema e dagli obiettivi di ottimizzazione. Algoritmi di ordinamento con prelazione sono spesso preferiti in sistemi in cui la reattività e il tempo di risposta sono critici. Al contrario, algoritmi senza prelazione possono essere più appropriati in situazioni in cui la semplicità e la minimizzazione del tempo di attesa medio sono più importanti.","x":-6540,"y":1440,"width":698,"height":1180,"color":"2"},
		{"id":"9ed99aa483da3638","type":"text","text":"# Batch Systems (per cultura)\n\nI \"batch systems\" si riferiscono a sistemi operativi o ambienti informatici in cui le attività vengono eseguite in lotti (batch), senza interazione immediata con l'utente. In un sistema batch, gli utenti preparano un insieme di comandi o job in anticipo e li presentano al sistema operativo per l'esecuzione. Il sistema operativo quindi esegue i job uno dopo l'altro senza richiedere un'interazione diretta con l'utente durante l'esecuzione di ciascun job.\n\nCaratteristiche principali dei batch systems:\n\n1. **Pianificazione e Esecuzione Automatica:** Gli utenti preparano uno o più job insieme a tutti i dati necessari e li inviano al sistema operativo per esecuzione. Il sistema operativo pianifica l'esecuzione dei job in base a determinati criteri.\n    \n2. **Assenza di Interazione Utente:** Durante l'esecuzione dei job, non è richiesta l'interazione diretta dell'utente. Il sistema operativo esegue i job in modo sequenziale senza richiedere input dall'utente tra un job e l'altro.\n    \n3. **Ottimizzazione delle Risorse:** I batch systems sono progettati per ottimizzare l'utilizzo delle risorse del sistema. Possono eseguire automaticamente una sequenza di job senza la necessità di costante monitoraggio umano.\n    \n4. **Elaborazione in Lotti:** Le attività vengono elaborate in lotti piuttosto che in modo interattivo. Questo è particolarmente utile per attività ripetitive o computazioni intensive che richiedono un tempo significativo.\n    \n5. **Output Salvato:** I risultati o l'output dei job possono essere salvati su file o stampati per consentire agli utenti di esaminare i risultati in un secondo momento.\n    \n6. **Storico e Monitoraggio:** I sistemi batch spesso mantengono un registro delle attività eseguite e forniscono strumenti di monitoraggio per verificare lo stato dei job in esecuzione o completati.\n    \n\nQuesti sistemi batch erano particolarmente comuni nei primi giorni dell'informatica e sono ancora utilizzati in alcune applicazioni specifiche oggi, specialmente in contesti di elaborazione di grandi volumi di dati o di esecuzione di processi automatizzati.\n\nEcco alcuni esempi pratici di situazioni in cui i sistemi batch potrebbero essere utilizzati:\n\n1. **Elaborazione Notturna delle Transazioni Bancarie:**\n    \n    - Un istituto finanziario può eseguire un sistema batch durante la notte per elaborare tutte le transazioni finanziarie effettuate durante la giornata. Ciò include l'aggiornamento dei saldi dei conti, la generazione di estratti conto e altre operazioni di elaborazione dati.\n2. **Compilazione di Programmi Software:**\n    \n    - In un ambiente di sviluppo del software, la compilazione di programmi complessi può richiedere tempo. I sistemi batch possono essere utilizzati per automatizzare il processo di compilazione di grandi progetti software durante le ore non lavorative.\n3. **Calcolo Scientifico Intensivo:**\n    \n    - In ambiti scientifici, come la simulazione di modelli complessi o il rendering grafico, i sistemi batch possono essere utilizzati per gestire l'esecuzione di calcoli intensivi durante periodi di inattività del sistema.\n4. **Produzione di Rapporti Periodici:**\n    \n    - Un'azienda può generare rapporti periodici, come rapporti finanziari mensili, mediante un sistema batch che elabora i dati accumulati durante il mese e produce i rapporti senza richiedere l'intervento dell'utente.\n5. **Elaborazione di Grandi Batch di Dati:**\n    \n    - In applicazioni di analisi dei dati, come la creazione di modelli statistici su grandi insiemi di dati, i sistemi batch possono essere utilizzati per eseguire analisi complesse senza interrompere l'interazione dell'utente.\n6. **Stampa di Documenti in Massa:**\n    \n    - In ambienti in cui è necessario stampare grandi volumi di documenti, come fatture o estratti conto, i sistemi batch possono gestire la coda di stampa in modo che la stampa avvenga in modo automatico senza richiedere l'intervento costante dell'utente.\n\nIn questi esempi, l'uso di sistemi batch consente di automatizzare processi ripetitivi, di ottimizzare l'utilizzo delle risorse e di pianificare l'esecuzione delle attività quando il sistema è meno sollecitato.","x":-5759,"y":1440,"width":857,"height":420},
		{"id":"8fac94dbd27f5a21","type":"text","text":"# Context Switch\n\nOvvero, sospendere un processo running per eseguirne uno ready. Molto costoso, devo salvare tutto nel PCB per quando dovrò riprenderlo. Succede ogni qualvolta arriva un segnale di trap, e la CPU deve passare in Kernel Mode per gestire l'interrupt. Esempi sono interazioni I/O sui processi attivi o la \"fairness\", ovvero il timer (il \"time slice\" è il massimo tempo tra due Context Switch, usato per implementare lo pseudo-parallelismo dei processi sul singolo core, detta \"responsiveness\"). Il trade-off è quindi tra\n\n- Massimizzare la responsiveness diminuendo il time slice;\n- Minimizzare il tempo perso nel fare Switch aumentando il time slice.\n\nUn time slice dura tipicamente 10-100 millisecondi, contro i 10 microsecondi di uno Switch.","x":-5759,"y":1900,"width":857,"height":400,"color":"4"},
		{"id":"da8d7ccc61fb288f","type":"text","text":"# Useful Definitions\n• Arrival Time: time at which the process arrives in the ready queue\n• Completion Time: time at which the process completes its execution\n• Burst Time: time required by a process for CPU execution\n• Turnaround Time: time difference between completion and arrival time\n• Waiting Time: time difference between turnaround time and burst time","x":-3580,"y":2340,"width":840,"height":280,"color":"1"},
		{"id":"4fe1989d7b05db02","type":"text","text":"# Dispatcher\n\nOgni volta che si ha un Context Switch si attiva il modulo Dispatcher, che passa il controllo della CPU al processo selezionato dallo scheduler. Il suo tempo di esecuzione (dispatch latency) deve quindi essere particolarmente basso. Its functions include:\n\n• Switching context (salva vecchio PCB, carica il nuovo)\n• Switching to user mode\n• Jumping to the proper location in the newly loaded program\n\nInoltre, monitora il tempo di uso della CPU, e può prendere decisioni da preemptive scheduler interrompendo il burst CPU prima del timer. In un sistema multi-core, è suo compito la coordinazione tra di essi.\n","x":-5759,"y":2680,"width":839,"height":400,"color":"2"},
		{"id":"127fb02c474f9e0c","type":"text","text":"# Scheduling Criteria\n\n- Utilizzo CPU (frazione di tempo in cui la CPU è occupata): da massimizzare. In sistemi reali dovrebbe essere nel range (0.4, 0.9);\n- Throughput (processi completati per unità di tempo): da massimizzare. Può variare tra 10/sec e 1/ora;\n- Tournaround time (tempo \"di orologio\" di completamento di un processo, dallo stato NEW a TERMINATED): da minimizzare;\n- Waiting time (tempo speso dal processo nella ready queue): da minimizzare. Notare che i processi waiting non possono essere gestiti dallo scheduler, sono solo \"ready to run\";\n- Response time (una sorta di input delay, tempo che intercorre tra il comando e l'inizio della sua esecuzione): da minimizzare.\n\nSi può intuire che è impossibile ottimizzarle tutte insieme, quindi si fa trade-off. Il criterio è scrivere lo scheduler basandosi su una certa policy, ovvero scegliendo cosa sacrificare.\n\n- Per Sistemi Interattivi si ottimizza il tempo di risposta;\n-  Per Sistemi Batch si massimizza il throughput (minimizzando l'Overhead, ovvero lo switch User-Kernel mode) e si minimizza il Waiting time, tipicamente minimizzando gli interrupt durante i burst CPU, andando eventualmente a penalizzare il tempo di risposta.","x":-4786,"y":2680,"width":1111,"height":400,"color":"4"},
		{"id":"1c983ed53f331726","type":"text","text":"### Shared Memory\n• Faster once it is set up, as no system calls are needed\n• More complicated to set up, and doesn't work as well across multiple computers\n• Preferable when (large amount of) information must be shared on the same computer","x":-8020,"y":1060,"width":698,"height":254,"color":"1"},
		{"id":"a468bd8ba770bd4b","type":"text","text":"# First-Come-First-Serve (FCFS)\n\nNon-preemptive. Pila FIFO (i.e. fila al post office). I processi sono eseguiti in ordine di arrivo nella ready queue. The scheduler takes over only when the currently running job asks for an I/O operation (or finishes its execution). A job may keep using the CPU indefinitely (i.e., until it blocks).\n\nPro: Semplice.\nContro:\n- Il tempo di attesa è molto variabile (un processo breve può restare bloccato dietro processi lunghi);\n- Convoy Effect: Se cambio processo da A a B per fare un breve I/O, questo potrebbe restare bloccato a tempo indeterminato in attesa che finisca B --> Poca ottimizzazione sul fronte I/O.","x":-7225,"y":1440,"width":583,"height":500,"color":"2"},
		{"id":"e286057ad92c4f0c","type":"text","text":"# Round Robin (RR)\nPreemptive. Come FCFS, due differenze:\n\n- A ogni burst CPU corrisponde un time slice. Quando parte la CPU, parte il timer.\n\t• Se il job finisce prima del timer si ricade nell'algoritmo FCFS. Chiaro che se metto un time slice enorme tendo a ricadere in FCFS;\n\t• Altrimenti, il job viene tolto dalla CPU e messo in fondo alla coda ready.\n\n- La coda è gestita in modo circolare. Il processo successivo è sempre quello in cima alla pila, e dopo essere stato tolto dallo stato di RUN finisce in fondo alla pila. Evito il Convoy Effect.\n\nSegue che l'average waiting time può essere lungo (i processi brevi non hanno alcuna priorità perché nessun processo ha priorità). Il trade-off tra ricadere in FCFS e i troppi context switch (che abbassano il throughput) è avere un time slice circa 3 ordini di grandezza più piccolo (i.e. context switch dura 0.1ms, time slice di 100ms). Le effettive differenze sulle metriche rispetto a FCFS possono variare a seconda di fattori come \\#jobs, durata di ogni job, time slice, arrival time, numero di context switch, ...","x":-8020,"y":1440,"width":698,"height":500,"color":"4"},
		{"id":"66990f7c63e2d405","type":"text","text":"# Scheduling Algorithms","x":-7877,"y":1999,"width":412,"height":62,"color":"4"},
		{"id":"4ff852d5afad6346","type":"text","text":"# Shortest Job First (SJF)\n\nSchedule the job that has the least expected amount of work to do until its next I/O operation or termination.\n\nPro:\n• Optimal when the goal is to minimize the avg. waiting time\n• Works both with preemptive and non-preemptive schedulers (preemptive SJF is called SRTF or Shortest Remaining Time First, nel secondo caso lo scheduler si attiva quando arriva un nuovo processo nella coda ready e la sua durata di burst prevista è minore del processo in esecuzione).\n\nContro:\n• Almost impossible to predict the amount of CPU time of a job\n• Long running CPU-bound jobs can starve (as I/O-bound ones have implicitly higher priority over them)","x":-8680,"y":1440,"width":559,"height":500,"color":"2"},
		{"id":"6c0f163753eb8b85","type":"text","text":"# Preemption: Issues\n\nPreemption might cause troubles if it occurs while\n\n• the kernel is busy implementing a system call (e.g., updating critical kernel data structures);\n• two processes share data, one may get interrupted in the middle of updating shared data structures.\n\nPossible countermeasures:\n\n• Make the process wait until the system call has either completed or blocked before allowing the preemption --> problematic for real-time systems, as real-time response can no longer be guaranteed\n• Disable interrupts before entering critical code section and re-enabling immediately afterwards --> should only be done in rare situations, and only on very short pieces of code that will finish quickly","x":-6540,"y":2680,"width":698,"height":400,"color":"1"},
		{"id":"7c939ee2ebe1207c","type":"file","file":"Processi/ICP.png","x":-8650,"y":454,"width":499,"height":860},
		{"id":"ba2b6213e4637219","type":"text","text":"Molte dei processi di scheduling presentati sotto sono basati sull'assunzione che NON avvenga comunicazione tra processi.","x":-8650,"y":-24,"width":499,"height":100,"color":"4"},
		{"id":"2a9d90b8cc31da54","type":"text","text":"# Priority Scheduling\nUn SJF più generale. A ogni job assegno una priorità ed lo scheduler manda alla CPU quello con priorità maggiore.\nUsually, low numbers for high priorities (0 = the highest possible priority). La priorità può essere assegnata\n- Dal SO con i suoi criteri (Internal Priority);\n- Dall'utente (External Priority).\n\nPuò essere sia preemptive che non. Problemi associati sono:\n- Indefinite blocking (starvation): low-priority task can wait forever because some other jobs have always higher priority. Una soluzione è l'Aging, ovvero aumentare la priorità proporzionalmente al tempo di attesa;\n- Stuck jobs may eventually run when the system load is lighter or after a shutdown/crash and a reboot.","x":-8680,"y":2120,"width":559,"height":500,"color":"2"},
		{"id":"005e7e1e1c753ec3","type":"text","text":"# Multi-Level Queue (MLQ)\n\nUse multiple separate queues, one for each job category. Scheduling must be done between queues. Each queue implements whatever scheduling algorithm is most appropriate for that type of jobs.\n\nTwo common options are:\n- Strict Priority --> no job in a lower priority queue runs until all higher priority queues are empty;\n- Round-Robin --> each queue gets a time slice in turn, possibly of different sizes.\n\nNote: Jobs cannot switch from queue to queue (non cambiano categoria in corso d'opera o per effetto dello scheduling)","x":-7225,"y":2120,"width":583,"height":500,"color":"1"},
		{"id":"b73522939cb2e340","type":"file","file":"MLQ.png","x":-7225,"y":2770,"width":583,"height":220},
		{"id":"30f61bfe887b9609","type":"text","text":"# Multilevel Feedback-Queue (MLFQ)\n\nCome MLQ, ma è possibile cambiare categoria ai processi. Può servire se:\n- The characteristics of a job change between CPU-intensive and I/O-intensive.\n- A job that has waited for a long time can get bumped up into a higher priority queue for a while (to compensate the aging problem).\n\nMetodo:\n- Job starts in the highest priority queue (by default);\n-  If job's timer expires --> drop its priority level by one unit;\n-  If job's timer does not expire (i.e., context switch occurs due to I/O request) --> increase its priority level by one unit;\n- CPU-bound jobs will quickly drop priority, I/O-bound jobs will stay high priority.\n\nMost flexible, but also most complex to implement. Serve definire parametri come numero di code, algoritmo di scheduling di ogni coda, criteri di upgrade o downgrade tra le code, criterio di assegnazione iniziale di un processo a una coda, ...","x":-8020,"y":2120,"width":698,"height":500,"color":"2"},
		{"id":"97288d1ddddfffed","type":"text","text":"# Fairness Issue\n\nAlgoritmi come SJF e MLFQ (che promuovendo esplicitamente i job con tempo di esecuzione previsto più breve imita il best-behaviour di SJF) sono UNFAIR, ovvero permette situazioni in cui alcuni processi a bassa priorità hanno un waiting time altissimo. Non sempre aumentare i burst CPU per questi processi risolve il problema, perché rischia di aumentare l'average waiting time dell'intero sistema.\nUna soluzione può essere l'aumento dinamico della priorità proporzionalmente al waiting time del processo, ma in condizioni di overloading del sitema questo porta a un appiattimento dell'algoritmo (tutti i processi finiscono ad avere massima priorità).","x":-8020,"y":2680,"width":698,"height":400,"color":"4"},
		{"id":"ee4978ec280e0156","type":"text","text":"# Lottery Scheduling\n\nAlgoritmo non-deterministico che assegna dei \"biglietti della lotteria\" ai processi per poi estrarre un \"vincitore\" a ogni scadenza del timer. Più biglietti ai processi brevi, meno ai processi lunghi (una sorta di simulazione di SJF). A ogni processo viene dato almeno un biglietto (virtualmente per evitare la starvation).","x":-9380,"y":1900,"width":559,"height":250,"color":"4"},
		{"id":"c948ce6320acafbe","type":"file","file":"LotterySimplified.png","x":-9380,"y":2254,"width":559,"height":233},
		{"id":"113ca9ce4e51d6e6","type":"text","text":"# Threads\n\nSono un modo più semplice e veloce di eseguire le operazioni di un programma. Questo infatti può essere visto, più che come una sequenza lineare di istruzioni, come un insieme di moduli in esecuzione parallela che cooperano. Ad esempio, il programma editor di testo ha un thread che attende l'input, uno che controlla la grammatica, uno che gestisce la GUI, ... Tutto questo senza problemi come dover creare nuovi processi figli, attenderne la risoluzione, comunicare dati tra processi con schemi di memoria condivisa o con syscall per messaggi, ... La comunicazione tra thread è molto più veloce, così come la creazione e il context switch.\n\nUn Thread è definito come unità base di utilizzo CPU, ovvero un Program Counter, una Stack e un set di registri generici (oltre ovviamente all'ID del Thread). Ogni thread fa riferimento a un processo genitore, e ogni processo genitore condivide con ogni thread figlio codice, dati e zona di memoria. Se a ogni processo corrisponde un PCB, a ogni thread corrisponde un TCB. Più thread dello stesso processo possono andare in esecuzione parallela su diversi core. Questo richiede un ulteriore processo di scheduling da parte del SO.\n\nI thread si dividono in due macro-categorie:\n\n- Kernel thread, gestiti direttamente dal SO.\n\t- Pro: Kernel has full knowledge of all threads. Scheduler may decide to give more CPU time to a process having a large numer of threads. Good for applications that frequently block. Switching between threads is faster than switching between processes.\n\t- Contro: Significant overhead and increase in kernel complexity. Slow and inefficient (need kernel invocations). Context switching, although lighter, is managed by the kernel.\n\n- User thread, gestiti dall'utente con apposite librerie che sfruttano syscall fornite dal SO.\n\t- Pro: Really fast and lightweight. Scheduling policies are more flexible. Can be implemented in OSs that do not support threading. No system calls involved, just user-space function calls. No actual context switch.\n\t- Contro: Il SO non sa nulla dei thread in spazio utente, quindi li gestisce come programma concorrente.\n\nSi rende necessario quindi mappare i thread utente in thread kernel (spesso viene fatto da un'unità chiamata LWP, Lightweight Processor). Ci sono diversi modi di farlo.\n\n- Many-To-One: Più thread utente sono mappati in un singolo thread kernel. L'utente scrive un parallelismo che non verrà mai implementato;\n- One-To-One: N thread utente sono mappati in N thread kernel. La gestione del processo di mapping può rallentare il sistema, motivo per cui spesso c'è un limite al numero di thread creabili;\n- Many-To-Many: N thread utente sono mappati in M <= N thread kernel. Unisce i vantaggi dei metodi precedenti. Se possibile si mantiene il parallelismo dato da One-To-One, altrimenti più thread utente vengono mappati in un solo thread kernel. Presente anche in variante Two-Level, che esegue esplicitamente in parallelo il multiplexing di Many-To-Many e il collegamento diretto di One-To-One.","x":-1400,"y":1300,"width":880,"height":1000,"color":"4"},
		{"id":"c02fca4457eea4a1","type":"text","text":"# Design","x":-1045,"y":932,"width":250,"height":60,"color":"6"},
		{"id":"f9cd9cbd5670ae73","type":"text","text":"## Implementazione dei thread\n\nI thread utente sono implementati in specifiche API (POSIX threads (pthreads), Java threads, ...), mentre i thread kernel e il mapping sono gestiti da un sottosistema noto come Thread Library (o Package), parte integrante del SO, che sfrutta le syscall.","x":-464,"y":1300,"width":1000,"height":180,"color":"4"},
		{"id":"b34d99bdf2278892","type":"file","file":"pthreads.png","x":-464,"y":1510,"width":556,"height":790},
		{"id":"b6527646e8c708a9","type":"text","text":"# Java e Thread Pools\n\nPosto che non so usarlo, pare serva a gestire i server. Il multi-threading su server prevede la creazione di un thread per ogni richiesta da gestire. Il problema è che se ne possono creare troppi, per cui si usano delle THREAD POOLS, ovvero all'avvio creo un certo numero di thread che metto in una pool. Quando devo gestire una richiesta, pesco (\"risveglio\") un thread dalla pool. Se non ce ne sono, aspetto. Quando finisce la gestione della richiesta, il thread torna a dormire nella pool. Separare la richiesta (job da eseguire) dal processo di creazione del thread (chi lo esegue) permette anzitutto di guadagnare tempo (e quindi ridurre l'overhead, ovvero il \"lavoro in più\", immagina di dover creare ogni volta da capo il processo/thread che esegue un job piuttosto che averlo pronto e doverlo solo \"risvegliare\"), e secondariamente di organizzare con uno scheduler l'esecuzione di un certo thread in stand-by eseguendolo periodicamente, con un delay o al verificarsi di certe condizioni.","x":120,"y":1510,"width":416,"height":790,"color":"4"},
		{"id":"31454c1c260010da","type":"text","text":"# Threads Q&A\n\nQ: If one thread forks, is the entire process copied, or is the new process single-threaded?\n- A1: System dependent;\n- A2: If the new process execs right away, there is no need to copy all the other threads, otherwise the entire process should be copied;\n- A3: Many versions of UNIX provide multiple versions of the fork call for this purpose.\n\nQ: When a multi-threaded process receives a signal, what thread should that signal be delivered to?\n- A1: There are 4 major options:\n\t- Deliver the signal to the thread to which the signal applies\n\t- Deliver the signal to every thread in the process\n\t- Deliver the signal to certain threads in the process\n\t- Assign a specific thread to receive all signals in a process\n\n\n- A2: UNIX allows individual threads to indicate which signals they are accepting and which they are ignoring. Provides 2 separate system calls for delivering signals to process/threads, respectively:\n\t- kill(pid, signal)\n\t- pthread_kill(tid, signal)","x":641,"y":1300,"width":762,"height":1000,"color":"1"},
		{"id":"fad3582cc9b8fe57","type":"text","text":"# Dove è necessario sincronizzare?\n\nIl conflitto per le risorse può avvenire su due livelli:\n- Process Contention Scope (PCS): più thread utente dello stesso processo (NON mappati in altrettanti thread kernel) dovrebbero essere sincronizzati dal processo;\n- System Contention Scope (SCS): più thread kernel devono essere sincronizzati dallo scheduler del SO.\n\nDue cose da notare:\n- è il kernel a dover notificare al processo se c'è conflitto per le risorse tra i suoi thread. Questo viene fatto con le UPCALL, una sorta di \"inverso\" delle syscall (ovvero kernel --> user). Le librerie che gestiscono i thread hanno degli upcall handler;\n-  Il processo può in linea di principio non sincronizzare i propri thread. Questo non crea errori a livello di integrità della macchina (perché poi diventano thread kernel sincronizzati dal SO) ma a livello di correttezza del codice (perché le modifiche a memoria possono non risultare ordinate correttamente).\n\n","x":-2638,"y":2340,"width":1111,"height":400,"color":"4"},
		{"id":"933c1f33f83329d3","type":"text","text":"# Come si implementa la sincronizzazione?\n\nIn generale si possono individuare delle SEZIONI CRITICHE, come ad esempio zone di memoria condivisa, sulle quali è fondamentale che più processi/thread non operino simultaneamente per evitare incongruenze. La soluzione è BLOCCARE l'accesso alla sezione critica nel momento in cui un thread vi entra, per poi liberarlo quando ne esce.\n\nUn esempio può essere il seguente. Siamo a casa dei thread Bob e Carla, la sezione critica è andare a comprare il latte se non ce n'è. Assumendo che le singole istruzioni siano atomiche (ovvero non interrompibili), una soluzione \"naive\" può essere quella di sinistra, che rispetta i criteri di:\n- Mutual Exclusion: solo un thread alla volta può entrare nella sezione critica, ovvero solo uno tra Bob e Carla compra il latte se necessario;\n- Liveness: se non c'è alcun thread in seione critica, tutti quelli che vogliono entrarci devono poterlo fare, ovvero almeno uno tra Bob e Carla deve poter comprare il latte (ovvero, non permettere a nessuno di entrare in una zona critica su cui c'è conflitto è una soluzione ma non è una buona soluzione);\n- Bounded Waiting: l'attesa per l'ingresso nella sezione critica non deve essere indefinita, ovvero sia Bob che Carla, a seconda dello scheduling dei rispettivi thread, hanno la possibilità di andare a comprare il latte.\n\nTuttavia si può fare di meglio. Posto di avere un'implementazione HW che lo consente, esistono delle primitive atomiche ad-hoc per la sincronizzazione.","x":-2638,"y":2800,"width":1111,"height":540,"color":"4"},
		{"id":"004837f0a7396bbf","type":"file","file":"naive_sync.png","x":-3583,"y":2680,"width":846,"height":400},
		{"id":"45cd529f8bc60a75","type":"text","text":"## Problemi di questa soluzione\nPosto che questa soluzione funziona, ha diverse criticità.\n- Difficile verificare l'effettivo funzionamento;\n- Asimmetrica. Se fossero più di due thread la complessità aumenterebbe molto;\n- Bob va in busy waiting ogni volta che gli viene data la CPU.","x":-3580,"y":3140,"width":840,"height":200,"color":"4"},
		{"id":"4a9e0af6fa1f8472","type":"text","text":"# Sincronizzazione Thread","x":-1175,"y":2506,"width":431,"height":69,"color":"6"},
		{"id":"a8d94719750798b3","type":"file","file":"thread.png","x":-1840,"y":1407,"width":400,"height":256},
		{"id":"b18a396618049aa5","type":"file","file":"parallelism.png","x":-1274,"y":1097,"width":629,"height":170},
		{"id":"0bac8ddd0cc0ea48","type":"text","text":"# Lock\n\nImmagina il lock come un lasciapassare, un oggetto unico che può avere solo una persona per volta. Chi ha il lock può entrare nelle sezioni critiche, gli altri aspettano. Quando costui finisce i suoi doveri nella sezione critica libera il lock, che viene assegnato a uno dei processi/thread in attesa. Viene implementato tramite due primitive:\n- Lock.acquire() --> si mette in attesa che il lock si liberi, quindi lo prende per sè;\n- Lock.release() --> libera il lock e sveglia uno dei thread nella pool di attesa creata da acquire().\n\nNell'esempio di Bob e Carla (che non so perché non si chiami Alice, vbb) il codice diventa simmetrico:\n\n\tLock.acquire()\n\tif(!milk):\n\t\tbuy_milk()\n\tLock.release()\n\n","x":-1399,"y":2800,"width":880,"height":540,"color":"4"},
		{"id":"6b26542e75b5a010","type":"text","text":"## Implementazione di un lock I - disable_interrupts()\n\nIl motivo per cui si rende necessario il lock è il fatto che la CPU in linea di principio può andare in context-switch in qualsiasi momento. O meglio, i casi sono due:\n- Il running thread cede volontariamente la CPU eseguendo, ad esempio, una syscall per operazioni di I/O;\n- C'è un interrupt esterno che blocca brutalmente l'esecuzione indipendentemente da cosa vorrebbe fare il thread.\n\nIl lock si basa sulla possibilità dell'HW di disabilitare gli interrupt per il tempo necessario a eseguire le operazioni critiche.\nCi sono però diversi problemi in una simile implementazione:\n- Perdita di responsività: il SO non  è reattivo nei confronti di richieste anche urgenti;\n- Inversione di priorità: un processo a bassa priorità che fa un disable_interrupts() può bloccare processi a priorità maggiore;\n- Multithreading","x":-464,"y":2340,"width":1000,"height":640,"color":"4"},
		{"id":"adc54afbae0740e4","type":"text","text":"## Implementazione di un lock II - test&set\n\nUn modo alternativo per implementare un lock è sfruttare le istruzioni atomiche come test&set, che legge un valore e scrive 1 in memoria. I dettagli implementativi li capirò più avanti credo. __Non ho capito niente del commento sul multiprocessore__","x":641,"y":2340,"width":762,"height":730},
		{"id":"1dad249a05ab28b1","type":"text","text":"### In C++\n\tClass Lock\n\t{\n\t\tpublic void acquire(Thread t);\n\t\tpublic void release();\n\t\tprivate int value; // 0=FREE, 1=BUSY\n\t\tprivate Queue q;\n\t\tLock()\n\t\t{\n\t\t\tthis.value = 0; // Lock is initially free\n\t\t\tthis.q = null;\n\t\t}\n\t}\n\n\tpublic void acquire(Thread t)\n\t{\n\t\tdisable_interrupts();\n\t\tif(this.value) { // lock is held by someone\n\t\tq.push(t); // add t to waiting queue\n\t\tt.sleep(); // put t to sleep\n\t\t}\n\t\telse this.value = 1;\n\t\tenable_interrupts();\n\t}\n\n\tpublic void release()\n\t{\n\t\tdisable_interrupts();\n\t\tif(!q.is_empty())\n\t\t{\n\t\t\tt = q.pop(); // extract a waiting thread from q\n\t\t\tpush_onto_ready_queue(t); // put t on ready queue\n\t\t}\n\t\telse this.value = 0;\n\t\tenable_interrupts();\n\t}","x":-464,"y":3020,"width":1000,"height":320,"color":"1"}
	],
	"edges":[
		{"id":"edc62c3892b1527c","fromNode":"65f8df716b94268d","fromSide":"right","toNode":"5d67baa15b95e53b","toSide":"left"},
		{"id":"95151c4e7f8fbc92","fromNode":"f259623a35cf9802","fromSide":"right","toNode":"1fb92b9bd42e2c32","toSide":"left"},
		{"id":"5dc9877b09b663e1","fromNode":"1fb92b9bd42e2c32","fromSide":"right","toNode":"24babc6f213a28a7","toSide":"left"},
		{"id":"52c245b570accbde","fromNode":"65f8df716b94268d","fromSide":"bottom","toNode":"f259623a35cf9802","toSide":"top"},
		{"id":"24627fbf3858f743","fromNode":"24babc6f213a28a7","fromSide":"right","toNode":"582cbf0b2f379d20","toSide":"left"},
		{"id":"e1b8844758b417e3","fromNode":"582cbf0b2f379d20","fromSide":"right","toNode":"771c1bd426fd8f47","toSide":"left"},
		{"id":"4cf3992b458c5a19","fromNode":"5d67baa15b95e53b","fromSide":"top","toNode":"667a17b2a2c4afbc","toSide":"bottom"},
		{"id":"681c2ddd6d5625b6","fromNode":"667a17b2a2c4afbc","fromSide":"top","toNode":"76425af58183667e","toSide":"bottom"},
		{"id":"52759ba275a01a39","fromNode":"76425af58183667e","fromSide":"right","toNode":"13a15e4783d53ebf","toSide":"left"},
		{"id":"d8203fbbada60b75","fromNode":"76425af58183667e","fromSide":"right","toNode":"7bdf1dc58118080b","toSide":"left"},
		{"id":"1eced803d27e0b5b","fromNode":"651b3e34405ca302","fromSide":"top","toNode":"69f392e5d5620920","toSide":"bottom"},
		{"id":"2b7ae5a38042da44","fromNode":"255c19cad945a18f","fromSide":"top","toNode":"65f8df716b94268d","toSide":"left"},
		{"id":"d293de9c75d36484","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"651b3e34405ca302","toSide":"bottom"},
		{"id":"0fb324781f2f8ddb","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"255c19cad945a18f","toSide":"bottom"},
		{"id":"067069f44a43fdee","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"0f5be1b419c22070","toSide":"right"},
		{"id":"cc48460b9d62b58d","fromNode":"06528774c7a17e8f","fromSide":"top","toNode":"c5128c9a62b77d1c","toSide":"right"},
		{"id":"af861c59a6d77c9e","fromNode":"c5128c9a62b77d1c","fromSide":"left","toNode":"b763de7850a80c53","toSide":"right"},
		{"id":"4f13bebe82fad842","fromNode":"06528774c7a17e8f","fromSide":"top","toNode":"3b4c354f921c302c","toSide":"right"},
		{"id":"d715240d9948d69d","fromNode":"c5128c9a62b77d1c","fromSide":"bottom","toNode":"9aa74fda3231a196","toSide":"top"},
		{"id":"5eba096a0b958952","fromNode":"9aa74fda3231a196","fromSide":"bottom","toNode":"558ba900733523b5","toSide":"top"},
		{"id":"2bb965729a2d1282","fromNode":"3b4c354f921c302c","fromSide":"top","toNode":"2cbd9476c35281f6","toSide":"bottom"},
		{"id":"8e217020043c5cfd","fromNode":"c5128c9a62b77d1c","fromSide":"left","toNode":"7f02462535d305da","toSide":"right"},
		{"id":"07dd0a50bfeb1f16","fromNode":"307924e88efadd9d","fromSide":"left","toNode":"99c05cd2bb5fb531","toSide":"right"},
		{"id":"99f8a9a52b3c9853","fromNode":"558ba900733523b5","fromSide":"left","toNode":"307924e88efadd9d","toSide":"right"},
		{"id":"a99cb436db17db6e","fromNode":"06528774c7a17e8f","fromSide":"left","toNode":"558ba900733523b5","toSide":"right"},
		{"id":"8e0732983a2e84c4","fromNode":"99c05cd2bb5fb531","fromSide":"left","toNode":"a2ca84c1f075532c","toSide":"right"},
		{"id":"48c624f207642033","fromNode":"ebda4cf153d6ae26","fromSide":"bottom","toNode":"fccd506f086b692b","toSide":"top"},
		{"id":"4f3fd12e72b50247","fromNode":"16683038ca807a6e","fromSide":"left","toNode":"f104b3656720780b","toSide":"right"},
		{"id":"54a1b680c224da4b","fromNode":"f104b3656720780b","fromSide":"left","toNode":"4f7a30ec90f5f7a1","toSide":"right"},
		{"id":"1e74e9b040717bdf","fromNode":"69f392e5d5620920","fromSide":"top","toNode":"d944c099d4a52726","toSide":"bottom"},
		{"id":"b8304082ba758712","fromNode":"d944c099d4a52726","fromSide":"right","toNode":"69f3dd73ee95ff32","toSide":"left"},
		{"id":"3398396f12b7d67c","fromNode":"16683038ca807a6e","fromSide":"right","toNode":"c02fca4457eea4a1","toSide":"left"},
		{"id":"c839bef60036bb31","fromNode":"c02fca4457eea4a1","fromSide":"right","toNode":"cffda0fb3a359471","toSide":"left"},
		{"id":"0be209d4f4b381c0","fromNode":"cffda0fb3a359471","fromSide":"right","toNode":"50134cc52be508aa","toSide":"left"},
		{"id":"e49b2c4209b70436","fromNode":"50134cc52be508aa","fromSide":"right","toNode":"6bc46856fa34b1e2","toSide":"left"},
		{"id":"1df4ae7e3b3f3880","fromNode":"16683038ca807a6e","fromSide":"bottom","toNode":"ccea465ee5a66f66","toSide":"top"},
		{"id":"96cf72cd1e5c85fb","fromNode":"ccea465ee5a66f66","fromSide":"bottom","toNode":"409f9cd96c788b91","toSide":"top"},
		{"id":"58b3492bc3a36d0b","fromNode":"409f9cd96c788b91","fromSide":"bottom","toNode":"e864bef1d25309b9","toSide":"top"},
		{"id":"40ef8fb659b5e498","fromNode":"e864bef1d25309b9","fromSide":"left","toNode":"efa5f9c31e4d06bc","toSide":"right"},
		{"id":"46c9b7d88843fbbc","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"06528774c7a17e8f","toSide":"right"},
		{"id":"c94d1eb183cd2ea4","fromNode":"f104b3656720780b","fromSide":"bottom","toNode":"ccea465ee5a66f66","toSide":"left"},
		{"id":"5d94b490a5b2e514","fromNode":"ccea465ee5a66f66","fromSide":"left","toNode":"f104b3656720780b","toSide":"bottom"},
		{"id":"60968084a2fe0dab","fromNode":"4f7a30ec90f5f7a1","fromSide":"left","toNode":"66b9c1070bde7f69","toSide":"right"},
		{"id":"f4396814055bce28","fromNode":"4f7a30ec90f5f7a1","fromSide":"bottom","toNode":"077958ec99cf0920","toSide":"top"},
		{"id":"5913f5186ef94be5","fromNode":"409f9cd96c788b91","fromSide":"left","toNode":"50883272249f2785","toSide":"right"},
		{"id":"a236ceb51a82c4c7","fromNode":"a1adbe9bb664a9c2","fromSide":"right","toNode":"50883272249f2785","toSide":"left"},
		{"id":"df29268ac512a536","fromNode":"a1adbe9bb664a9c2","fromSide":"left","toNode":"077958ec99cf0920","toSide":"right"},
		{"id":"670e1493337dc598","fromNode":"077958ec99cf0920","fromSide":"left","toNode":"8fac94dbd27f5a21","toSide":"right"},
		{"id":"1b4788b11ebf0238","fromNode":"077958ec99cf0920","fromSide":"left","toNode":"9ed99aa483da3638","toSide":"right"},
		{"id":"3867373f2edbe894","fromNode":"307924e88efadd9d","fromSide":"left","toNode":"2bd5a1b48bac530b","toSide":"top"},
		{"id":"ce23a5818adb79a5","fromNode":"3cbd143423e3f10a","fromSide":"right","toNode":"2bd5a1b48bac530b","toSide":"left"},
		{"id":"5ed619d4204533a1","fromNode":"2bd5a1b48bac530b","fromSide":"left","toNode":"3cbd143423e3f10a","toSide":"right"},
		{"id":"6ddcfe773f92dcc2","fromNode":"3cbd143423e3f10a","fromSide":"left","toNode":"7c939ee2ebe1207c","toSide":"right"},
		{"id":"c3464022fcab6606","fromNode":"3cbd143423e3f10a","fromSide":"top","toNode":"e2aefc482d1e7497","toSide":"bottom"},
		{"id":"8e8550eab6fae909","fromNode":"077958ec99cf0920","fromSide":"bottom","toNode":"97b3e71503c3e19d","toSide":"top"},
		{"id":"bc353e107d214a96","fromNode":"97b3e71503c3e19d","fromSide":"bottom","toNode":"6f102d8a296c67cf","toSide":"top"},
		{"id":"4532c867becfe2e6","fromNode":"6f102d8a296c67cf","fromSide":"left","toNode":"890280218841edc0","toSide":"right"},
		{"id":"bf02e50884b3ddd5","fromNode":"890280218841edc0","fromSide":"left","toNode":"0d183aee8445a447","toSide":"right"},
		{"id":"383a98afb3008463","fromNode":"0d183aee8445a447","fromSide":"left","toNode":"7c61dcb5932faf1f","toSide":"right"},
		{"id":"52f32e8d8b49ded4","fromNode":"6f102d8a296c67cf","fromSide":"right","toNode":"da8d7ccc61fb288f","toSide":"left"},
		{"id":"360f2a91dd1b123f","fromNode":"890280218841edc0","fromSide":"bottom","toNode":"4fe1989d7b05db02","toSide":"top"},
		{"id":"ac94d247b1fabc7d","fromNode":"8fac94dbd27f5a21","fromSide":"bottom","toNode":"4fe1989d7b05db02","toSide":"top"},
		{"id":"cf02d4cb1a746558","fromNode":"6f102d8a296c67cf","fromSide":"bottom","toNode":"127fb02c474f9e0c","toSide":"top"},
		{"id":"1dd016202fbf2fdc","fromNode":"3cbd143423e3f10a","fromSide":"bottom","toNode":"1c983ed53f331726","toSide":"top"},
		{"id":"9078d105834790b6","fromNode":"7c61dcb5932faf1f","fromSide":"left","toNode":"66990f7c63e2d405","toSide":"right"},
		{"id":"b1cd1503042a71db","fromNode":"3cbd143423e3f10a","fromSide":"left","toNode":"ba2b6213e4637219","toSide":"bottom"},
		{"id":"2c527e4b10454f12","fromNode":"66990f7c63e2d405","fromSide":"top","toNode":"e286057ad92c4f0c","toSide":"bottom"},
		{"id":"7b732ebd6b98fb05","fromNode":"66990f7c63e2d405","fromSide":"right","toNode":"a468bd8ba770bd4b","toSide":"left"},
		{"id":"9571cd60a5124870","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"4ff852d5afad6346","toSide":"right"},
		{"id":"66573d7025a6c12e","fromNode":"7c61dcb5932faf1f","fromSide":"bottom","toNode":"6c0f163753eb8b85","toSide":"top"},
		{"id":"f5136f611675b525","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"2a9d90b8cc31da54","toSide":"right"},
		{"id":"f463b513261aace8","fromNode":"a468bd8ba770bd4b","fromSide":"left","toNode":"e286057ad92c4f0c","toSide":"right"},
		{"id":"d893929f320106c9","fromNode":"4ff852d5afad6346","fromSide":"bottom","toNode":"2a9d90b8cc31da54","toSide":"top"},
		{"id":"567c9121d0606efb","fromNode":"66990f7c63e2d405","fromSide":"right","toNode":"005e7e1e1c753ec3","toSide":"left"},
		{"id":"c328310a1108ab59","fromNode":"005e7e1e1c753ec3","fromSide":"bottom","toNode":"b73522939cb2e340","toSide":"top"},
		{"id":"27e340efb990c46f","fromNode":"66990f7c63e2d405","fromSide":"bottom","toNode":"30f61bfe887b9609","toSide":"top"},
		{"id":"0d30eb082ccf3688","fromNode":"005e7e1e1c753ec3","fromSide":"left","toNode":"30f61bfe887b9609","toSide":"right"},
		{"id":"397e64d7228e29f4","fromNode":"66990f7c63e2d405","fromSide":"bottom","toNode":"97288d1ddddfffed","toSide":"top"},
		{"id":"2feb230814305d21","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"ee4978ec280e0156","toSide":"right"},
		{"id":"4b0512ad6f58e730","fromNode":"ee4978ec280e0156","fromSide":"bottom","toNode":"c948ce6320acafbe","toSide":"top"},
		{"id":"6adf051489ec3ca2","fromNode":"ccea465ee5a66f66","fromSide":"right","toNode":"113ca9ce4e51d6e6","toSide":"left"},
		{"id":"cbec9e6171417d9a","fromNode":"113ca9ce4e51d6e6","fromSide":"top","toNode":"b18a396618049aa5","toSide":"bottom"},
		{"id":"b3a442e2fbe1e6d6","fromNode":"113ca9ce4e51d6e6","fromSide":"right","toNode":"f9cd9cbd5670ae73","toSide":"left"},
		{"id":"9ae401be5385be51","fromNode":"f9cd9cbd5670ae73","fromSide":"bottom","toNode":"b34d99bdf2278892","toSide":"top"},
		{"id":"7c7616daa8714bad","fromNode":"f9cd9cbd5670ae73","fromSide":"bottom","toNode":"b6527646e8c708a9","toSide":"top"},
		{"id":"10f2a9db4884ff78","fromNode":"f9cd9cbd5670ae73","fromSide":"right","toNode":"31454c1c260010da","toSide":"left"},
		{"id":"d79a4b17e6be3f2e","fromNode":"113ca9ce4e51d6e6","fromSide":"bottom","toNode":"4a9e0af6fa1f8472","toSide":"top"},
		{"id":"d6f0d98646ef8786","fromNode":"4a9e0af6fa1f8472","fromSide":"left","toNode":"fad3582cc9b8fe57","toSide":"right"},
		{"id":"e20e3517047dbf43","fromNode":"fad3582cc9b8fe57","fromSide":"bottom","toNode":"933c1f33f83329d3","toSide":"top"},
		{"id":"dbbc61ed301cfd99","fromNode":"933c1f33f83329d3","fromSide":"left","toNode":"004837f0a7396bbf","toSide":"right"},
		{"id":"8a06bf0ae88cd109","fromNode":"004837f0a7396bbf","fromSide":"bottom","toNode":"45cd529f8bc60a75","toSide":"top"},
		{"id":"3458496fb70e45db","fromNode":"45cd529f8bc60a75","fromSide":"right","toNode":"933c1f33f83329d3","toSide":"left"},
		{"id":"cfbee7a02809a3c9","fromNode":"933c1f33f83329d3","fromSide":"right","toNode":"0bac8ddd0cc0ea48","toSide":"left"},
		{"id":"42a43d777eddf699","fromNode":"4a9e0af6fa1f8472","fromSide":"bottom","toNode":"0bac8ddd0cc0ea48","toSide":"top"},
		{"id":"aeaa7e17c9f266b1","fromNode":"6b26542e75b5a010","fromSide":"right","toNode":"adc54afbae0740e4","toSide":"left"},
		{"id":"71489c7da900eae1","fromNode":"0bac8ddd0cc0ea48","fromSide":"top","toNode":"6b26542e75b5a010","toSide":"left"},
		{"id":"576614796f1f592e","fromNode":"6b26542e75b5a010","fromSide":"bottom","toNode":"1dad249a05ab28b1","toSide":"top"}
	]
}
{
	"nodes":[
		{"id":"16683038ca807a6e","type":"text","text":"# Sistema Operativo","x":-2248,"y":924,"width":329,"height":74,"color":"5"},
		{"id":"1829ebdad1c10164","type":"text","text":"# Verso l'Hardware","x":-2248,"y":799,"width":329,"height":50,"color":"3"},
		{"id":"d28c649c75ac5104","type":"text","text":"# Verso il Software","x":-2248,"y":1072,"width":329,"height":50,"color":"6"},
		{"id":"f104b3656720780b","type":"text","text":"# Sincronizzazione Processi","x":-3460,"y":931,"width":440,"height":60,"color":"6"},
		{"id":"9ed99aa483da3638","type":"text","text":"# Batch Systems (per cultura)\n\nI \"batch systems\" si riferiscono a sistemi operativi o ambienti informatici in cui le attività vengono eseguite in lotti (batch), senza interazione immediata con l'utente. In un sistema batch, gli utenti preparano un insieme di comandi o job in anticipo e li presentano al sistema operativo per l'esecuzione. Il sistema operativo quindi esegue i job uno dopo l'altro senza richiedere un'interazione diretta con l'utente durante l'esecuzione di ciascun job.\n\nCaratteristiche principali dei batch systems:\n\n1. **Pianificazione e Esecuzione Automatica:** Gli utenti preparano uno o più job insieme a tutti i dati necessari e li inviano al sistema operativo per esecuzione. Il sistema operativo pianifica l'esecuzione dei job in base a determinati criteri.\n    \n2. **Assenza di Interazione Utente:** Durante l'esecuzione dei job, non è richiesta l'interazione diretta dell'utente. Il sistema operativo esegue i job in modo sequenziale senza richiedere input dall'utente tra un job e l'altro.\n    \n3. **Ottimizzazione delle Risorse:** I batch systems sono progettati per ottimizzare l'utilizzo delle risorse del sistema. Possono eseguire automaticamente una sequenza di job senza la necessità di costante monitoraggio umano.\n    \n4. **Elaborazione in Lotti:** Le attività vengono elaborate in lotti piuttosto che in modo interattivo. Questo è particolarmente utile per attività ripetitive o computazioni intensive che richiedono un tempo significativo.\n    \n5. **Output Salvato:** I risultati o l'output dei job possono essere salvati su file o stampati per consentire agli utenti di esaminare i risultati in un secondo momento.\n    \n6. **Storico e Monitoraggio:** I sistemi batch spesso mantengono un registro delle attività eseguite e forniscono strumenti di monitoraggio per verificare lo stato dei job in esecuzione o completati.\n    \n\nQuesti sistemi batch erano particolarmente comuni nei primi giorni dell'informatica e sono ancora utilizzati in alcune applicazioni specifiche oggi, specialmente in contesti di elaborazione di grandi volumi di dati o di esecuzione di processi automatizzati.\n\nEcco alcuni esempi pratici di situazioni in cui i sistemi batch potrebbero essere utilizzati:\n\n1. **Elaborazione Notturna delle Transazioni Bancarie:**\n    \n    - Un istituto finanziario può eseguire un sistema batch durante la notte per elaborare tutte le transazioni finanziarie effettuate durante la giornata. Ciò include l'aggiornamento dei saldi dei conti, la generazione di estratti conto e altre operazioni di elaborazione dati.\n2. **Compilazione di Programmi Software:**\n    \n    - In un ambiente di sviluppo del software, la compilazione di programmi complessi può richiedere tempo. I sistemi batch possono essere utilizzati per automatizzare il processo di compilazione di grandi progetti software durante le ore non lavorative.\n3. **Calcolo Scientifico Intensivo:**\n    \n    - In ambiti scientifici, come la simulazione di modelli complessi o il rendering grafico, i sistemi batch possono essere utilizzati per gestire l'esecuzione di calcoli intensivi durante periodi di inattività del sistema.\n4. **Produzione di Rapporti Periodici:**\n    \n    - Un'azienda può generare rapporti periodici, come rapporti finanziari mensili, mediante un sistema batch che elabora i dati accumulati durante il mese e produce i rapporti senza richiedere l'intervento dell'utente.\n5. **Elaborazione di Grandi Batch di Dati:**\n    \n    - In applicazioni di analisi dei dati, come la creazione di modelli statistici su grandi insiemi di dati, i sistemi batch possono essere utilizzati per eseguire analisi complesse senza interrompere l'interazione dell'utente.\n6. **Stampa di Documenti in Massa:**\n    \n    - In ambienti in cui è necessario stampare grandi volumi di documenti, come fatture o estratti conto, i sistemi batch possono gestire la coda di stampa in modo che la stampa avvenga in modo automatico senza richiedere l'intervento costante dell'utente.\n\nIn questi esempi, l'uso di sistemi batch consente di automatizzare processi ripetitivi, di ottimizzare l'utilizzo delle risorse e di pianificare l'esecuzione delle attività quando il sistema è meno sollecitato.","x":-5788,"y":1320,"width":857,"height":441},
		{"id":"8fac94dbd27f5a21","type":"text","text":"# Context Switch\n\nOvvero, sospendere un processo running per eseguirne uno ready. Molto costoso, devo salvare tutto nel PCB per quando dovrò riprenderlo. Succede ogni qualvolta arriva un segnale di trap, e la CPU deve passare in Kernel Mode per gestire l'interrupt. Esempi sono interazioni I/O sui processi attivi o la \"fairness\", ovvero il timer (il \"time slice\" è il massimo tempo tra due Context Switch, usato per implementare lo pseudo-parallelismo dei processi sul singolo core, detta \"responsiveness\"). Il trade-off è quindi tra\n\n- Massimizzare la responsiveness diminuendo il time slice;\n- Minimizzare il tempo perso nel fare Switch aumentando il time slice.\n\nUn time slice dura tipicamente 10-100 millisecondi, contro i 10 microsecondi di uno Switch.","x":-5788,"y":1801,"width":857,"height":400,"color":"4"},
		{"id":"0d183aee8445a447","type":"text","text":"Nei primo e nell'ultimo caso (non-preemptive scheduling) è necessario selezionare un altro processo, mentre nei due intermedi (preemptive scheduling) può continuare quello corrente","x":-5788,"y":2241,"width":250,"height":280,"color":"4"},
		{"id":"890280218841edc0","type":"text","text":"### Quando si attiva lo Scheduler CPU?\nQuando un processo\n\t- Passa da RUNNING a WAITING --> Richiesta di I/O o syscall wait();\n\t- Passa da RUNNING a READY --> Interrupt;\n\t- Passa da WAITING a READY --> Ritorno da I/O o da syscall wait();\n\t- Viene creato (NEW) o termina (TERMINATED).","x":-5509,"y":2241,"width":578,"height":280,"color":"4"},
		{"id":"4fe1989d7b05db02","type":"text","text":"# Dispatcher\n\nOgni volta che si ha un Context Switch si attiva il modulo Dispatcher, che passa il controllo della CPU al processo selezionato dallo scheduler. Il suo tempo di esecuzione (dispatch latency) deve quindi essere particolarmente basso. Its functions include:\n\n• Switching context (salva vecchio PCB, carica il nuovo)\n• Switching to user mode\n• Jumping to the proper location in the newly loaded program\n\nInoltre, monitora il tempo di uso della CPU, e può prendere decisioni da preemptive scheduler interrompendo il burst CPU prima del timer. In un sistema multi-core, è suo compito la coordinazione tra di essi.\n","x":-5788,"y":2581,"width":839,"height":400,"color":"2"},
		{"id":"a468bd8ba770bd4b","type":"text","text":"# First-Come-First-Serve (FCFS)\n\nNon-preemptive. Pila FIFO (i.e. fila al post office). I processi sono eseguiti in ordine di arrivo nella ready queue. The scheduler takes over only when the currently running job asks for an I/O operation (or finishes its execution). A job may keep using the CPU indefinitely (i.e., until it blocks).\n\nPro: Semplice.\nContro:\n- Il tempo di attesa è molto variabile (un processo breve può restare bloccato dietro processi lunghi);\n- Convoy Effect: Se cambio processo da A a B per fare un breve I/O, questo potrebbe restare bloccato a tempo indeterminato in attesa che finisca B --> Poca ottimizzazione sul fronte I/O.","x":-7254,"y":1320,"width":583,"height":521,"color":"2"},
		{"id":"005e7e1e1c753ec3","type":"text","text":"# Multi-Level Queue (MLQ)\n\nUse multiple separate queues, one for each job category. Scheduling must be done between queues. Each queue implements whatever scheduling algorithm is most appropriate for that type of jobs.\n\nTwo common options are:\n- Strict Priority --> no job in a lower priority queue runs until all higher priority queues are empty;\n- Round-Robin --> each queue gets a time slice in turn, possibly of different sizes.\n\nNote: Jobs cannot switch from queue to queue (non cambiano categoria in corso d'opera o per effetto dello scheduling)","x":-7254,"y":2021,"width":583,"height":500,"color":"1"},
		{"id":"7c61dcb5932faf1f","type":"text","text":"### Non-preemptive Scheduling (più \"statico\")\n\n1. **Caratteristiche Principali:**\n\t-  I processi non vengono interrotti durante il loro tempo di CPU burst.\n\t- Un processo mantiene la CPU fino a quando non completa il suo burst o si sospende volontariamente (ad esempio, per attendere l'I/O).\n2. **Esempio:**\n        - Un algoritmo di ordinamento senza prelazione potrebbe essere il First-Come-First-Served (FCFS) o Shortest Job Next (SJN), dove il processo in esecuzione continua finché non completa la sua esecuzione o decide di attendere volontariamente.\n3. **Vantaggi:**\n    - Semplice da implementare e comprendere.\n    - Minimizza il tempo di attesa medio per i processi brevi.\n4. **Svantaggi:**\n\tPuò portare al problema del \"convoy effect\", dove un processo lungo ritarda l'esecuzione di processi più brevi che lo seguono nella coda.\n\n### Preemptive Scheduling (più \"dinamico\")\n\n1. **Caratteristiche Principali:**\n    - Un processo può essere interrotto durante il suo CPU burst.\n    - La CPU può essere assegnata a un nuovo processo prima che il processo attuale abbia completato il suo burst.\n2. **Esempio:**\n    - Un algoritmo di ordinamento con prelazione potrebbe essere il Round Robin (RR) o l'algoritmo di prioritizzazione in cui un processo può essere interrotto dopo un certo quantum di tempo o se un processo con una priorità più alta diventa disponibile.\n3. **Vantaggi:**\n    - Riduce il tempo di risposta medio e migliora la reattività del sistema.\n    - Può evitare il \"convoy effect\" poiché processi più brevi possono essere eseguiti prima.\n4. **Svantaggi:**\n    - Complessità aggiuntiva nell'implementazione dell'ordinamento con prelazione.\n    - Potenzialmente può portare a un aumento del tempo di attesa per i processi brevi in determinate circostanze.\n\nLa scelta tra ordinamento con e senza prelazione dipende dalle esigenze specifiche del sistema e dagli obiettivi di ottimizzazione. Algoritmi di ordinamento con prelazione sono spesso preferiti in sistemi in cui la reattività e il tempo di risposta sono critici. Al contrario, algoritmi senza prelazione possono essere più appropriati in situazioni in cui la semplicità e la minimizzazione del tempo di attesa medio sono più importanti.","x":-6569,"y":1320,"width":698,"height":1201,"color":"2"},
		{"id":"6c0f163753eb8b85","type":"text","text":"# Preemption: Issues\n\nPreemption might cause troubles if it occurs while\n\n• the kernel is busy implementing a system call (e.g., updating critical kernel data structures);\n• two processes share data, one may get interrupted in the middle of updating shared data structures.\n\nPossible countermeasures:\n\n• Make the process wait until the system call has either completed or blocked before allowing the preemption --> problematic for real-time systems, as real-time response can no longer be guaranteed\n• Disable interrupts before entering critical code section and re-enabling immediately afterwards --> should only be done in rare situations, and only on very short pieces of code that will finish quickly","x":-6569,"y":2581,"width":698,"height":400,"color":"1"},
		{"id":"b73522939cb2e340","type":"file","file":"Processi/Sincronizzazione Processi (Scheduler CPU)/MLQ.png","x":-7254,"y":2671,"width":583,"height":220},
		{"id":"077958ec99cf0920","type":"text","text":"# Process Scheduling\n2 main goals of the process scheduling system:\n- keep the CPU busy at all times\n- deliver \"acceptable\" response times for all programs, particularly for interactive ones\n\nThe process scheduler must meet these objectives by implementing suitable policies for swapping processes in and out of the CPU.\nNote that these objectives can be conflicting!\n\t• Every time the OS steps in to swap processes it takes up time on the CPU to do so, which is thereby \"lost\" from doing any useful productive work.\n## Process State Queues\nThe OS mantains the PCBs of all the processes in state queues\n\t• There is one queue for each of the 5 states a process can be in\n\t• There is typically one queue for each I/O device (where processes wait for a device to become available or to deliver data)\n\t• When the OS change the status of a process (e.g., from ready to running) the PCB is unlinked from the current queue and moved to the\n\tnew one\n\t• The OS may use different policies to manage each state queue\nHow many PCBs can be in the Running Queue?\n\t• The Running Queue is bound by the number of cores available on the system\n\t• At each time, only one process can be executed on a CPU\nWhat about the other queues?\n\t• They are basically unbounded as there is no theoretical limit on the number processes in new/ready/waiting/terminated states","x":-4815,"y":1320,"width":1111,"height":621,"color":"1"},
		{"id":"97b3e71503c3e19d","type":"text","text":"Possono esserci Scheduler long-term (gira poco frequentemente, tipico dei Batch Systems, definisce il livello di multiprogramming, ovvero quanti processi vengono caricati in RAM), short-term (che è quello della CPU, gira con una frequenza dell'ordine dei 100 millsecondi, regola come scegliere il prossimo processo dalla ready queue) e medium-term (quando c'è tanto carico di lavoro, fanno passare avanti i processi che ci mettono poco, tipo in fila al supermercato). In effetti gli scheduler possono essere visualizzati con un supermercato. Short term indirizza le persone alle casse, medium-term fa saltare la fila a quello che ha solo un paio di cose e long term gestisce il flusso di persone nella struttura (calzante in tempi covid). Chiaro che il più importante è il primo. Un buon sistema di scheduling occupa in modo bilanciato CPU e I/O.","x":-4815,"y":2001,"width":1111,"height":200,"color":"4"},
		{"id":"127fb02c474f9e0c","type":"text","text":"# Scheduling Criteria\n\n- Utilizzo CPU (frazione di tempo in cui la CPU è occupata): da massimizzare. In sistemi reali dovrebbe essere nel range (0.4, 0.9);\n- Throughput (processi completati per unità di tempo): da massimizzare. Può variare tra 10/sec e 1/ora;\n- Tournaround time (tempo \"di orologio\" di completamento di un processo, dallo stato NEW a TERMINATED): da minimizzare;\n- Waiting time (tempo speso dal processo nella ready queue): da minimizzare. Notare che i processi waiting non possono essere gestiti dallo scheduler, sono solo \"ready to run\";\n- Response time (una sorta di input delay, tempo che intercorre tra il comando e l'inizio della sua esecuzione): da minimizzare.\n\nSi può intuire che è impossibile ottimizzarle tutte insieme, quindi si fa trade-off. Il criterio è scrivere lo scheduler basandosi su una certa policy, ovvero scegliendo cosa sacrificare.\n\n- Per Sistemi Interattivi si ottimizza il tempo di risposta;\n-  Per Sistemi Batch si massimizza il throughput (minimizzando l'Overhead, ovvero lo switch User-Kernel mode) e si minimizza il Waiting time, tipicamente minimizzando gli interrupt durante i burst CPU, andando eventualmente a penalizzare il tempo di risposta.","x":-4815,"y":2581,"width":1111,"height":400,"color":"4"},
		{"id":"6f102d8a296c67cf","type":"text","text":"# CPU Scheduler (Short-Term)","x":-4500,"y":2356,"width":482,"height":50,"color":"6"},
		{"id":"4f7a30ec90f5f7a1","type":"text","text":"# Sincronizzazione dei processi e \"democrazia\"\n\nC'è un timer (che non è il clock delle operazioni di base della CPU!) che ogni tot tempo manda degli interrupt alla CPU, il cui Scheduler decide qual è il prossimo processo da eseguire.\n\nIl SO deve essere in grado di coordinare le attività in modo da ottimizzare il lavoro dello Scheduler della CPU.\n\nHardware must ensure that short sequences of instructions (e.g., read- modify-write) are executed atomically by either:\n\t• Disabling interrupts before the sequence and re-enable them afterwards;\n\t• Special instructions that are natively executed atomically.\nQuesto perché sarebbe davvero spiacevole interrompere un'operazione di scrittura prima che abbia finito, lasciando la memoria in uno stato inconsistente.\n\n• Most system calls (e.g., I/O ones) are blocking\n• the caller process (user space) can't do anything until the system call returns\n• the OS (kernel space):\n\t• sets the current process to a waiting state (i.e., waiting for the system call to return)\n\t• schedules a different ready process to avoid the CPU being idle\n• once the system call returns the previously blocked process is ready to be scheduled for execution again\n• NOTE: the whole system is not blocked, only the process which has requested the blocked call is!","x":-4815,"y":706,"width":1111,"height":510,"color":"2"},
		{"id":"4ff852d5afad6346","type":"text","text":"# Shortest Job First (SJF)\n\nSchedule the job that has the least expected amount of work to do until its next I/O operation or termination.\n\nPro:\n• Optimal when the goal is to minimize the avg. waiting time\n• Works both with preemptive and non-preemptive schedulers (preemptive SJF is called SRTF or Shortest Remaining Time First, nel secondo caso lo scheduler si attiva quando arriva un nuovo processo nella coda ready e la sua durata di burst prevista è minore del processo in esecuzione).\n\nContro:\n• Almost impossible to predict the amount of CPU time of a job\n• Long running CPU-bound jobs can starve (as I/O-bound ones have implicitly higher priority over them)","x":-8709,"y":1320,"width":559,"height":521,"color":"2"},
		{"id":"2a9d90b8cc31da54","type":"text","text":"# Priority Scheduling\nUn SJF più generale. A ogni job assegno una priorità ed lo scheduler manda alla CPU quello con priorità maggiore.\nUsually, low numbers for high priorities (0 = the highest possible priority). La priorità può essere assegnata\n- Dal SO con i suoi criteri (Internal Priority);\n- Dall'utente (External Priority).\n\nPuò essere sia preemptive che non. Problemi associati sono:\n- Indefinite blocking (starvation): low-priority task can wait forever because some other jobs have always higher priority. Una soluzione è l'Aging, ovvero aumentare la priorità proporzionalmente al tempo di attesa;\n- Stuck jobs may eventually run when the system load is lighter or after a shutdown/crash and a reboot.","x":-8709,"y":2021,"width":559,"height":500,"color":"2"},
		{"id":"e286057ad92c4f0c","type":"text","text":"# Round Robin (RR)\nPreemptive. Come FCFS, due differenze:\n\n- A ogni burst CPU corrisponde un time slice. Quando parte la CPU, parte il timer.\n\t• Se il job finisce prima del timer si ricade nell'algoritmo FCFS. Chiaro che se metto un time slice enorme tendo a ricadere in FCFS;\n\t• Altrimenti, il job viene tolto dalla CPU e messo in fondo alla coda ready.\n\n- La coda è gestita in modo circolare. Il processo successivo è sempre quello in cima alla pila, e dopo essere stato tolto dallo stato di RUN finisce in fondo alla pila. Evito il Convoy Effect.\n\nSegue che l'average waiting time può essere lungo (i processi brevi non hanno alcuna priorità perché nessun processo ha priorità). Il trade-off tra ricadere in FCFS e i troppi context switch (che abbassano il throughput) è avere un time slice circa 3 ordini di grandezza più piccolo (i.e. context switch dura 0.1ms, time slice di 100ms). Le effettive differenze sulle metriche rispetto a FCFS possono variare a seconda di fattori come \\#jobs, durata di ogni job, time slice, arrival time, numero di context switch, ...","x":-8049,"y":1320,"width":698,"height":521,"color":"4"},
		{"id":"30f61bfe887b9609","type":"text","text":"# Multilevel Feedback-Queue (MLFQ)\n\nCome MLQ, ma è possibile cambiare categoria ai processi. Può servire se:\n- The characteristics of a job change between CPU-intensive and I/O-intensive.\n- A job that has waited for a long time can get bumped up into a higher priority queue for a while (to compensate the aging problem).\n\nMetodo:\n- Job starts in the highest priority queue (by default);\n-  If job's timer expires --> drop its priority level by one unit;\n-  If job's timer does not expire (i.e., context switch occurs due to I/O request) --> increase its priority level by one unit;\n- CPU-bound jobs will quickly drop priority, I/O-bound jobs will stay high priority.\n\nMost flexible, but also most complex to implement. Serve definire parametri come numero di code, algoritmo di scheduling di ogni coda, criteri di upgrade o downgrade tra le code, criterio di assegnazione iniziale di un processo a una coda, ...","x":-8049,"y":2021,"width":698,"height":500,"color":"2"},
		{"id":"66990f7c63e2d405","type":"text","text":"# Scheduling Algorithms","x":-7906,"y":1900,"width":412,"height":62,"color":"6"},
		{"id":"97288d1ddddfffed","type":"text","text":"# Fairness Issue\n\nAlgoritmi come SJF e MLFQ (che promuovendo esplicitamente i job con tempo di esecuzione previsto più breve imita il best-behaviour di SJF) sono UNFAIR, ovvero permette situazioni in cui alcuni processi a bassa priorità hanno un waiting time altissimo. Non sempre aumentare i burst CPU per questi processi risolve il problema, perché rischia di aumentare l'average waiting time dell'intero sistema.\nUna soluzione può essere l'aumento dinamico della priorità proporzionalmente al waiting time del processo, ma in condizioni di overloading del sitema questo porta a un appiattimento dell'algoritmo (tutti i processi finiscono ad avere massima priorità).","x":-8049,"y":2581,"width":698,"height":400,"color":"4"},
		{"id":"ee4978ec280e0156","type":"text","text":"# Lottery Scheduling\n\nAlgoritmo non-deterministico che assegna dei \"biglietti della lotteria\" ai processi per poi estrarre un \"vincitore\" a ogni scadenza del timer. Più biglietti ai processi brevi, meno ai processi lunghi (una sorta di simulazione di SJF). A ogni processo viene dato almeno un biglietto (virtualmente per evitare la starvation).","x":-9409,"y":1801,"width":559,"height":250,"color":"4"},
		{"id":"c948ce6320acafbe","type":"file","file":"Processi/Sincronizzazione Processi (Scheduler CPU)/LotterySimplified.png","x":-9409,"y":2155,"width":559,"height":233},
		{"id":"a1adbe9bb664a9c2","type":"file","file":"processiV.txt","x":-3560,"y":1320,"width":400,"height":421,"color":"4"},
		{"id":"50883272249f2785","type":"text","text":"# Creazione Processi\n\nAggiunte: Windows ha una syscall, spawn() che unisce le syscall fork() e exec() di Unix.\n\nPer specificare quale figlio aspettare c'è la syscall waitpid(pid_t pid, int \\*status, int options).\n\n\n\n","x":-3140,"y":1320,"width":420,"height":421,"color":"4"},
		{"id":"da8d7ccc61fb288f","type":"text","text":"# Useful Definitions\n• Arrival Time: time at which the process arrives in the ready queue\n• Completion Time: time at which the process completes its execution\n• Burst Time: time required by a process for CPU execution\n• Turnaround Time: time difference between completion and arrival time\n• Waiting Time: time difference between turnaround time and burst time","x":-3560,"y":2241,"width":840,"height":280,"color":"1"},
		{"id":"cffda0fb3a359471","type":"text","text":"# Implementazione generale\n\nDecoupling policy (*what* will be done) logic from the underlying mechanism (*how* to do it) is a general design principle in computer science, as it improves system's\n\t• flexibility: addition and modification of policies can be easily supported\n\t• reusability: existing mechanisms can be reused for implementing new policies\n\t• stability: adding a new policy doesn't necessarily destabilize the system\nPolicy changes can be easily adjusted without re-writing the code.\n\nEarly OSs developed in assembly language,\n\t• PRO - direct control over the HW (high efficiency)\n\t• CON - bound to a specific HW (low portability)\nToday, a mixture of languages:\n\t• Lowest levels in assembly\n\t• Main body in C\n\t• Systems programs in C, C++, scripting languages like PERL, Python, etc.","x":2415,"y":744,"width":1111,"height":448,"color":"1"},
		{"id":"6bc46856fa34b1e2","type":"text","text":"# So what?\n\nMonolithic vs. Microkernel: Hybrid Trade-off\n• Try to get the best out of both approaches\n• combining multiple approaches to address performance, security, usability needs\n• Linux and Solaris: monolithic + LKMs (i.e., modular monolithic)\n• Windows NT: mostly monolithic + microkernel for different subsystems\n• Apple Mac OS X: monolithic (BSD UNIX) + microkernel (Mach) + LKMs","x":4375,"y":744,"width":1111,"height":448,"color":"1"},
		{"id":"50134cc52be508aa","type":"file","file":"OS_Design.pdf","x":3747,"y":838,"width":420,"height":260,"color":"1"},
		{"id":"c02fca4457eea4a1","type":"text","text":"# Design","x":1850,"y":938,"width":250,"height":60,"color":"6"},
		{"id":"4a9e0af6fa1f8472","type":"text","text":"# Sincronizzazione Thread","x":-175,"y":2689,"width":431,"height":69,"color":"6"},
		{"id":"10e69b68374e69a4","type":"text","text":"### In C++\n\n\tClass Semaphore\n\t{\n\t\tpublic void wait(Thread t);\n\t\tpublic void signal();\n\t\tprivate int value;\n\t\tprivate int guard;\n\t\tprivate Queue q;\n\n\t\tSemaphore(int val)\n\t\t {\n\t\t\t// initialize semaphore\n\t\t\t// with val and empty queue\n\t\t\tthis.value = val;\n\t\t\tthis.q = null;\n\t\t}\n\t}\n\n\n\tpublic void wait(Thread t)\n\t{\n\t\twhile(test&set(this.guard) == 1)\n\t\t{\n\t\t\t// while busy do nothing\n\t\t}\n\t\n\t\tthis.value -= 1;\n\t\tif(this.value < 0)\n\t\t{\n\t\t\tq.push(t);\n\t\t\tt.sleep_and_reset_guard_to_0();\n\t\t}\n\t\telse\n\t\t{\n\t\t\tthis.guard = 0;\n\t\t}\n\t}\n\n\tpublic void signal()\n\t {\n\t\twhile(test&set(this.guard) == 1)\n\t\t{\n\t\t// while busy do nothing\n\t\t}\n\t\n\t\tthis.value += 1;\n\t\tif(!q.isEmpty())\n\t\t {\n\t\t\t // this.value <= 0\n\t\t\tt = q.pop();\n\t\t\tpush_onto_ready_queue(t);\n\t\t}\n\t\tthis.guard = 0;\n\t\t}","x":536,"y":3203,"width":484,"height":320,"color":"1"},
		{"id":"0bac8ddd0cc0ea48","type":"text","text":"# Livello base - Lock\n\nImmagina il lock come un lasciapassare, un oggetto unico che può avere solo una persona per volta. Chi ha il lock può entrare nelle sezioni critiche, gli altri aspettano. Quando costui finisce i suoi doveri nella sezione critica libera il lock, che viene assegnato a uno dei processi/thread in attesa. Viene implementato tramite due primitive:\n- Lock.acquire() --> si mette in attesa che il lock si liberi, quindi lo prende per sè;\n- Lock.release() --> libera il lock e sveglia uno dei thread nella pool di attesa creata da acquire().\n\nNell'esempio di Bob e Carla (che non so perché non si chiami Alice, vbb) il codice diventa simmetrico:\n\n\tLock.acquire()\n\tif(!milk):\n\t\tbuy_milk()\n\tLock.release()\n\nA questo punto si rende necessario rendere le primitive istruzioni atomiche, ovvero non interrompibili da un context-switch dello scheduler.","x":-399,"y":2983,"width":880,"height":540,"color":"4"},
		{"id":"1dad249a05ab28b1","type":"text","text":"### In C++\n\tClass Lock\n\t{\n\t\tpublic void acquire(Thread t);\n\t\tpublic void release();\n\t\tprivate int value; // 0=FREE, 1=BUSY\n\t\tprivate Queue q;\n\t\tLock()\n\t\t{\n\t\t\tthis.value = 0; // Lock is initially free\n\t\t\tthis.q = null;\n\t\t}\n\t}\n\n\tpublic void acquire(Thread t)\n\t{\n\t\tdisable_interrupts();\n\t\tif(this.value) { // lock is held by someone\n\t\tq.push(t); // add t to waiting queue\n\t\tt.sleep(); // put t to sleep\n\t\t}\n\t\telse this.value = 1;\n\t\tenable_interrupts();\n\t}\n\n\tpublic void release()\n\t{\n\t\tdisable_interrupts();\n\t\tif(!q.is_empty())\n\t\t{\n\t\t\tt = q.pop(); // extract a waiting thread from q\n\t\t\tpush_onto_ready_queue(t); // put t on ready queue\n\t\t}\n\t\telse this.value = 0;\n\t\tenable_interrupts();\n\t}\n\n#### Con test&set\n\t// Inizializza la variabile condivisa a 0 (non acquisito)\n\tsharedVariable = 0;\n\n\t// Acquisizione della lock\n\twhile (test_and_set(&sharedVariable) == 1) {\n\t// Attendi finché la lock è acquisita da un altro\n\t}\n\n\t// Sezione critica\n\n\t// Rilascio della lock\n\tsharedVariable = 0;\n","x":1060,"y":3203,"width":476,"height":320,"color":"1"},
		{"id":"6b26542e75b5a010","type":"text","text":"## Implementazione di un lock\n\n#### disable_interrupts()\nLa CPU in linea di principio può andare in context-switch in qualsiasi momento. O meglio, i casi sono due:\n- Il running thread cede volontariamente la CPU eseguendo, ad esempio, una syscall per operazioni di I/O. In questo caso è sufficiente che il codice del thread non preveda una cosa del genere quando entra in una sezione critica;\n- C'è un interrupt esterno che blocca brutalmente l'esecuzione indipendentemente da cosa vorrebbe fare il thread.\n\nIl lock si basa sulla possibilità dell'HW di ritardare gli interrupt fino al termine delle operazioni critiche. Ci sono però diversi problemi in una simile implementazione (vedi sotto i dettagli), come la perdita di responsività del SO (che smette di essere reattivo nei confronti di richieste anche urgenti), una sorta di \"Inversione di priorità\", per cui un processo a bassa priorità che fa un lock con disable_interrupts() può bloccare processi a priorità maggiore, e soprattutto tutto questo discorso incontra grossi problemi se ho più core. Blocco gli interrupt per tutti? E se stanno eseguendo altri thread che contemporaneamente chiedono il lock? Si capisce che il lock è una primitiva di sincronizzazione superata e che ne esistono di migliori.\n\n#### test&set\nUn modo alternativo per implementare un lock è sfruttare le istruzioni atomiche come test&set, che legge un valore e scrive 1 in memoria. I dettagli implementativi sono sotto.","x":536,"y":2582,"width":1000,"height":581,"color":"4"},
		{"id":"206e2718cacccb39","type":"text","text":"## Race Condition\n\nSituazione in cui il risultato di più thread dipende dal loro ordine di esecuzione (ovviamente da evitare)","x":1863,"y":3263,"width":319,"height":200,"color":"4"},
		{"id":"adc54afbae0740e4","type":"text","text":"## Issues\n\n2 main problems with disabling interrupts:\n- overhead as it requires invoking the kernel\n- unfeasible with mulitprocessor architectures\n\n2 main problems with atomic instructions:\n- busy waiting\n- unfairness as there is no queue where threads wait for the lock to be released\n\n\nNon si può eliminare il busy waiting, ma si può ottimizzare rendendolo indipendente dalla durata della sezione critica (?)\n\nLe slides qua sono particolarmente oscure e non si riesce a venirne a capo cercando online perché non è chiaro _cosa_ vogliano comunicarmi.","x":1641,"y":2582,"width":762,"height":581,"color":"1"},
		{"id":"a8d94719750798b3","type":"file","file":"Processi/Threads/thread.png","x":-840,"y":1535,"width":400,"height":256},
		{"id":"ccea465ee5a66f66","type":"text","text":"# Processi","x":-2248,"y":1425,"width":329,"height":50,"color":"6"},
		{"id":"409f9cd96c788b91","type":"file","file":"processi.txt","x":-2283,"y":1535,"width":400,"height":180,"color":"4"},
		{"id":"d1b1da8e14a89c26","type":"text","text":"# Livello intermedio - Semaforo (estensione del lock)\n\nImmaginalo come un semaforo di un parcheggio coperto. Ci sono N posti liberi (valore di inizializzazione del semaforo) e ogni macchina quando accede decrementa il contatore di posti. Se il counter è zero o negativo le macchine che vogliono entrare devono aspettare che ne esca una. Tutte queste operazioni sono svolte dalla funzione wait() (anche detta P o Down, di decremento, che in pratica controlla se il numero è positivo, se non lo è aspetta, se lo è lo decrementa di 1). Quando una macchina esce, segnala che si è liberato un posto, chiamando appunto la funzione signal() (anche detta V o Up, che incrementa).\n\nA livello implementativo puoi pensarlo come una classe contenente il contatore e le implementazioni delle funzioni wait e signal, oltre a una struttura che gestisce la coda dei processi in attesa.\n\nSe il semaforo può assumere solo valori 0 e 1 si ricade nel caso di lock (ma in questo caso viene chiamato **mutex**... perché sì. Credo stia tipo per \"mutually exclusive\").\n\nAltrimenti, posso inizializzare a zero e aspettare che qualcosa mi dia il verde, tipo waitpid().","x":-399,"y":3583,"width":880,"height":400,"color":"4"},
		{"id":"ec02cf92e35c5eb6","type":"text","text":"# Livello avanzato - Monitor (mutex + metodi)\nUn monitor è una \"scatola\" (quinidi tipicamente implementata con una classe) associata a una risorsa condivisa. Non è ad accesso esclusivo ma ad esecuzione esclusiva, ovvero solo il thread che detiene il lock del monitor può eseguire i metodi (funzioni) del monitor sulla risorsa a lui associata. All'interno di questa scatola sono implementate (oltre ai metodi) due funzioni di sincronizzazione interna, wait e signal. Nel caso in cui il thread detentore del lock (che chiamiamo A) abbia necessità di aspettare prima di eseguire quello che deve eseguire (tramite i metodi del monitor) può chiamare la funzione wait sul semaforo di sincronizzazione interna. Questa funzione rilascia temporaneamente il lock del monitor e mette il thread A in una queue di attesa interna. Un altro thread esterno (che chiamiamo B, potenzialmente in una queue esterna) può a questo punto prendere il lock ed eseguire le proprie operazioni e uscire, passando il lock a un altro thread C. Questo gioco va avanti così finché uno di questi thread, diciamo D, invoca una signal. Questo fa sì che il thread A si \"risvegli\" tornando ad essere un candidato a prendere il lock. Quando D esce e rilascia il lock, lo prende uno dei processi \"svegli\" in una delle code (interna o esterna). Quando riprende il lock, A esegue le sue operazioni ed esce rilasciandolo nuovamente. Quale coda ha la priorità è un dettaglio implementativo.","x":-399,"y":4063,"width":880,"height":440,"color":"4"},
		{"id":"5ebb9d2dabcdc329","type":"text","text":"### Esempio (scheduling constraints con semafori)\nDue thread paralleli possono essere\n\n\tstudy()\n\tS.signal()\ne\n\n\tS.wait()\n\ttake_exam()","x":536,"y":3583,"width":484,"height":400,"color":"3"},
		{"id":"2c40139566bcddb2","type":"text","text":"### Aggiunte varie ed eventuali sui Monitor\n\n- Esiste una terza primitiva, broadcast(), che è una signal per tutti i processi in attesa.\n- A rigore quello dentro al monitor non è un semaforo. Le differenze sono infatti che\n\t- La wait() nel semaforo blocca il primo thread in queue e può essere chiamato in qualsiasi momento (perché in pratica decrementa un contatore), mentre nel monitor il thread deve star eseguendo un metodo del monitor (in pratica blocca il thread e rilascia il lock);\n\t- La signal() nel semaforo incrementa il contatore anche se non ci sono thread attualmente in attesa, permettendo a un futuro thread di entrare. Nel monitor, se non c'è alcun processo in queue il segnale viene perso.\n- Esistono due modi di implementare la signal(), detti Mesa e Hoare. Pare che la prima sia di utilizzo più comune e la seconda utilizzata a titolo di esempio nei libri. Non riporto dettagli implementativi.\n- Problema tipico da risolvere con un monitor: Readers-Writers.","x":536,"y":4063,"width":1000,"height":440,"color":"4"},
		{"id":"b18a396618049aa5","type":"file","file":"Processi/Threads/parallelism.png","x":-274,"y":1120,"width":629,"height":170},
		{"id":"fad3582cc9b8fe57","type":"text","text":"# Dove è necessario sincronizzare i thread?\n\nIl conflitto per le risorse può avvenire su due livelli:\n- Process Contention Scope (PCS): più thread utente dello stesso processo (NON mappati in altrettanti thread kernel) dovrebbero essere sincronizzati dal processo;\n- System Contention Scope (SCS): più thread kernel devono essere sincronizzati dallo scheduler del SO.\n\nDue cose da notare:\n- è il kernel a dover notificare al processo se c'è conflitto per le risorse tra i suoi thread. Questo viene fatto con le UPCALL, una sorta di \"inverso\" delle syscall (ovvero kernel --> user). Le librerie che gestiscono i thread hanno degli upcall handler;\n-  Il processo può in linea di principio non sincronizzare i propri thread. Questo non crea errori a livello di integrità della macchina (perché poi diventano thread kernel sincronizzati dal SO) ma a livello di correttezza del codice (perché le modifiche a memoria possono non risultare ordinate correttamente).\n\n","x":-1678,"y":2524,"width":1111,"height":400,"color":"4"},
		{"id":"933c1f33f83329d3","type":"text","text":"# Come si implementa la sincronizzazione?\n\nIn generale si possono individuare delle SEZIONI CRITICHE, come ad esempio zone di memoria condivisa, sulle quali è fondamentale che più processi/thread non operino simultaneamente per evitare incongruenze. La soluzione è BLOCCARE l'accesso alla sezione critica nel momento in cui un thread vi entra, per poi liberarlo quando ne esce.\n\nUn esempio può essere il seguente. Siamo a casa dei thread Bob e Carla, la sezione critica è andare a comprare il latte se non ce n'è. Assumendo che le singole istruzioni siano atomiche (ovvero non interrompibili), una soluzione \"naive\" può essere quella di sinistra, che rispetta i criteri di:\n- Mutual Exclusion: solo un thread alla volta può entrare nella sezione critica, ovvero solo uno tra Bob e Carla compra il latte se necessario;\n- Liveness: se non c'è alcun thread in seione critica, tutti quelli che vogliono entrarci devono poterlo fare, ovvero almeno uno tra Bob e Carla deve poter comprare il latte (ovvero, non permettere a nessuno di entrare in una zona critica su cui c'è conflitto è una soluzione ma non è una buona soluzione);\n- Bounded Waiting: l'attesa per l'ingresso nella sezione critica non deve essere indefinita, ovvero sia Bob che Carla, a seconda dello scheduling dei rispettivi thread, hanno la possibilità di andare a comprare il latte.\n\nTuttavia si può fare di meglio. Posto di avere un'implementazione HW che lo consente, esistono delle primitive atomiche ad-hoc per la sincronizzazione.","x":-1678,"y":2984,"width":1111,"height":540,"color":"4"},
		{"id":"004837f0a7396bbf","type":"file","file":"Processi/Threads/naive_sync.png","x":-2626,"y":2889,"width":846,"height":400},
		{"id":"45cd529f8bc60a75","type":"text","text":"## Problemi di questa soluzione\nPosto che questa soluzione funziona, ha diverse criticità.\n- Difficile verificare l'effettivo funzionamento;\n- Asimmetrica. Se fossero più di due thread la complessità aumenterebbe molto;\n- Bob va in busy waiting ogni volta che gli viene data la CPU.","x":-2620,"y":3324,"width":840,"height":200,"color":"4"},
		{"id":"b21a9f5130d5c590","type":"text","text":"# Threads","x":-1300,"y":1633,"width":250,"height":60,"color":"6"},
		{"id":"2cbd9476c35281f6","type":"file","file":"Sicurezza e syscall/valid_address.png","x":-5524,"y":-2400,"width":388,"height":387},
		{"id":"9aa74fda3231a196","type":"text","text":"# Quindi è impossibile eseguire da utente le istruzioni privilegiate?\n\nNo, non è impossibile. Basta chiederlo gentilmente tramite le SYSTEM CALL, e il SO valuterà se è il caso di eseguirle o meno.","x":-5886,"y":-1045,"width":1111,"height":105,"color":"4"},
		{"id":"3b4c354f921c302c","type":"text","text":"# Protezione della Memoria\n\nPer proteggere la memoria, a ogni programma viene assegnato un range di indirizzi fisici.\n\nUscire dai limiiti significa generare un interrupt di tipo SIGSEGV (Segmentation Fault).","x":-5886,"y":-1940,"width":1111,"height":387,"color":"4"},
		{"id":"c5128c9a62b77d1c","type":"text","text":"# Istruzioni privilegiate (Kernel Mode)\n\nCi sono istruzioni che non possono essere lasciate all'utente. Esempi possono essere HLT (blocca il processore in attesa di un interrupt) o INT (genera un interrupt). In User Mode è impedito di accedere direttamente all'I/O o alla RAM, passare in Kernel Mode, ...\n\nC'è un singolo bit protetto nella CPU che dice se sta eseguendo un'operazione in modalità Kernel (0) o User (1).\n\nL'HW deve pertanto supportare almeno queste due modalità, ma sono implementabili gerarchie di privilegi più fini.\n\nQualsiasi tipo di evento che fa passare la CPU in Kernel Mode è detto TRAP.","x":-5886,"y":-1493,"width":1111,"height":387,"color":"4"},
		{"id":"b763de7850a80c53","type":"file","file":"Sicurezza e syscall/privilege.png","x":-6526,"y":-1940,"width":523,"height":387},
		{"id":"307924e88efadd9d","type":"text","text":"# Ci sono diverse categorie di syscall...\n\n- File Management\n\t- Include create file, delete file, open, close, read, write, reposition, get file attributes, and set file attributes\n\t- These operations may also be supported for directories as well as ordinary files\n\t- The actual directory structure may be implemented using ordinary files on the file system, or through other means\n\n- Process Control\n\t- Include end, abort, load, execute, create process, terminate process, get/set process attributes, wait for time or event, signal event, and allocate and free memory\n\t- When one process pauses or stops, then another must be launched or resumed\n\t- When processes stop abnormally it may be necessary to provide core dumps and/or other diagnostic or recovery tools\n\nDevice Management\n• Include request device, release device, read, write, reposition, get/set device attributes, and logically attach or detach devices\n• Devices may be physical (e.g., disk drives), or virtual/abstract (e.g., files, partitions, and RAM disks)\n• Some systems represent devices as special files in the file system, so that accessing the \"file\" calls upon the appropriate OS device driver (e.g., the /dev directory on any UNIX system)\n\nInformation Maintenance\n• Include calls to get/set the time, date, system data, and process, file, or device attributes\n• Systems may also provide the ability to dump memory at any time\n• Single step programs pausing execution after each instruction, and tracing the operation of programs (debugging\n\nCommunication\n• Include create/delete communication connection, send/receive messages, transfer status information, and attach/detach remote devices\n• 2 models of communication:\n\nMessage passing\nShared memory","x":-6860,"y":-1045,"width":857,"height":1048,"color":"1"},
		{"id":"7f02462535d305da","type":"file","file":"Sicurezza e syscall/ItsATrap.png","x":-6860,"y":-1493,"width":857,"height":387},
		{"id":"99c05cd2bb5fb531","type":"file","file":"Sicurezza e syscall/syscall_categories.png","x":-7640,"y":-1045,"width":698,"height":1048},
		{"id":"558ba900733523b5","type":"text","text":"# SYSCALL\n\nSono il \"cuscinetto\" tra User e Kernel Mode. \n\nTipicamente scritte in C/C++ e fornite da librerie API scritte direttamente dagli sviluppatori del SO. Questo significa che in realtà User chiama una funzione WRAPPER con dentro, ad esempio, la *read()*, e i dettagli implementativi sono nascosti dalla API. Quando viene chiamata la vera syscall (INT $0x80 è la chiamata alle syscall in Assembly)e la palla passa al Kernel, questo salva in registri deditati lo stato della User Mode e usa una sua funzione sys_*read*() che esegue le vere operazioni.\n\nAl termine della syscall, usa una versione privilegiata della ret (IRET) per tornare alla User Mode.\n\nSi possono passare i parametri tramite registri, tabelle o direttamente pushando in stack.","x":-5886,"y":-320,"width":1111,"height":323,"color":"4"},
		{"id":"013481a47473bf04","type":"file","file":"Sicurezza e syscall/syscall.png","x":-5886,"y":-900,"width":1111,"height":523},
		{"id":"1c983ed53f331726","type":"text","text":"### Shared Memory\n• Faster once it is set up, as no system calls are needed\n• More complicated to set up, and doesn't work as well across multiple computers\n• Preferable when (large amount of) information must be shared on the same computer","x":-9120,"y":364,"width":698,"height":254,"color":"1"},
		{"id":"e2aefc482d1e7497","type":"text","text":"### Message Passing\n• Slower as it requires system calls for every message transfer\n• Simpler to set up and works well across multiple computers\n• Preferable when the amount and/or frequency of data transfers is small, or when multiple computers are involved\n• Must support at least system calls for sending and receiving messages\n• A communication link must be established between the cooperating processes before messages can be sent.\n#### Communication (i.e., naming)\nSi può comunicare in due modi:\n\t- Comunicazione diretta: il mittente deve sapere il nome del ricevitore. Per una comunicazione simmetrice, deve essere vero anche il contrario. A ogni coppia mittente-ricevitore corrisponde un link;\n\t-  Comunicazione indiretta: usa porte o mailbox condivise. Più processi possono condividere le stesse porte. Il SO deve fornire syscall per creare ed eliminare le mailbox, così come per inviare e ricevere messaggi da esse.\n\n#### Sincronizzazione e Buffering\nSi possono presentare diverse situazioni.\n\t- Zero Capacity: Non esiste una coda di messaggi, i mittenti devono aspettare che il destinatario accetti il messaggio precedente;\n\t- Bounded Capacity: La coda ha una capienza finita, i mittenti si fermano solo se la coda è piena;\n\t- Unbounded Capacity: La coda ha una capienza virtualmente infinita, i mittenti non vanno mai in blocco forzato.","x":-9120,"y":-1045,"width":698,"height":749,"color":"2"},
		{"id":"3cbd143423e3f10a","type":"text","text":"# Comunicazione\n\nProcesses can be either independent or cooperating\n• Independent processes - operate concurrently on a system and can neither affect or be affected by other processes;\n• Cooperating processes - can affect or be affected by other processes in order to achieve a common task.\n\nPerché?\n\n• Information sharing - There may be several processes which need access to the same file (e.g., pipelines)\n• Computation speedup - A problem can be solved faster if it can be broken down into sub-tasks to be solved simultaneously\n• Modularity - The most efficient architecture may be to break a system down into cooperating modules\n• Convenience - Even a single user may be multi-tasking, such as editing,\ncompiling, printing, and running the same code in different windows\n\nCome?\n\n","x":-9120,"y":-241,"width":698,"height":545,"color":"2"},
		{"id":"ba2b6213e4637219","type":"text","text":"Molte dei processi di scheduling presentati sotto sono basati sull'assunzione che NON avvenga comunicazione tra processi.","x":-9750,"y":-720,"width":499,"height":100,"color":"4"},
		{"id":"a2ca84c1f075532c","type":"file","file":"Sicurezza e syscall/syscall_esempi.png","x":-8325,"y":-987,"width":583,"height":633},
		{"id":"2bd5a1b48bac530b","type":"file","file":"Sicurezza e syscall/syscall_communication_modes.png","x":-8325,"y":-241,"width":583,"height":859},
		{"id":"7c939ee2ebe1207c","type":"file","file":"Processi/ICP.png","x":-9750,"y":-242,"width":499,"height":860},
		{"id":"06528774c7a17e8f","type":"text","text":"# Sicurezza","x":-4384,"y":-189,"width":250,"height":61,"color":"6"},
		{"id":"0f5be1b419c22070","type":"file","file":"SO.txt","x":-4459,"y":84,"width":400,"height":400,"color":"4"},
		{"id":"9c55c12867f0cfe8","type":"text","text":"# Estensione RAG\n\nLa definizione di Safe State porta alla definizione di un terzo tipo di freccia, detta **claim**.\n\nIn pratica una freccia di claim $(t_i, r_j)$ indica che il processo $t_i$ *potrebbe* in futuro richiedere la risorsa $r_j$.\n\nSegue che soddisfare una claim significa rendere la freccia tratteggiata $(t_i, r_j)$ una freccia di assegnazione $(r_j, t_i)$.\n\nSe nell'esempio sotto soddisfo $(t_4, r_2)$ creo una freccia verde $(r_2, t_4)$ generando potenzialmente un ciclo se $(t_3, r_2)$ diventa una freccia rossa di richiesta $\\Rightarrow$ Unsafe State","x":-3160,"y":4422,"width":445,"height":460,"color":"4"},
		{"id":"b38a5df100f9850b","type":"text","text":"# [Algoritmo del Banchiere](https://it.wikipedia.org/wiki/Algoritmo_del_banchiere)\n\nAlgoritmo che decide se assegnare o meno le risorse ai processi.\n\nI thread devono preventivamente dichiarare il proprio $m_i$. A questo punto i criteri per l'assegnazione sono sostanzialmente tre:\npiù\n- Le risorse devono essere disponibili;\n- La richiesta deve essere coerente con il numero massimo di risorse potenzialmente necessarie al thread (e.g. se un thread dichiara $m_i = 8$ e utilizza $c_i = 6$, una richiesta di ulteriori $4$ risorse non è coerente);\n- A seguito dell'assegnazione il sistema deve essere ancora in un Safe State.\n\nSe anche una sola delle condizioni non è verificata, la richiesta viene rifiutata.\n\nWikipedia lo spiega meglio di me, link nel titolo.","x":-2619,"y":4580,"width":839,"height":740,"color":"4"},
		{"id":"8c7076684bac10a2","type":"text","text":"\n# Condizioni di Deadlock\n\nPossono verificarsi dei deadlock se l'ambiente consente le seguenti situazioni:\n\n- Mutual Exclusion - Una data risorsa non può essere eseguita da più thread contemporaneamente. Questo è necessario se si pensa alle sezioni critiche e ovvio se si pensa, ad esempio, alla modalità schermo intero;\n- Hold-and-Wait - I processi possono bloccare le risorse e devono necessariamente aspettare una signal() per rilasciarle;\n- Circular Waiting - Si possono verificare situazioni in cui in un set di n threads l'i-esimo aspetta una signal() dall'(i+1)%n-esimo. \n\nPerchè si concretizzi una situazione di deadlock è necessario che si verifichino contemporaneamente tutte e 4 le condizioni.\nSegue che per **prevenire** un deadlock è sufficiente che anche solo una di queste non sia verificata.\n\nPer individuare un deadlock è necessario un algoritmo di scan su grafo orientato G = (V, E), detto Resource Allocation Graph (RAG) per trovare i loop. Se V è il numero di vertici ed E il numero di frecce, un algoritmo di ricerca in profondità (DFS, *depth-first search*) richiede un tempo di ordine $|V|+|E|$. **Qui le slides dicono che il problema è $O(|V|^2)$ perché $|E| = O(|V|^2)$. Non trovo alcuna corrispondenza, se non Wikipedia che riporta una *complessità* $O(n^2)$ dove n è il numero di processi**.\n\nUn modo alternativo per la prevenzione dei deadlock consiste nel definire degli stati sicuri (**Safe States**) nei quali non si verificano le condizioni sopracitate.","x":-1678,"y":4013,"width":1111,"height":493,"color":"4"},
		{"id":"28ef98e44e010a54","type":"text","text":"# Safe State\n\nUno *Stato* (inteso come insieme di thread attivi) è definito *Sicuro* se esiste almeno una sequenza ordinata dei thread tale che **per ogni thread** è rispettata la condizione\n\n$$\nm_i - c_i \\leq R - C + \\sum_{j < i} c_j\n$$\ndove\n\n- $m_i$ è il massimo numero di risorse che può richiedere l'i-esimo thread;\n- $c_i$ è il numero di risorse attualmente assegnate all'i-esimo thread;\n- $R$ è il numero totale di risorse;\n- $C = \\sum_i^n c_i$ è il numero complessivo di risorse attualmente assegnate ai thread.\n\nSegue naturalmente che\n\n- $R - C$ è il numero di risorse disponibili (non assegnate ad alcun thread);\n- $m_i - c_i$ è il massimo numero di risorse che l'i-esimo thread *potrebbe* ancora richiedere;\n- $\\sum_{j < i} c_j$ è il numero di risorse assegnate a tutti i thread precedenti all'i-esimo.\n\nL'idea è che se il thread $i$-esimo può richiedere tutte le risorse potenzialmente necessarie, questo potrà terminare l'esecuzione per primo e le rilascerà a disposizione del thread $(i+1)$-esimo. Si noti che\n\n- Ogni sequenza che rispetta la condizione di Safe State è un possibile ordine di esecuzione dei thread;\n- Un furbo test preliminare prima di testare tutte le sequenze può essere $m_i \\leq R$ $\\forall i$. Se anche solo un thread potrebbe richiedere più risorse di quelle disponibili lo stato è sicuramente unsafe;\n- Essendo una sequenza ordinata, per $N$ threads è in linea di principio necessario testare $N!$ sequenze;\n- L'algoritmo che generalizza questi $N!$ test a $M$ diversi tipi di risorse è detto Algoritmo del Banchiere (Banker's Algorithm).","x":-1678,"y":4580,"width":1111,"height":740,"color":"4"},
		{"id":"8d0dc0d08efb8898","type":"file","file":"Processi/Deadlock/Potential Deadlock.png","x":-2619,"y":4066,"width":839,"height":356},
		{"id":"26cfad6010ff7969","type":"text","text":"# Cos'è un Deadlock\n\nUn deadlock è una situazione in cui risulta impossibile sbloccare una o più risorse tramite funzioni signal(), verosimilmente perché l'esecuzione della signal(Risorsa1) ha come requisito la Risorsa1 stessa o perché le condizioni di sblocco entrano in un loop che non si può più rompere.\n\nIntuitively, a condition where two or more threads are waiting for an event that can only be generated by the very same threads\nNot to be confused with Starvation, which occurs when a thread waits indefinitely for some resource but other threads are actually making progress using that resource. The main difference with deadlock is that the system is not completely stuck!","x":-1678,"y":3683,"width":1111,"height":261,"color":"6"},
		{"id":"61fad2ad255cf82a","type":"file","file":"Processi/Deadlock/Deadlock 1.png","x":-2620,"y":3683,"width":403,"height":261},
		{"id":"27e4fdde4c9ad72d","type":"file","file":"Processi/Deadlock/Deadlock 2.png","x":-2179,"y":3683,"width":399,"height":261},
		{"id":"e00a97cccf420735","type":"text","text":"# Resource Allocation Graph\n\nMetodo grafico per visualizzare le dinamiche tra le risorse che vengono assegnate e i thread che le richiedono. Ci sono due tipi di vertici (thread e risorse) e due tipi di frecce\n\n- thread --> risorsa (Richiesta)\n- risorsa --> thread (Assegnazione)\n\nSe una risorsa è libera (cioè non assegnata ad alcun thread, o il thread a cui era assegnata termina l'esecuzione) questa può andare ai thread che la richiedono. Un thread che fa richiesta di una risorsa ne ha bisogno per completare l'esecuzione e liberare tutte le risorse che sta bloccando.\n\nA questo punto è ovvio che condizione necessaria perché si verifichi un deadlock è che in questo grafico vi sia un loop. Non è sufficiente, perché è possibile che ogni risorsa possa essere assegnata contemporaneamente a più thread, motivo per cui in genere al posto di scrivere solo r3 si mettono anche dei pallini a simboleggiare la molteplicità della risorsa, che qui non c'è...","x":-3160,"y":3683,"width":445,"height":659,"color":"4"},
		{"id":"264ec2af514b533d","type":"text","text":"Sono indeciso se questa parte è quasi inutile e overcomplicata o da rivedere","x":1420,"y":3756,"width":642,"height":55},
		{"id":"bd7a77b4a999548f","type":"text","text":"Serve a qualcosa??","x":5667,"y":932,"width":250,"height":60},
		{"id":"346edb2cd343ae50","type":"text","text":"# Rappresentazione virtuale della Memoria fisica\n\nQui tende ad esserci molta confusione. Provo a fare ordine. Ragioniamo a 32-bit e 4Kb di pagina.\n\nLa memoria fisica ha una capacità limite di $2^{32}$ byte $= 4$ Gigabyte, banalmente perché non posso referenziare più di quello con un indirizzo fisico a $32$ bit.\n\nAnche la memoria virtuale, con la sua Page Table (**PT**), può referenziare al più $4$ Gigabyte, perché anche gli indirizzi virtuali possono essere al massimo di $32$ bit.\n\nA questo punto però mi ricordo che esiste la paginazione. Questo è quello che succede (credo):\n\n1. Ho un indirizzo virtuale, uso i primi $20$ bit per scorrere la PT del processo per trovare il frame a cui è associata;\n\n2. Tale frame è indicizzato da un numero a $32$ bit, e può trovarsi sia in memoria fisica che in swap (come pure non essere allocato). Questa informazione è contenuta in una tabella di corrispondenza del SO (e suppongo della MMU) che associa $2^32$ frame a tre tipi di dato:\n\n\t- Uno dei possibili $2^{20}$ indirizzi per i frame disponibili in memoria fisica, se è allocato attualmente in RAM;\n\t- L'indirizzo nello spazio di swap su disco, se non è allocato in RAM ma lo è su disco;\n\t- Un qualche tipo di *NULL* se non è allocato;\n\n3. Se il frame è in memoria fisica tutto bene, uso gli ultimi $12$ bit dell'indirizzo virtuale per trovare l'offest leggere il dato;\n\n4. Se è in swap, sostituisco quel frame con uno in RAM, poi procedo col punto 3;\n\n5. Se non è allocato SIGSEGV.\n\nA questo punto è chiaro che il *limite teorico della memoria virtuale*, ovvero la quantità di memoria virtuale complessiva gestita dal SO tra RAM e disco, è $2^{32}\\cdot sizeof(page)$ byte, ovvero $2^{44}$ byte $= 16$ Terabyte.","x":-259,"y":-1299,"width":860,"height":700,"color":"4"},
		{"id":"7d169a16a8cca630","type":"file","file":"Memoria/Compaction/FullCompaction.png","x":-259,"y":-2259,"width":860,"height":402},
		{"id":"58f52445ff3fb61e","type":"file","file":"Memoria/Compaction/PartialCompaction.png","x":-259,"y":-1823,"width":860,"height":404},
		{"id":"69f3dd73ee95ff32","type":"text","text":"# (1) Alcune aggiunte a questo sacro .txt\n\n#### MMU\n\nSi trova nel processore. Usa due registri, che forniscono gli indirizzi limite per il processo in analisi. Si chiamano *base* e *limit*. Ogni volta che si genera un indirizzo di memoria in User Mode, la CPU deve controllare che questo sia nel range $[base, base+limit]$ per quel dato programma\n\nLo scorrimento della memoria per mappare i buchi tra i processi è $O(N)$ con $N$ numero di buchi. Può diventare $O(log N)$ se uso un Binary Search Tree (BST) tenendo traccia dei buchi (e quindi non doverli cercare ogni volta).\n\nLe simulazioni dicono che *first fit* e *best fit* sono gli algoritmi più efficienti, il primo è naturalmente più veloce.\nSimulations show that for every 2N allocated blocks, N are lost due to external fragmentation. 1/3 of memory space is wasted on average.\nCi sta una pratica chiamata *Compaction* che appunto compatta i processi per ridurre la frammentazione esterna.\n\n#### Swapping\n\nI processi devono stare in RAM solo quando vengono eseguiti, altrimenti posso fiondarli in SSD e riprenderli quando necessario (swapping).\n- Se l'Address Binding è dinamico posso rilocare come voglio. Prima dello swapping faccio Compaction e ottimizzo la frammentazione esterna\n- Se è Static o Absolute devo ricaricare (o ricompilare) il processo nella stessa identica porzione di memoria. Questo significa in pratica che lo swaping è utile solo se c'è un altro processo che può runnare nelle stesse locazioni, e sfruttare quindi gli interrupt dell'altro. In realtà usare lo swapping in questi casi **NON HA ALCUN SENSO**, perché così sovrascrivo continuamente i dati dei processi swappati. (ma infatti perché non lo dici nelle slides??).\n\n#### Paging\n\nIn realtà oggi non si usa lo swapping, ma il paging.\nProcesses spend 90% of their time accessing only 10% of their allocated memory space.\n\nSe la memoria virtuale è indicizzata da $m$ bit (indirizzi virtuali che variano in range $[0, 2^{m-1}]$) e la dimensione della pagina è $2^n$ (ovvero l'offset interno è indicizzato da $n$ bit) il numero di pagine nella memoria virtuale è $2^{m-n}$. A questo punto è chiaro perché i primi $m-n$ bit di un indrizzo indicizzano la pagina, mentre i restanti $n$ si riferiscono all'offset.","x":-1639,"y":-2259,"width":1238,"height":840,"color":"4"},
		{"id":"a809a009a3c7f901","type":"text","text":"## Nota sul paging e sulle architetture\n\nSiamo abituati a ragionare in byte (8-bit). Quindi se dico che la memoria virtuale è $1024$ byte mi aspetto di avere $1024$ *words* indicizzabili da $log(1024) = 10$ bit.\n\nE questo in linea di principio è vero.\n\nSe però uso un'architettura a 32-bit una *word* consta di $4$ byte, quindi nello stesso spazio avrò chiaramente $256$ *words* indicizzabili da $8$ bit.\n\nA livello di indicizzazione di pagina non cambia nulla.\nSe scelgo come size della pagina $16$ byte ho in entrambi i casi $2^{m-n} = 2^{10-4} = 2^6 = 64$ pagine, motivo per cui mi servono sempre i primi $6$ bit dell'indirizzo.\n\nNel secondo caso però i bit restanti sono $2$, contro i $4$ dell'architettura a 8-bit.\n\nIn un moderno sistema a 64-bit ($8$ byte) notiamo che con questi numeri avremmo $128$ *words* indicizzabili da $7$ bit, ovvero in una pagina da $16$ byte entrano solo due *words*. Questo riduce la lunghezza strettamente necessaria dell'indirizzo, ma in pratica verrà comunque gestito come gruppo di $64$ bit, non potendo essere più corto di una *word*.\n\nIn linea di principio, un indirizzo a $64$ bit può indicizzare $2^{64}$ *words* da $64$ bit, ovvero la massima memoria virtuale (e quindi fisica) possibile sarebbe $2^{64} \\cdot 64$ bit, ovvero $2^{66}$ byte $= 2^{26}$ Terabyte = $16 \\cdot 32$ Exabyte","x":-1639,"y":-1299,"width":619,"height":700,"color":"4"},
		{"id":"f3560ddcee0e71de","type":"text","text":"## Nota sulla nota sul paging e sulle architetture (...)\n\nTutto molto bello, ma resta un discorso teorico o comunque non convenzionale a livello implementativo.\n\nIn pratica è necessario (nonché più economico...?) avere la possibilità di referenziare il singolo bit di memoria, motivo per cui a 32-bit si ha uno spazio di memoria virtuale pari a $2^{32}$ byte, ovvero $16$ Gigabyte, e a 64-bit si arriva \"solo\" a $2^{64}$ byte $= 16$ Exabyte.\n\nQueste slides mi fanno perdere tempo...","x":-959,"y":-949,"width":558,"height":350,"color":"4"},
		{"id":"e4716290f3d5b096","type":"file","file":"Memoria/AddressBinding/Traduzione Indirizzi.png","x":-959,"y":-1279,"width":558,"height":266},
		{"id":"19cda58d82f6e368","type":"text","text":"## Pro e Contro dei vari Address Binding\n\n1. **Absolute Code (Compile Time Binding)**:\n\tIn realtà non entra in classifica, è proprio la versione base e non serve nemmeno un SO.\n\t\n1. **Statically Relocatable Code (Load Time Binding)**:\n\tNon posso modificare gli indirizzi in corso d'opera, quindi quando alloco devo mettermi nel caso peggiore e creare quindi frammentazione interna. Inoltre, in questo tipo di allocazione **NON ENTRA IN GIOCO LA MMU**, quindi nessuno gestisce i Segmentation Fault. Segue che da qualsiasi programma posso scegliere di scrivere (ad esempio con una syscall write()) all'indirizzo, compreso quello di un altro processo o del SO. Naturalmente, oggi il SO richiede la *Kernel Mode* per fare una cosa del genere, ma in passato no (tipo MS-DOS).\n\tIl vantaggio? Non serve la MMU, ovvero non serve supporto HW. Che oggi è un vantaggio sostanzialmente inutile, ma alcuni sistemi \"intermedi\" (troppo complessi per fare Absolute Code ma troppo poco per richiedere un HW che offra MMU) la usano.\n\tQuesto in realtà porta ad un altro svantaggio, perché sono sistemi più vulnerabili ad attacchi come *buffer overflow* (overflow di dati rispetto alla memoria assegnata, che vanno a finire in altri punti della memoria creando il caos) o *injection* (inserimento di codice *malevolo* insieme ai dati).\n\t\n1. **Dynamically Relocatable Code (Execution Time Binding)**:\n\tSe c'è un SO, questo metodo ha quasi tutti pro.\n\tLa MMU gestisce i SIGSEGV e protegge gli altri processi, il SO può riorganizzare tutto come gli è più comodo.\n\tDi contro ogni referenza di memoria richiede tempo di tipo HW (deve runnare la MMU).\n\tNelle slides mette altri contro ma penso sia perché non ha ancora spiegato la paginazione...\n","x":-3899,"y":-2259,"width":600,"height":840,"color":"4"},
		{"id":"ed6ac0281f980f03","type":"text","text":"# Address Binding\n\n1. **Absolute Code (Compile Time Binding)**:\n\tE' specifico per una determinata posizione di memoria. Le variabili e le istruzioni nel codice utilizzano indirizzi assoluti (quindi gli indirizzi logici coincidono con gli indirizzi fisici) espliciti. Se voglio eseguirlo in una zona di memoria diversa devo ricompilare il codice.\n2. **Statically Relocatable Code (Load Time Binding)**:\n\tPuò essere eseguito in qualsiasi posizione di memoria. Utilizza riferimenti relativi anziché assoluti per variabili e istruzioni (resta comunque una corrispondenza tra indirizzi logici e fisici, ma non è esplicita), quindi si può semplicemente ricaricare in memoria piuttosto che ricompilarlo.\n3. **Dynamically Relocatable Code (Execution Time Binding)**:\n    Sfrutta la memoria virtuale, motivo per cui si può spostare anche a runtime. Sfrutta MMU, quindi serve supporto HW.\n\nIn pratica, i pezzi di codice che devono essere modificati a runtime devono essere preferibilmente Dynamically, perché nel chiamare (ad esempio) una grossa malloc non nota a compile time (tipo malloc(n) con n inserito da tastiera) può essere necessario spostare l'intero programma in uno spazio dove entra. \n\nQuesto però richiede complessità aggiuntiva, e se non necessario si evita, usando Statically (ad esempio in una libreria, la cui dimensione su RAM è nota a compile time e si può spostare come blocco a dimensione fissata). \n\nL'Absolute Code in un contesto di SO è scomodo perché deve essere caricato nella esatta porzione di memoria fisica per la quale sono stati scritti staticamente gli indirizzi nel codice, rendendo impossibile un riposizionamento in RAM ed essendo utile solo in sistemi tipo microprocessori.","x":-3254,"y":-2259,"width":753,"height":840,"color":"4"},
		{"id":"d944c099d4a52726","type":"file","file":"memoria.txt","x":-2447,"y":-2231,"width":730,"height":359,"color":"4"},
		{"id":"6dbca290cf842d6e","type":"text","text":"# Premessa: Indirizzi\n\n- **Logici**: Sono interni al programma e relativi solo e soltanto ad esso, ne definiscono la logica (appunto) interna. Se dichiaro un puntatore di tipo array come\n\t\n\t\tint vettore[10];\n\t\tint valore = vettore[2];\n\tallora $2$ è un indirizzo logico, in questo caso di offset rispetto al puntatore.\n -\n- **Virtuali**: La premessa agli indirizzi virtuali è la seguente:\n\t- Il SO assegna un range di memoria virtuale al processo;\n\t- Il compilatore/linker alloca i puntatori, quindi assegna loro un indirizzo all'interno del range di memoria virtuale, detto appunto *indirizzo virtuale*.\n\n\tA questo punto agli *astratti* indirizzi logici corrisponderanno degli indirizzi virtuali.\n\n\tEsempio: il compilatore assegna al puntatore `vettore` un valore come `0xABADCAFE`, e lascia spazio nei successivi `10*sizeof(int)` indirizzi. All'indirizzo logico `2` di `vettore[2]` corrisponderà l'indirizzo virtuale `0xABADCAFE + 2*sizeof(int)`.\n-\n- **Fisici**: Quelli \"veri\" della RAM, in cui vengono mappati gli indirizzi virtuali di tutti i processi. Non necessariamente all'indirizzo virtuale `0xABADCAFE` corrisponde l'indrizzo fisico `0xABADCAFE`, perché un sistema di *Memory Management Unit (**MMU**)* può spostare la mappatura di ogni indirizzo virtuale in fisico a seconda delle necessità.","x":-2447,"y":-1299,"width":730,"height":700,"color":"4"},
		{"id":"69f392e5d5620920","type":"file","file":"Memoria/memory_hierarchy.png","x":-2447,"y":-1789,"width":730,"height":342},
		{"id":"9a0af77adce9ad06","type":"file","file":"Memoria/AddressBinding/Address Binding.png","x":-3254,"y":-1299,"width":753,"height":700},
		{"id":"651b3e34405ca302","type":"text","text":"# Memoria","x":-2182,"y":-287,"width":200,"height":61,"color":"3"},
		{"id":"255c19cad945a18f","type":"text","text":"# Operazioni di Input/Output","x":-899,"y":320,"width":518,"height":61,"color":"3"},
		{"id":"652e671c121210e0","type":"text","text":"# Translation Look-aside Buffer (TLB)\n\nC'è una cache anche per la PT, si chiama TLB.\n\nCostituisce un *trade-off* tra la voglia di utilizzare i registri per velocizzare il paging e la necessità di usare la RAM perché mica posso usare 4Mb (se va bene, quindi a 32-bit, altrimenti diventano 8Pb) di registri.\n\nTipicamente ha un numero di entrate bel range $[8, 2048]$, ed esattamente come la cache sfrutta la località.\n\nNaturalmente si pone un problema: la PT è specifica del processo, come gestisco una cache che vedono tutti i processi? \n\n- Livello basic: faccio un wipe totale del TLB a ogni Context Switch;\n- Livello assurdo wow chi l'avrebbe mai detto: salvo sempre una copia del TLB nel PCB del processo.","x":710,"y":-1299,"width":530,"height":700,"color":"4"},
		{"id":"62a83dc4f208244f","type":"text","text":"### Initializing Memory when Starting a Process\n\n1. Process requests for k pages;\n2. If k frames are free then allocate those to the process, otherwise free frames no longer needed (swapping-out);\n3. OS puts each page into a frame and sets the corresponding mapping into the page table (in main memory);\n4. OS marks all previous TLB entries as invalid (i.e., flushes the cache) or restores TLB entries from saved PCB;\n5. As process runs, OS loads TLB missed entries possibly replacing existing entries if TLB is full.\n\n\n#### Saving/Restoring Memory Upon Context Switch\nThe PCB must now contain:\n- The value of the Page Table Base Register (PTBR)\n- Possibly a copy of the TLB entries\n\nOn a context switch:\n- Copy the PTBR value to the PCB\n- Copy the TLB to the PCB (optional)\n- Flush the TLB (if TLB is not saved to/restored from the PCB)\n- Restore the PTBR (i.e., with the value of the new running process)\n- Restore the TLB (if it was previously saved)","x":710,"y":-2259,"width":530,"height":840,"color":"1"},
		{"id":"a23e13dca8a3ad1d","type":"text","text":"# Sharing Pages\nPaging systems can make it very easy to share blocks of memory, since memory doesn't have to be contiguous anymore\n\nThis can be done by simply duplicating page entries of different\nprocesses to the same page frames (both for code and data)\n\nOnly if code is reentrant:\n- it does not write to or change the code (i.e., it is non self-modifying)\n- the code can be shared by multiple processes, as long as each has their own\ncopy of the data and registers, including the instruction register","x":1280,"y":-2259,"width":541,"height":479,"color":"1"},
		{"id":"0c73604c03c3a581","type":"text","text":"# \"Reentrant\"\n\nCodice che non deve preoccuparsi della sincronizzazione, in pratica. Credo. Sicuramente è spiegato meglio [qui](https://it.wikipedia.org/wiki/Codice_rientrante).","x":1280,"y":-1740,"width":541,"height":321,"color":"4"},
		{"id":"edd84b5881ba408b","type":"text","text":"# Attenzione alle conversioni!!\n\nLavorando con i [byte](https://it.wikipedia.org/wiki/Byte) il fatto che $2^{10} \\simeq 10^3$ (per esempio Gib $\\simeq$ Gb) porta a fare errori tanto più grandi quanto è grande il prefisso.","x":-1560,"y":50,"width":461,"height":160,"color":"6"},
		{"id":"46a10f1736b333eb","type":"file","file":"Memoria/Binaryvdecimal.png","x":-1629,"y":-500,"width":600,"height":464},
		{"id":"65f8df716b94268d","type":"text","text":"# Come dialogo con un dispositivo I/O?\n\nOgni device I/O consta di due parti:\n\t- Il device stesso\n\t• the device controller (chip or set of chips controlling a family of physical devices)\n\nOS talks to a device controller using a specific device driver\n\n• Every device controller has a number of dedicated registers to communicate with it:\n\t• Status registers: provide status information to the CPU about the I/O device (e.g., idle, ready for input, busy, error, transaction complete)\n\t• Configuration/Control registers: used by the CPU to configure and control the device\n\t• Data registers: used to read data from or send data to the I/O device\n\n\n","x":647,"y":-238,"width":1111,"height":387,"color":"2"},
		{"id":"5d67baa15b95e53b","type":"file","file":"Input-Output/controller_driver.png","x":1827,"y":-238,"width":724,"height":387},
		{"id":"f259623a35cf9802","type":"text","text":"# How does the CPU know how to address (registers of) I/O devices?\n\nPort-Mapped I/O\n• Each I/O device controller's register is mapped to a specific port\n(address)\n• Requires special class of CPU instructions (e.g., IN/OUT)\n• The IN instruction reads from an I/O device, OUT writes\n• When you use the IN or OUT instructions, the M/#IO is not asserted,\nso memory does not respond and the I/O chip does\n\nMemory-Mapped I/O\n• Memory-mapped I/O \"wastes\" some address space but doesn’t need any special instruction\n• To the CPU I/O device ports are just like normal memory addresses\n• The CPU use MOV-like instructions to access I/O device registers\n• In this way, the M/#IO is asserted indicating the address requested by the CPU refers to main memory","x":647,"y":210,"width":1111,"height":448,"color":"1"},
		{"id":"1fb92b9bd42e2c32","type":"file","file":"Input-Output/addressing_IO.png","x":1827,"y":243,"width":723,"height":382},
		{"id":"582cbf0b2f379d20","type":"file","file":"Input-Output/port_mapping_easy.png","x":3227,"y":-238,"width":895,"height":895},
		{"id":"771c1bd426fd8f47","type":"text","text":"## Quindi la differenza è...\n\nChe se in assembly {ATTENZIONE SINTASSI INTEL} scrivo \n\nMOV DX, 1234h\nMOV AL, \\[DX\\]\n\nsto leggendo il contenuto dell'indirizzo di memoria 0x1234 che mi porta poi alla periferica (devo usare il canale M/#IO del Control Bus), mentre invece se scrivo\n\nIN AL, DX\n\nmi interfaccio direttamente col chip di I/O corrispondente su di un I/O Address Space.\n\nNotare che entrambi gli approcci scrivono 0x1234 sull'Address Bus e invocano la READ sul Control Bus.\n\n","x":4187,"y":-238,"width":560,"height":895,"color":"4"},
		{"id":"24babc6f213a28a7","type":"file","file":"Input-Output/memory_port_mapping.png","x":2607,"y":-238,"width":543,"height":895},
		{"id":"76425af58183667e","type":"file","file":"Input-Output/DMA.png","x":1827,"y":-1225,"width":724,"height":724},
		{"id":"7bdf1dc58118080b","type":"file","file":"Input-Output/IO_CPU_POV.png","x":2607,"y":-818,"width":543,"height":538},
		{"id":"667a17b2a2c4afbc","type":"text","text":"## Ogni trasferimento dati deve passare per la CPU?\n\nNo. Se bisogna scambiare dati tra memoria e I/O la CPU delega il lavoro al Controller DMA (Direct Memory Access). Al massimo si limita a fare POLLING, cioè a chiedere ogni tot al processo se ha finito.","x":1827,"y":-465,"width":724,"height":185,"color":"4"},
		{"id":"13a15e4783d53ebf","type":"file","file":"Input-Output/DMA_scheme.png","x":2607,"y":-1234,"width":543,"height":371},
		{"id":"ee6c1653941f5cf9","type":"text","text":"# Segmentazione\n\nUn punto di vista diverso rispetto al Paging, ovvero dividere i programmi non in pagine ma in segmenti.\n\nUna Segment Table (**ST**) ha come indice il numero di segmento e come valori gli indirizzi *base* e *limit* che li individuano in memoria.\nQuesto porta come vantaggio una maggiore semplicità nel tenere traccia del codice: una ST ha al più una mezza dozzina di entrate, contro le $\\sim 2^{20}$ di una PT, e può quindi essere tenuta nei registri.\n\n### Combinare Segmentazione e Paging\nSi possono ottenere vantaggi non indifferenti scegliendo di fare paging non sulle singole pagine ma sui segmenti, ovvero gruppi contigui di pagine. Ad esempio, ha senso mappare interamente in RAM l'**heap** del processo se questo è utilizzato, e ha senso deallocarlo in blocco se non lo è. Questo sempre premesso che le pagine contigue non necessariamente sono mappati in frame contigui.\n\nL'indirizzo virtuale a questo punto ha i primi bit (credo siano 3) che indicizzano il segmento e i restanti divisi come prima in pagina e offset. Si noti che sacrificare 3 bit della pagina riduce il numero di pagine utilizzabili, ma in 64-bit passare da $2^{52}$ a $2^{49}$ (e quindi da $\\sim 16$ Eb a $\\sim 2$ Eb di memoria a disposizione del singolo processo) non è una grossa perdita.\n\n","x":-2447,"y":-3080,"width":730,"height":720,"color":"4"},
		{"id":"c117519b0d042f3b","type":"text","text":"# Ulteriori note\n\nE' ovviamente necessario stipare da qualche parte le ST e le PT. Dove?\n\n- Segment tables in a small number of registers page tables in main memory with TLB cache. Faster but the number of segments is limited.\n- Both segment tables and page tables in main memory with TLB cache. TLB lookup done using segment index and page index. Slower but more flexible.\n\nPer condividere la memoria è sufficiente condividere il segmento piuttosto che cercare nella PT le relative pagine.\n\n### Pros and cons (gli piace proprio)\n\n- Questo POV \"mischia\" gli approcci del compilatore, che ragiona per segmenti, e del SO che invece ragiona a pagine.\n- Nonostante le allocazioni inizino come blocchi di codice, finiscono in RAM come singoli frame $\\Rightarrow$ elimino la frammentazione esterna.\n- Di contro è un processo un po' più lento (e qui ci fidiamo).\n- Questo non elimina la frammentazione interna. Se faccio solo paging perdo $\\sim 0.5$ pagine di spazio complessivo, se faccio sia frammentazione che paging ne perdo $\\sim 0.5$ per frammento.","x":-3899,"y":-3080,"width":600,"height":720,"color":"2"},
		{"id":"374ffdc5ef9b8c37","type":"file","file":"Memoria/Paging/Segmentation+Paging.png","x":-3254,"y":-2891,"width":753,"height":343},
		{"id":"efa5f9c31e4d06bc","type":"file","file":"Processi/process_state.png","x":-3560,"y":1821,"width":840,"height":340},
		{"id":"c122bc6beeff65cb","type":"text","text":"","x":-3142,"y":2004,"width":250,"height":60},
		{"id":"e864bef1d25309b9","type":"text","text":"# Aggiunte\n## Stack Pointer\nOltre allo Stack Pointer esp si definisce uno Stack Base Pointer che punta alla base dello Stack Frame del chiamante.\nQuando chiamo una funzione posso pushare il vecchio valore di ebp e usare quello al posto di esp, mentre esp \"scende\" insieme alle variabili locali.\n\n## Process Execution State\nAt each time a process can be in one of the following 5 states:\n\t- New: The OS has set up the process state;\n\t- Ready: The process is ready to be executed yet waiting to be scheduled on to the CPU\n\t- Running: The process is actually executing instructions on the CPU\n\t- Waiting: The process is suspended waiting for a resource to be available or an event to complete/occur (e.g., keyboard input, disk access, timer, etc.);\n\t- Terminated: The process is finished and the OS can destroy it","x":-2323,"y":1813,"width":480,"height":696,"color":"2"},
		{"id":"4e690bb692a0c595","type":"text","text":"# Tabelle multilivello\n\nAnche solo in un sistema a 32-bit la PT occupa 4Mib, ed è inverosimile pensare di tenerla sempre tutta in memoria\n\nQuindi si pagina la tabella delle pagine.\n\n### Tabelle di hash (HT)\n\nCredo che sostituisca le PT ma non mi è ben chiaro in che modo.\n\nPare sia indicizzata dai possibili output di una fantomatica *hash function* (*\"piuttosto che da interi\"*).\n\n### Inverted Page Table\n\nColpo d'occhio sui processi (PID) a cui sono assegnati attualmente i frame.","x":-4560,"y":-3080,"width":600,"height":720,"color":"2"},
		{"id":"fc632d9a9c345ef1","type":"file","file":"Memoria/Paging/PagingPageTable.png","x":-4935,"y":-2932,"width":320,"height":425},
		{"id":"742f4065dd5c5cbc","type":"text","text":"# Gestione Page Fault\n\nCome descritto nel .txt con il bit di validità, con l'aggiunta dei *TLB hit* e *miss* (come con la cache, e d'altronde è una cache, tutto sembra essere la cache di qualcos'altro).\n\nIl problema relativo al capire quale pagina del segmento genera il fault è specifico dell'architettura e richiede supporto HW, che serve anche a salvare lo stato della CPU (e del sistema in generale) per capire come riprendere l'esecuzione.\n\nCi sono infatti due tipi di istruzioni.\n\n- **idempotenti**, per le quali è sufficiente eseguire nuovamente la riga di codice;\n- **non-idempotenti**, come `MOV [%R1], +(%R2)`, che incrementa il valore in `R2` e poi se il riferimento a memoria `[%R1]` fa page fault... eseguo da capo incrementando di nuovo il valore in `R2`? Ovviamente no. Prima di eseguire istruzioni non-idempotenti si gestisce l'eventuale page fault.\n\n### Page Fetching e Page Replacement\n\nIl SO deve stabilire quando è necessario caricare una pagina in memoria fisica (**fetching**) e quale pagina rimuovere se questa è piena (**replacement**).\nIdealmente l'obiettivo è ottimizzare il processo e dare l'impressione di utilizzare la capacità del disco con la velocità della RAM, nonostante l'accesso a disco sia $\\sim 10^5$ volte più lento dell'accesso a memoria.","x":-1639,"y":-2860,"width":1238,"height":500,"color":"4"},
		{"id":"e9bab4cd14415702","type":"text","text":"# Page Fetching\n\n Ci sono tre diverse strategie di fetching:\n\n- **Startup** - Tutte le pagine del processo sono caricate in memoria all'avvio;\n- **Overlays** - La decisione spetta al programmatore;\n- **Demand** - Il SO carica una pagina in memoria solo quando il processo la richiede. Detto anche *lazy swapper* o *pager*.\n\nOvviamente nella maggior parte dei moderni SO si usa quest'ultima.\n\n#### Prefetching\n\nIl pager può provare a ottimizzare assumendo che i processi mostrino località. Quando un processo richiede una pagina, questo carica in RAM anche le pagine contigue.","x":-960,"y":-3480,"width":559,"height":520,"color":"4"},
		{"id":"6b5bb4e98e9e2a28","type":"text","text":"# Page Replacement\n\nSe in RAM c'è abbastanza spazio per fare fetching, tutto bene.\n\nAltrimenti devo decidere quali pagine rimuovere per fare spazio a quelle nuove.\n\nSono possibili diversi algoritmi con diversi vantaggi e svantaggi.\n\n- **Random** - Autoesplicativo, pare funzioni meglio di quanto si possa pensare;\n- **FIFO** - In pratica assume che la pagina più \"vecchia\" sia la meno utilizzata, questo ovviamente non è sempre vero;\n- **MIN (OPT)** - In teoria l'algoritmo ottimale (detto *Minimo* o *Ottimale*), prova a predire la pagina che servirà di meno in futuro. Il come, chiaramente, è un *utile esercizio per il lettore*.\n\t- **LRU** - Rimuove la pagina *Last Recently Used*, cioè in pratica approssima un algoritmo *Ottimale* assumendo che il passato possa predire il futuro.","x":-1639,"y":-3480,"width":559,"height":520,"color":"4"},
		{"id":"113ca9ce4e51d6e6","type":"text","text":"# Threads\n\nSono un modo più semplice e veloce di eseguire le operazioni di un programma. Questo infatti può essere visto, più che come una sequenza lineare di istruzioni, come un insieme di moduli in esecuzione parallela che cooperano. Ad esempio, il programma editor di testo ha un thread che attende l'input, uno che controlla la grammatica, uno che gestisce la GUI, ... Tutto questo senza problemi come dover creare nuovi processi figli, attenderne la risoluzione, comunicare dati tra processi con schemi di memoria condivisa o con syscall per messaggi, ... La comunicazione tra thread è molto più veloce, così come la creazione e il context switch.\n\nUn Thread è definito come unità base di utilizzo CPU, ovvero un Program Counter, una Stack e un set di registri generici (oltre ovviamente all'ID del Thread). Ogni thread fa riferimento a un processo genitore, e ogni processo genitore condivide con ogni thread figlio codice, dati e zona di memoria. Se a ogni processo corrisponde un PCB, a ogni thread corrisponde un TCB. Più thread dello stesso processo possono andare in esecuzione parallela su diversi core. Questo richiede un ulteriore processo di scheduling da parte del SO.\n\nI thread si dividono in due macro-categorie:\n\n- Kernel thread, gestiti direttamente dal SO.\n\t- Pro: Kernel has full knowledge of all threads. Scheduler may decide to give more CPU time to a process having a large numer of threads. Good for applications that frequently block. Switching between threads is faster than switching between processes.\n\t- Contro: Significant overhead and increase in kernel complexity. Slow and inefficient (need kernel invocations). Context switching, although lighter, is managed by the kernel.\n\n- User thread, gestiti dall'utente con apposite librerie che sfruttano syscall fornite dal SO.\n\t- Pro: Really fast and lightweight. Scheduling policies are more flexible. Can be implemented in OSs that do not support threading. No system calls involved, just user-space function calls. No actual context switch.\n\t- Contro: Il SO non sa nulla dei thread in spazio utente, quindi li gestisce come programma concorrente.\n\nSi rende necessario quindi mappare i thread utente in thread kernel (spesso viene fatto da un'unità chiamata LWP, Lightweight Processor). Ci sono diversi modi di farlo.\n\n- Many-To-One: Più thread utente sono mappati in un singolo thread kernel. L'utente scrive un parallelismo che non verrà mai implementato;\n- One-To-One: N thread utente sono mappati in N thread kernel. La gestione del processo di mapping può rallentare il sistema, motivo per cui spesso c'è un limite al numero di thread creabili;\n- Many-To-Many: N thread utente sono mappati in M <= N thread kernel. Unisce i vantaggi dei metodi precedenti. Se possibile si mantiene il parallelismo dato da One-To-One, altrimenti più thread utente vengono mappati in un solo thread kernel. Presente anche in variante Two-Level, che esegue esplicitamente in parallelo il multiplexing di Many-To-Many e il collegamento diretto di One-To-One.","x":-399,"y":1320,"width":880,"height":1080,"color":"4"},
		{"id":"f9cd9cbd5670ae73","type":"text","text":"# Implementazione dei thread\n\nI thread utente sono implementati in specifiche API (POSIX threads (pthreads), Java threads, ...), mentre i thread kernel e il mapping sono gestiti da un sottosistema noto come Thread Library (o Package), parte integrante del SO, che sfrutta le syscall.","x":536,"y":1320,"width":1000,"height":180,"color":"4"},
		{"id":"b34d99bdf2278892","type":"file","file":"Processi/Threads/pthreads.png","x":536,"y":1573,"width":582,"height":827},
		{"id":"b6527646e8c708a9","type":"text","text":"# Java e Thread Pools\n\nPosto che non so usarlo, pare serva a gestire i server. Il multi-threading su server prevede la creazione di un thread per ogni richiesta da gestire. Il problema è che se ne possono creare troppi, per cui si usano delle THREAD POOLS, ovvero all'avvio creo un certo numero di thread che metto in una pool. Quando devo gestire una richiesta, pesco (\"risveglio\") un thread dalla pool. Se non ce ne sono, aspetto. Quando finisce la gestione della richiesta, il thread torna a dormire nella pool. Separare la richiesta (job da eseguire) dal processo di creazione del thread (chi lo esegue) permette anzitutto di guadagnare tempo (e quindi ridurre l'overhead, ovvero il \"lavoro in più\", immagina di dover creare ogni volta da capo il processo/thread che esegue un job piuttosto che averlo pronto e doverlo solo \"risvegliare\"), e secondariamente di organizzare con uno scheduler l'esecuzione di un certo thread in stand-by eseguendolo periodicamente, con un delay o al verificarsi di certe condizioni.","x":1160,"y":1573,"width":376,"height":827,"color":"4"},
		{"id":"31454c1c260010da","type":"text","text":"# Threads Q&A\n\nQ: If one thread forks, is the entire process copied, or is the new process single-threaded?\n- A1: System dependent;\n- A2: If the new process execs right away, there is no need to copy all the other threads, otherwise the entire process should be copied;\n- A3: Many versions of UNIX provide multiple versions of the fork call for this purpose.\n\nQ: When a multi-threaded process receives a signal, what thread should that signal be delivered to?\n- A1: There are 4 major options:\n\t- Deliver the signal to the thread to which the signal applies\n\t- Deliver the signal to every thread in the process\n\t- Deliver the signal to certain threads in the process\n\t- Assign a specific thread to receive all signals in a process\n\n\n- A2: UNIX allows individual threads to indicate which signals they are accepting and which they are ignoring. Provides 2 separate system calls for delivering signals to process/threads, respectively:\n\t- kill(pid, signal)\n\t- pthread_kill(tid, signal)","x":1641,"y":1320,"width":762,"height":1043,"color":"1"},
		{"id":"deedc18089e093f1","type":"text","text":"### 64-bit\n\nGiusto per ridere, a 64-bit il SO può gestire una memoria apparente di $2^{76}$ byte $= 64$ Zib $\\simeq 64$ Zettabyte ($O(10^{21})$). Considera che i Terabyte sono $O(10^{12})$.","x":-29,"y":-500,"width":400,"height":194,"color":"4"},
		{"id":"760de5855566da94","type":"text","text":"# Second Chance Algorithm (or Clock Algorithm)\n\nPartiamo col dire che è meno precisa di Additional-Reference Bit. Ma allora perché lo si usa? Ovvio, perché è più veloce. Il mondo informatico è tutto un *trade-off*.\nIn pratica è un Single-Bit Reference + FIFO.\n\n- C'è una lista dei frame che si aggiorna secondo una FIFO, che a ogni interrupt del clock rimuove l'ultimo elemento per metterlo in testa;\n- Questo determina soltanto la pagina di partenza da cui il SO scorre la lista.\n- Ogni pagina ha in Single-Bit, inizialmente settato a 1. Puoi vederla come una \"vita\" in stile Super Mario, perché...\n- ... se il SO trova un 1 lo decrementa e passa al frame successivo (da cui *Second Chance*);\n- Se invece trova uno zero questa sarà la vittima. Rimpiazza la pagina e riscrive 1.\n\nNon sembra avere molto senso, vero? Eppure pensa che ne esiste una versione *enhanced*.\n\n#### Enhanced Second Chance Algorithm\n\nSi basa su un'idea abbastanza semplice: \"It is cheaper to replace a page which has not been modified, since the OS does not need to write this back to disk\". In pratica, l'HW tiene conto dell'eventuale modifica con un bit apposito. Si crea quindi una gerarchia di preferenze.\n\n- **(0, 0)** - Nè recentemente usata né modificata. Le vittime perfette.\n- **(0, 1)** - Non usata recentemente, ma modificata.\n- **(1, 0)** - Usata recentemente, ma non modificata.\n- **(1, 1)** - Se possibile, questa pagina andrebbe mantenuta in memoria.\n\nIl SO scorre la lista alla ricerca del primo frame **(0, 0)**, se non lo trova scorre nuovamente cercando un frame **(0, 1)**, e così via.","x":-3254,"y":-4040,"width":753,"height":820,"color":"4"},
		{"id":"b5aedc73d018cc9e","type":"text","text":"# Belady's Anomaly\n\nSe incremento la memoria fisica diminuisco i page fault, giusto?\n\nNo. O almeno, non sempre.\n\nAlcuni algoritmi, come FIFO, possono addirittura peggiorare le proprie prestazioni con un aumento di memoria. Intuitivamente, questo è dovuto al fatto che non considera l'uso delle pagine e le rimuove \"a giro\". Infatti, in pratica, è un algoritmo di Round Robin e soffre degli stessi problemi (vedi Scheduling Algorithms, in basso a sinistra).\n\nAltri, come LRU, possono solo migliorare. Rimuovendo le pagine inutilizzate da più tempo tende a mantenere sempre in memoria le pagine referenziate più spesso (soprattutto secondo la legge empirica del 90-10).","x":-1639,"y":-4040,"width":559,"height":440,"color":"4"},
		{"id":"ab7ce62182178f88","type":"text","text":"# Swap Space\n\nSpazio su disco per le pagine che non entrano in RAM. Può essere una partizione dedicata (e.g. Linux) o una cartella del filesystem (e.g. MacOS).\n\nGeneralmente quando si fa **swap out** (ovvero fetching, dal punto di vista del SO) si salva una copia della pagina richiesta.\n\nOra, le pagine possono essere di due tipi, e sono gestite in modi diversi.\n\n- Codice, quindi *read-only*. Non essendo modificabile, è possibile risalire all'originale dal codice sorgente\n- Dati, quindi modificabile. Devo farne ogni volta una copia.","x":-960,"y":-4040,"width":559,"height":440,"color":"4"},
		{"id":"23b1b309c92014a7","type":"text","text":"# La LRU perfetta non esist...\n\nNo, per davvero. Come la implemento in pratica?\n\n- Salvando i tempi di accesso e facendo uno scan lineare di tutte le pagine confrontandola con il *timestamp* attuale. Lentissimo, passiamo oltre.\n- Aggiornando una lista ordinata, così l'algoritmo si limita a controllare l'ultimo elemento. In pratica ho una SCL di supporto di $2^{20}$ elementi di cui devo cambiare un numero assurdo di puntatori per ogni accesso a memoria. In pochissimo tempo. Inverosimile.\n\nIniziamo a capire perché l'algoritmo **Random** funziona sorprendentemente bene.\n\nIn realtà molte implementazioni della MMU forniscono il supporto HW necessario a implementare LRU in modo decente, ma non ottimale. In pratica si perde per strada l'ordine esatto di accesso, mantenendone uno approssimativo. Vediamo come.\n\n- **Single-Reference Bit** - Ogni frame ha un bit che viene settato a 1 in accesso. Periodicamente (interrupt del clock) questo bit viene rimesso a 0, in modo che LRU possa scegliere sostanzialmente a caso tra gli zeri. Per comodità lo chiameremo Gianni.\n- **Additional-Reference Bit** - Chi l'avrebbe mai detto, invece di un solo bit ne uso di più. Per contare, vero? Più o meno. Non conto i singoli accessi, ma \"hai fatto almeno un accesso dall'ultimo interrupt del clock?\" (che si vede da Gianni, che è un bit a parte rispetto agli 8 che contano). A ogni interrupt faccio due cose:\n\t- Shifto a destra gli 8 bit che contano;\n\t- Copio Gianni nel *leftmost bit*, che sarebbe il più significativo degli 8.\n\n\tA questo punto LRU ha a disposizione una pool molto più ristretta (e quindi precisa) per scegliere la sua vittima.\n- **Second Chance Algorithm** - Merita una card dedicata, la trovi a sinistra.","x":-2447,"y":-4040,"width":730,"height":820,"color":"4"},
		{"id":"05216adedc2d6235","type":"text","text":"# Thrashing\n\nQuando il **working set** dei processi occupa più spazio della memoria fisica inizio a fare replacement con pagine attualmente in uso.\n\nQuesto aumenterà significativamente il page fault, e conseguentemente il tempo verrà monopolizzato dalla MMU (piuttosto che dalla ALU, che vorrebbe tanto fare calcoli utili ma non ha i dati).\n\nUn possibile modo di diminuire il rischio di thrashing è sostituire il processo di fetching/replacement *globale* (per come descritto prima) con uno **locale** per ogni singolo processo, in modo da mandare in thrashing solo il processo che esagera col proprio working set.\n\nMa come faccio a sapere quanti frame assegnare a ogni singolo processo?","x":171,"y":-3480,"width":430,"height":520,"color":"4"},
		{"id":"fdb26cc1e8ca8651","type":"text","text":"# Prevedere il working set\n\nFormalmente, il working set $\\Delta$ è l'insieme di pagine referenziate dal processo negli ultimi T (milli)secondi, che generalmente include almeno $O(10^{8})$ istruzioni. Bisogna considerare che per gestire un page fault si perde un tempo corrispondente a $\\sim O(10^{6\\div 7})$ istruzioni.\n\nVisto che così è complicato, si sceglie di inferire una stima di $\\Delta_i$ per campionamento ogni $k$ (e.g. $10^3$) istruzioni eseguite.\n\nAll'atto pratico, il numero di frames riservato per $\\Delta$ viene scelto in modo da mantanere il *page-fault rate* $\\tau$ entro dei valori di soglia prestabiliti.","x":171,"y":-4040,"width":430,"height":440,"color":"4"},
		{"id":"9132abad1267a121","type":"file","file":"Memoria/Thrashing/Thrashing.png","x":710,"y":-3375,"width":529,"height":310},
		{"id":"f03ea06b8cc06adb","type":"file","file":"Memoria/Thrashing/WorkingSet.png","x":710,"y":-3933,"width":530,"height":227},
		{"id":"9f60f09a269a32aa","type":"text","text":"# Manage Multiprogramming Memory\n\n- Sharing\n\t- Several processes coexist in main memory at the same time\n\t- Cooperating processes can share portions of address space\n\n- Transparency\n\t- Processes should not be aware that memory is shared\n\t- Processes should not be aware of which portions of physical memory they are assigned to\n\n- Protection/Security\n\t- Processes must not be able to corrupt each other or the OS\n\t- Processes must not be able to read data of other processes\n\n- Efficiency\n\t- CPU and memory performance should not degrade badly due to sharing\n\t- Keep memory fragmentation low","x":-3960,"y":-1299,"width":600,"height":560,"color":"1"},
		{"id":"ebda4cf153d6ae26","type":"text","text":"## Mentre eseguo una syscall?\n\nPosso scegliere di aspettare (sincrono col processo) o fare altro nel frattempo (asincrono).","x":-5739,"y":84,"width":760,"height":100},
		{"id":"2d34128153e6b03e","x":-6569,"y":706,"width":698,"height":510,"color":"4","type":"file","file":"pipelining.txt"},
		{"id":"66b9c1070bde7f69","type":"file","file":"processiIII.txt","x":-7311,"y":706,"width":698,"height":510,"color":"4"},
		{"id":"fccd506f086b692b","type":"file","file":"Sicurezza e syscall/syscall_waiting.png","x":-5739,"y":767,"width":760,"height":387},
		{"id":"ffcaef257a0334a1","x":-7151,"y":-2070,"width":400,"height":400,"type":"file","file":"segnali.txt"},
		{"id":"d4d33725ee010f29","x":-9708,"y":-4042,"width":217,"height":50,"color":"6","type":"text","text":"# Premesse"},
		{"id":"925b75588817e4f2","x":-9708,"y":-3567,"width":217,"height":50,"color":"6","type":"text","text":"# Generale"},
		{"id":"f9bd700671836856","x":-9708,"y":-2992,"width":217,"height":60,"color":"6","type":"text","text":"# Assembly"},
		{"id":"5d912aa428876e90","x":-9708,"y":-2392,"width":217,"height":50,"color":"6","type":"text","text":"# Altro"},
		{"id":"241de77d83aa7a2e","x":-9168,"y":-3742,"width":400,"height":400,"color":"4","type":"file","file":"vonneumann.txt"},
		{"id":"e4fb36d38cd1f579","x":-9168,"y":-3161,"width":400,"height":400,"color":"4","type":"file","file":"vonneumannDemetrescu.txt"},
		{"id":"ae158c9814d93e39","x":-9168,"y":-2562,"width":400,"height":400,"color":"4","type":"file","file":"Ottimizzazione.txt"},
		{"id":"829486c3d7b82293","x":-8551,"y":-3742,"width":400,"height":400,"color":"4","type":"file","file":"SO 1.txt"},
		{"id":"441b39d70b5495bc","x":-8551,"y":-3161,"width":400,"height":400,"color":"4","type":"file","file":"IA-32.txt"},
		{"id":"a17a579ccfec49f8","x":-7931,"y":-3162,"width":400,"height":400,"color":"4","type":"file","file":"funzioni_con_parametri.txt"},
		{"id":"ccccd634116d267b","x":-7291,"y":-3161,"width":400,"height":400,"color":"4","type":"file","file":"ABI.txt"},
		{"id":"a6494ec2a3a14739","type":"file","file":"Processi/Deadlock/Potentially Unsafe.png","x":-3198,"y":4964,"width":521,"height":356}
	],
	"edges":[
		{"id":"edc62c3892b1527c","fromNode":"65f8df716b94268d","fromSide":"right","toNode":"5d67baa15b95e53b","toSide":"left"},
		{"id":"95151c4e7f8fbc92","fromNode":"f259623a35cf9802","fromSide":"right","toNode":"1fb92b9bd42e2c32","toSide":"left"},
		{"id":"5dc9877b09b663e1","fromNode":"1fb92b9bd42e2c32","fromSide":"right","toNode":"24babc6f213a28a7","toSide":"left"},
		{"id":"52c245b570accbde","fromNode":"65f8df716b94268d","fromSide":"bottom","toNode":"f259623a35cf9802","toSide":"top"},
		{"id":"24627fbf3858f743","fromNode":"24babc6f213a28a7","fromSide":"right","toNode":"582cbf0b2f379d20","toSide":"left"},
		{"id":"e1b8844758b417e3","fromNode":"582cbf0b2f379d20","fromSide":"right","toNode":"771c1bd426fd8f47","toSide":"left"},
		{"id":"4cf3992b458c5a19","fromNode":"5d67baa15b95e53b","fromSide":"top","toNode":"667a17b2a2c4afbc","toSide":"bottom"},
		{"id":"681c2ddd6d5625b6","fromNode":"667a17b2a2c4afbc","fromSide":"top","toNode":"76425af58183667e","toSide":"bottom"},
		{"id":"52759ba275a01a39","fromNode":"76425af58183667e","fromSide":"right","toNode":"13a15e4783d53ebf","toSide":"left"},
		{"id":"d8203fbbada60b75","fromNode":"76425af58183667e","fromSide":"right","toNode":"7bdf1dc58118080b","toSide":"left"},
		{"id":"1eced803d27e0b5b","fromNode":"651b3e34405ca302","fromSide":"top","toNode":"69f392e5d5620920","toSide":"bottom"},
		{"id":"d293de9c75d36484","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"651b3e34405ca302","toSide":"bottom"},
		{"id":"0fb324781f2f8ddb","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"255c19cad945a18f","toSide":"left"},
		{"id":"067069f44a43fdee","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"0f5be1b419c22070","toSide":"right"},
		{"id":"af861c59a6d77c9e","fromNode":"c5128c9a62b77d1c","fromSide":"left","toNode":"b763de7850a80c53","toSide":"right"},
		{"id":"d715240d9948d69d","fromNode":"c5128c9a62b77d1c","fromSide":"bottom","toNode":"9aa74fda3231a196","toSide":"top"},
		{"id":"5eba096a0b958952","fromNode":"9aa74fda3231a196","fromSide":"bottom","toNode":"558ba900733523b5","toSide":"top"},
		{"id":"2bb965729a2d1282","fromNode":"3b4c354f921c302c","fromSide":"top","toNode":"2cbd9476c35281f6","toSide":"bottom"},
		{"id":"8e217020043c5cfd","fromNode":"c5128c9a62b77d1c","fromSide":"left","toNode":"7f02462535d305da","toSide":"right"},
		{"id":"07dd0a50bfeb1f16","fromNode":"307924e88efadd9d","fromSide":"left","toNode":"99c05cd2bb5fb531","toSide":"right"},
		{"id":"99f8a9a52b3c9853","fromNode":"558ba900733523b5","fromSide":"left","toNode":"307924e88efadd9d","toSide":"right"},
		{"id":"a99cb436db17db6e","fromNode":"06528774c7a17e8f","fromSide":"left","toNode":"558ba900733523b5","toSide":"right"},
		{"id":"8e0732983a2e84c4","fromNode":"99c05cd2bb5fb531","fromSide":"left","toNode":"a2ca84c1f075532c","toSide":"right"},
		{"id":"48c624f207642033","fromNode":"ebda4cf153d6ae26","fromSide":"bottom","toNode":"fccd506f086b692b","toSide":"top"},
		{"id":"4f3fd12e72b50247","fromNode":"16683038ca807a6e","fromSide":"left","toNode":"f104b3656720780b","toSide":"right"},
		{"id":"54a1b680c224da4b","fromNode":"f104b3656720780b","fromSide":"left","toNode":"4f7a30ec90f5f7a1","toSide":"right"},
		{"id":"1e74e9b040717bdf","fromNode":"69f392e5d5620920","fromSide":"top","toNode":"d944c099d4a52726","toSide":"bottom"},
		{"id":"b8304082ba758712","fromNode":"d944c099d4a52726","fromSide":"right","toNode":"69f3dd73ee95ff32","toSide":"left"},
		{"id":"3398396f12b7d67c","fromNode":"16683038ca807a6e","fromSide":"right","toNode":"c02fca4457eea4a1","toSide":"left"},
		{"id":"c839bef60036bb31","fromNode":"c02fca4457eea4a1","fromSide":"right","toNode":"cffda0fb3a359471","toSide":"left"},
		{"id":"0be209d4f4b381c0","fromNode":"cffda0fb3a359471","fromSide":"right","toNode":"50134cc52be508aa","toSide":"left"},
		{"id":"e49b2c4209b70436","fromNode":"50134cc52be508aa","fromSide":"right","toNode":"6bc46856fa34b1e2","toSide":"left"},
		{"id":"1df4ae7e3b3f3880","fromNode":"16683038ca807a6e","fromSide":"bottom","toNode":"ccea465ee5a66f66","toSide":"top"},
		{"id":"96cf72cd1e5c85fb","fromNode":"ccea465ee5a66f66","fromSide":"bottom","toNode":"409f9cd96c788b91","toSide":"top"},
		{"id":"58b3492bc3a36d0b","fromNode":"409f9cd96c788b91","fromSide":"bottom","toNode":"e864bef1d25309b9","toSide":"top"},
		{"id":"40ef8fb659b5e498","fromNode":"e864bef1d25309b9","fromSide":"left","toNode":"efa5f9c31e4d06bc","toSide":"right"},
		{"id":"46c9b7d88843fbbc","fromNode":"16683038ca807a6e","fromSide":"top","toNode":"06528774c7a17e8f","toSide":"right"},
		{"id":"c94d1eb183cd2ea4","fromNode":"f104b3656720780b","fromSide":"bottom","toNode":"ccea465ee5a66f66","toSide":"left"},
		{"id":"5d94b490a5b2e514","fromNode":"ccea465ee5a66f66","fromSide":"left","toNode":"f104b3656720780b","toSide":"bottom"},
		{"id":"f4396814055bce28","fromNode":"4f7a30ec90f5f7a1","fromSide":"bottom","toNode":"077958ec99cf0920","toSide":"top"},
		{"id":"5913f5186ef94be5","fromNode":"409f9cd96c788b91","fromSide":"left","toNode":"50883272249f2785","toSide":"right"},
		{"id":"a236ceb51a82c4c7","fromNode":"a1adbe9bb664a9c2","fromSide":"right","toNode":"50883272249f2785","toSide":"left"},
		{"id":"df29268ac512a536","fromNode":"a1adbe9bb664a9c2","fromSide":"left","toNode":"077958ec99cf0920","toSide":"right"},
		{"id":"670e1493337dc598","fromNode":"077958ec99cf0920","fromSide":"left","toNode":"8fac94dbd27f5a21","toSide":"right"},
		{"id":"1b4788b11ebf0238","fromNode":"077958ec99cf0920","fromSide":"left","toNode":"9ed99aa483da3638","toSide":"right"},
		{"id":"3867373f2edbe894","fromNode":"307924e88efadd9d","fromSide":"left","toNode":"2bd5a1b48bac530b","toSide":"top"},
		{"id":"ce23a5818adb79a5","fromNode":"3cbd143423e3f10a","fromSide":"right","toNode":"2bd5a1b48bac530b","toSide":"left"},
		{"id":"5ed619d4204533a1","fromNode":"2bd5a1b48bac530b","fromSide":"left","toNode":"3cbd143423e3f10a","toSide":"right"},
		{"id":"6ddcfe773f92dcc2","fromNode":"3cbd143423e3f10a","fromSide":"left","toNode":"7c939ee2ebe1207c","toSide":"right"},
		{"id":"c3464022fcab6606","fromNode":"3cbd143423e3f10a","fromSide":"top","toNode":"e2aefc482d1e7497","toSide":"bottom"},
		{"id":"8e8550eab6fae909","fromNode":"077958ec99cf0920","fromSide":"bottom","toNode":"97b3e71503c3e19d","toSide":"top"},
		{"id":"bc353e107d214a96","fromNode":"97b3e71503c3e19d","fromSide":"bottom","toNode":"6f102d8a296c67cf","toSide":"top"},
		{"id":"4532c867becfe2e6","fromNode":"6f102d8a296c67cf","fromSide":"left","toNode":"890280218841edc0","toSide":"right"},
		{"id":"bf02e50884b3ddd5","fromNode":"890280218841edc0","fromSide":"left","toNode":"0d183aee8445a447","toSide":"right"},
		{"id":"383a98afb3008463","fromNode":"0d183aee8445a447","fromSide":"left","toNode":"7c61dcb5932faf1f","toSide":"right"},
		{"id":"52f32e8d8b49ded4","fromNode":"6f102d8a296c67cf","fromSide":"right","toNode":"da8d7ccc61fb288f","toSide":"left"},
		{"id":"360f2a91dd1b123f","fromNode":"890280218841edc0","fromSide":"bottom","toNode":"4fe1989d7b05db02","toSide":"top"},
		{"id":"ac94d247b1fabc7d","fromNode":"8fac94dbd27f5a21","fromSide":"bottom","toNode":"4fe1989d7b05db02","toSide":"top"},
		{"id":"cf02d4cb1a746558","fromNode":"6f102d8a296c67cf","fromSide":"bottom","toNode":"127fb02c474f9e0c","toSide":"top"},
		{"id":"1dd016202fbf2fdc","fromNode":"3cbd143423e3f10a","fromSide":"bottom","toNode":"1c983ed53f331726","toSide":"top"},
		{"id":"9078d105834790b6","fromNode":"7c61dcb5932faf1f","fromSide":"left","toNode":"66990f7c63e2d405","toSide":"right"},
		{"id":"b1cd1503042a71db","fromNode":"3cbd143423e3f10a","fromSide":"left","toNode":"ba2b6213e4637219","toSide":"bottom"},
		{"id":"2c527e4b10454f12","fromNode":"66990f7c63e2d405","fromSide":"top","toNode":"e286057ad92c4f0c","toSide":"bottom"},
		{"id":"7b732ebd6b98fb05","fromNode":"66990f7c63e2d405","fromSide":"right","toNode":"a468bd8ba770bd4b","toSide":"left"},
		{"id":"9571cd60a5124870","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"4ff852d5afad6346","toSide":"right"},
		{"id":"66573d7025a6c12e","fromNode":"7c61dcb5932faf1f","fromSide":"bottom","toNode":"6c0f163753eb8b85","toSide":"top"},
		{"id":"f5136f611675b525","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"2a9d90b8cc31da54","toSide":"right"},
		{"id":"f463b513261aace8","fromNode":"a468bd8ba770bd4b","fromSide":"left","toNode":"e286057ad92c4f0c","toSide":"right"},
		{"id":"d893929f320106c9","fromNode":"4ff852d5afad6346","fromSide":"bottom","toNode":"2a9d90b8cc31da54","toSide":"top"},
		{"id":"567c9121d0606efb","fromNode":"66990f7c63e2d405","fromSide":"right","toNode":"005e7e1e1c753ec3","toSide":"left"},
		{"id":"c328310a1108ab59","fromNode":"005e7e1e1c753ec3","fromSide":"bottom","toNode":"b73522939cb2e340","toSide":"top"},
		{"id":"27e340efb990c46f","fromNode":"66990f7c63e2d405","fromSide":"bottom","toNode":"30f61bfe887b9609","toSide":"top"},
		{"id":"0d30eb082ccf3688","fromNode":"005e7e1e1c753ec3","fromSide":"left","toNode":"30f61bfe887b9609","toSide":"right"},
		{"id":"397e64d7228e29f4","fromNode":"66990f7c63e2d405","fromSide":"bottom","toNode":"97288d1ddddfffed","toSide":"top"},
		{"id":"2feb230814305d21","fromNode":"66990f7c63e2d405","fromSide":"left","toNode":"ee4978ec280e0156","toSide":"right"},
		{"id":"4b0512ad6f58e730","fromNode":"ee4978ec280e0156","fromSide":"bottom","toNode":"c948ce6320acafbe","toSide":"top"},
		{"id":"6adf051489ec3ca2","fromNode":"ccea465ee5a66f66","fromSide":"right","toNode":"113ca9ce4e51d6e6","toSide":"left"},
		{"id":"cbec9e6171417d9a","fromNode":"113ca9ce4e51d6e6","fromSide":"top","toNode":"b18a396618049aa5","toSide":"bottom"},
		{"id":"b3a442e2fbe1e6d6","fromNode":"113ca9ce4e51d6e6","fromSide":"right","toNode":"f9cd9cbd5670ae73","toSide":"left"},
		{"id":"9ae401be5385be51","fromNode":"f9cd9cbd5670ae73","fromSide":"bottom","toNode":"b34d99bdf2278892","toSide":"top"},
		{"id":"7c7616daa8714bad","fromNode":"f9cd9cbd5670ae73","fromSide":"bottom","toNode":"b6527646e8c708a9","toSide":"top"},
		{"id":"10f2a9db4884ff78","fromNode":"f9cd9cbd5670ae73","fromSide":"right","toNode":"31454c1c260010da","toSide":"left"},
		{"id":"d79a4b17e6be3f2e","fromNode":"113ca9ce4e51d6e6","fromSide":"bottom","toNode":"4a9e0af6fa1f8472","toSide":"top"},
		{"id":"d6f0d98646ef8786","fromNode":"4a9e0af6fa1f8472","fromSide":"left","toNode":"fad3582cc9b8fe57","toSide":"right"},
		{"id":"e20e3517047dbf43","fromNode":"fad3582cc9b8fe57","fromSide":"bottom","toNode":"933c1f33f83329d3","toSide":"top"},
		{"id":"dbbc61ed301cfd99","fromNode":"933c1f33f83329d3","fromSide":"left","toNode":"004837f0a7396bbf","toSide":"right"},
		{"id":"8a06bf0ae88cd109","fromNode":"004837f0a7396bbf","fromSide":"bottom","toNode":"45cd529f8bc60a75","toSide":"top"},
		{"id":"3458496fb70e45db","fromNode":"45cd529f8bc60a75","fromSide":"right","toNode":"933c1f33f83329d3","toSide":"left"},
		{"id":"42a43d777eddf699","fromNode":"4a9e0af6fa1f8472","fromSide":"bottom","toNode":"0bac8ddd0cc0ea48","toSide":"top"},
		{"id":"aeaa7e17c9f266b1","fromNode":"6b26542e75b5a010","fromSide":"right","toNode":"adc54afbae0740e4","toSide":"left"},
		{"id":"71489c7da900eae1","fromNode":"0bac8ddd0cc0ea48","fromSide":"top","toNode":"6b26542e75b5a010","toSide":"left"},
		{"id":"576614796f1f592e","fromNode":"6b26542e75b5a010","fromSide":"bottom","toNode":"1dad249a05ab28b1","toSide":"top"},
		{"id":"f9fb8571fc15d11c","fromNode":"0bac8ddd0cc0ea48","fromSide":"bottom","toNode":"d1b1da8e14a89c26","toSide":"top"},
		{"id":"6cebc9868a48e7c9","fromNode":"6b26542e75b5a010","fromSide":"right","toNode":"206e2718cacccb39","toSide":"left"},
		{"id":"166452c2f39c4f4b","fromNode":"d1b1da8e14a89c26","fromSide":"right","toNode":"10e69b68374e69a4","toSide":"left"},
		{"id":"15798cc8c3766df7","fromNode":"d1b1da8e14a89c26","fromSide":"right","toNode":"5ebb9d2dabcdc329","toSide":"left"},
		{"id":"9d981c6cd76b382b","fromNode":"d1b1da8e14a89c26","fromSide":"bottom","toNode":"ec02cf92e35c5eb6","toSide":"top"},
		{"id":"e08a6e14da48b53a","fromNode":"61fad2ad255cf82a","fromSide":"right","toNode":"27e4fdde4c9ad72d","toSide":"left"},
		{"id":"3b73f401a4430ae2","fromNode":"27e4fdde4c9ad72d","fromSide":"left","toNode":"61fad2ad255cf82a","toSide":"right"},
		{"id":"9600f852b160883f","fromNode":"26cfad6010ff7969","fromSide":"left","toNode":"27e4fdde4c9ad72d","toSide":"right"},
		{"id":"3a544c663e5af73e","fromNode":"26cfad6010ff7969","fromSide":"bottom","toNode":"8c7076684bac10a2","toSide":"top"},
		{"id":"cfbee7a02809a3c9","fromNode":"933c1f33f83329d3","fromSide":"right","toNode":"0bac8ddd0cc0ea48","toSide":"left"},
		{"id":"eec7b20bf6a64276","fromNode":"0bac8ddd0cc0ea48","fromSide":"left","toNode":"26cfad6010ff7969","toSide":"right"},
		{"id":"390f1c28413c1b85","fromNode":"8c7076684bac10a2","fromSide":"left","toNode":"8d0dc0d08efb8898","toSide":"right"},
		{"id":"9dcad2358fc814cb","fromNode":"8d0dc0d08efb8898","fromSide":"left","toNode":"e00a97cccf420735","toSide":"right"},
		{"id":"583dbca61d1454cf","fromNode":"8c7076684bac10a2","fromSide":"bottom","toNode":"28ef98e44e010a54","toSide":"top"},
		{"id":"a0c6776ccaf2b63a","fromNode":"e00a97cccf420735","fromSide":"bottom","toNode":"9c55c12867f0cfe8","toSide":"top"},
		{"id":"18ec5dd67397394a","fromNode":"28ef98e44e010a54","fromSide":"left","toNode":"b38a5df100f9850b","toSide":"right"},
		{"id":"c8a53e70710242cb","fromNode":"9c55c12867f0cfe8","fromSide":"bottom","toNode":"a6494ec2a3a14739","toSide":"top"},
		{"id":"fefc16fb2cfbd879","fromNode":"255c19cad945a18f","fromSide":"right","toNode":"65f8df716b94268d","toSide":"left"},
		{"id":"b160f9150bb7ee41","fromNode":"ed6ac0281f980f03","fromSide":"left","toNode":"19cda58d82f6e368","toSide":"right"},
		{"id":"86699d4adc27ad53","fromNode":"6dbca290cf842d6e","fromSide":"left","toNode":"9a0af77adce9ad06","toSide":"right"},
		{"id":"7507abfe85a6e554","fromNode":"9a0af77adce9ad06","fromSide":"top","toNode":"ed6ac0281f980f03","toSide":"bottom"},
		{"id":"571b4df7d4649dfd","fromNode":"69f3dd73ee95ff32","fromSide":"right","toNode":"7d169a16a8cca630","toSide":"left"},
		{"id":"828f3ed4f1df74af","fromNode":"69f3dd73ee95ff32","fromSide":"right","toNode":"58f52445ff3fb61e","toSide":"left"},
		{"id":"c997b2b3fdd984d6","fromNode":"ec02cf92e35c5eb6","fromSide":"right","toNode":"2c40139566bcddb2","toSide":"left"},
		{"id":"98d30276bbac9479","fromNode":"69f3dd73ee95ff32","fromSide":"bottom","toNode":"e4716290f3d5b096","toSide":"top"},
		{"id":"bf3d050c573b60d5","fromNode":"a809a009a3c7f901","fromSide":"right","toNode":"e4716290f3d5b096","toSide":"left"},
		{"id":"585153ac4f249aa4","fromNode":"e4716290f3d5b096","fromSide":"left","toNode":"a809a009a3c7f901","toSide":"right"},
		{"id":"69173c86f8cfb215","fromNode":"69f3dd73ee95ff32","fromSide":"bottom","toNode":"a809a009a3c7f901","toSide":"top"},
		{"id":"a478b13a8954f96b","fromNode":"a809a009a3c7f901","fromSide":"right","toNode":"f3560ddcee0e71de","toSide":"left"},
		{"id":"6d2aaf39cbed1436","fromNode":"f3560ddcee0e71de","fromSide":"right","toNode":"346edb2cd343ae50","toSide":"left"},
		{"id":"28ca28c9bd29dbfb","fromNode":"346edb2cd343ae50","fromSide":"bottom","toNode":"deedc18089e093f1","toSide":"top"},
		{"id":"63b6e17c3e3869ec","fromNode":"edd84b5881ba408b","fromSide":"top","toNode":"46a10f1736b333eb","toSide":"bottom"},
		{"id":"44ad6a4d17bbb04b","fromNode":"346edb2cd343ae50","fromSide":"right","toNode":"652e671c121210e0","toSide":"left"},
		{"id":"389909bba676d73e","fromNode":"a23e13dca8a3ad1d","fromSide":"bottom","toNode":"0c73604c03c3a581","toSide":"top"},
		{"id":"3bf4a9b4f5cea38d","fromNode":"652e671c121210e0","fromSide":"top","toNode":"62a83dc4f208244f","toSide":"bottom"},
		{"id":"449edb8fb12460cc","fromNode":"62a83dc4f208244f","fromSide":"right","toNode":"a23e13dca8a3ad1d","toSide":"left"},
		{"id":"5c9a0e053f0aad07","fromNode":"a23e13dca8a3ad1d","fromSide":"left","toNode":"62a83dc4f208244f","toSide":"right"},
		{"id":"042b6efd63193844","fromNode":"d944c099d4a52726","fromSide":"top","toNode":"ee6c1653941f5cf9","toSide":"bottom"},
		{"id":"509cee5635115cba","fromNode":"ee6c1653941f5cf9","fromSide":"left","toNode":"374ffdc5ef9b8c37","toSide":"right"},
		{"id":"4cc9780356b854be","fromNode":"374ffdc5ef9b8c37","fromSide":"left","toNode":"c117519b0d042f3b","toSide":"right"},
		{"id":"2026858fb723c170","fromNode":"4e690bb692a0c595","fromSide":"left","toNode":"fc632d9a9c345ef1","toSide":"right"},
		{"id":"f828ee1f99635d5a","fromNode":"d944c099d4a52726","fromSide":"top","toNode":"742f4065dd5c5cbc","toSide":"bottom"},
		{"id":"1cc3c26491c15394","fromNode":"69f3dd73ee95ff32","fromSide":"top","toNode":"742f4065dd5c5cbc","toSide":"bottom"},
		{"id":"63c24152615b505d","fromNode":"742f4065dd5c5cbc","fromSide":"top","toNode":"e9bab4cd14415702","toSide":"bottom"},
		{"id":"15f69df2a41b8a3b","fromNode":"742f4065dd5c5cbc","fromSide":"top","toNode":"6b5bb4e98e9e2a28","toSide":"bottom"},
		{"id":"780d602ef9a08740","fromNode":"62a83dc4f208244f","fromSide":"top","toNode":"e9bab4cd14415702","toSide":"right"},
		{"id":"403047f28a694c6d","fromNode":"e9bab4cd14415702","fromSide":"right","toNode":"62a83dc4f208244f","toSide":"top"},
		{"id":"9f8dc2221891f2f8","fromNode":"6b5bb4e98e9e2a28","fromSide":"top","toNode":"b5aedc73d018cc9e","toSide":"bottom"},
		{"id":"9c5ed8b3d94683e7","fromNode":"6b5bb4e98e9e2a28","fromSide":"left","toNode":"23b1b309c92014a7","toSide":"right"},
		{"id":"3bf40c61746fa239","fromNode":"23b1b309c92014a7","fromSide":"left","toNode":"760de5855566da94","toSide":"right"},
		{"id":"1b5c1f25dfeb08c2","fromNode":"6b5bb4e98e9e2a28","fromSide":"top","toNode":"ab7ce62182178f88","toSide":"left"},
		{"id":"f0600a4436663ad2","fromNode":"742f4065dd5c5cbc","fromSide":"right","toNode":"05216adedc2d6235","toSide":"left"},
		{"id":"1bedea8102e4294d","fromNode":"ab7ce62182178f88","fromSide":"left","toNode":"6b5bb4e98e9e2a28","toSide":"top"},
		{"id":"0fbc13db8479476e","fromNode":"e9bab4cd14415702","fromSide":"top","toNode":"ab7ce62182178f88","toSide":"bottom"},
		{"id":"f4e795e9a1ce9d6f","fromNode":"ab7ce62182178f88","fromSide":"bottom","toNode":"e9bab4cd14415702","toSide":"top"},
		{"id":"f660b2978b3bd069","fromNode":"6b5bb4e98e9e2a28","fromSide":"right","toNode":"e9bab4cd14415702","toSide":"left"},
		{"id":"6e43c1eaf117c27c","fromNode":"05216adedc2d6235","fromSide":"right","toNode":"9132abad1267a121","toSide":"left"},
		{"id":"d56c1f5bac3b324f","fromNode":"05216adedc2d6235","fromSide":"top","toNode":"fdb26cc1e8ca8651","toSide":"bottom"},
		{"id":"b2e4d396fa33d604","fromNode":"fdb26cc1e8ca8651","fromSide":"right","toNode":"f03ea06b8cc06adb","toSide":"left"},
		{"id":"8f50d906d38e1b31","fromNode":"c117519b0d042f3b","fromSide":"left","toNode":"4e690bb692a0c595","toSide":"right"},
		{"id":"08573efeb1283bcf","fromNode":"2d34128153e6b03e","fromSide":"left","toNode":"66b9c1070bde7f69","toSide":"right"},
		{"id":"098626aeae5f1448","fromNode":"fccd506f086b692b","fromSide":"left","toNode":"2d34128153e6b03e","toSide":"right"},
		{"id":"ce04929de2a5cb54","fromNode":"925b75588817e4f2","fromSide":"right","toNode":"241de77d83aa7a2e","toSide":"left"},
		{"id":"7d02c2e02214d9cd","fromNode":"241de77d83aa7a2e","fromSide":"right","toNode":"829486c3d7b82293","toSide":"left"},
		{"id":"904e58e42d21deae","fromNode":"f9bd700671836856","fromSide":"right","toNode":"e4fb36d38cd1f579","toSide":"left"},
		{"id":"69668805a3621edd","fromNode":"e4fb36d38cd1f579","fromSide":"right","toNode":"441b39d70b5495bc","toSide":"left"},
		{"id":"5181f774755f592c","fromNode":"441b39d70b5495bc","fromSide":"right","toNode":"a17a579ccfec49f8","toSide":"left"},
		{"id":"2c28d587a1f61c83","fromNode":"a17a579ccfec49f8","fromSide":"right","toNode":"ccccd634116d267b","toSide":"left"},
		{"id":"2960b600378f3782","fromNode":"5d912aa428876e90","fromSide":"right","toNode":"ae158c9814d93e39","toSide":"left"},
		{"id":"17456aad18945b13","fromNode":"4f7a30ec90f5f7a1","fromSide":"left","toNode":"fccd506f086b692b","toSide":"right"}
	]
}